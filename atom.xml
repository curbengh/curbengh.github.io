<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ming Di Leom&#39;s Blog</title>
  <icon>https://mdleom.com/svg/favicon.svg</icon>
  
  <link href="https://mdleom.com/atom.xml" rel="self"/>
  
  <link href="https://mdleom.com/"/>
  <updated>2024-02-24T00:00:00.000Z</updated>
  <id>https://mdleom.com/</id>
  
  <author>
    <name>Ming Di Leom</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Applying default-deny ACL in Splunk app</title>
    <link href="https://mdleom.com/blog/2024/02/24/splunk-app-acl/"/>
    <id>https://mdleom.com/blog/2024/02/24/splunk-app-acl/</id>
    <published>2024-02-24T00:00:00.000Z</published>
    <updated>2024-02-24T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>When I first started creating custom Splunk app, I had an incorrect understanding of access control list (ACLs) configured using <a href="https://docs.splunk.com/Documentation/Splunk/latest/Admin/Defaultmetaconf">default.meta.conf</a> (located at app_folder&#x2F;metadata&#x2F;default.meta) whereby I could grant read access to a role like this:</p><pre><code class="hljs conf">[]access = read : [ roleA ], write : [ ][lookups/lookupB.csv]access = read : [ roleA, roleB ], write : [ ]</code></pre><p>Or like this:</p><pre><code class="hljs conf">[]access = read : [ roleA ], write : [ ][lookups]access = read : [ roleA, roleB ], write : [ ]</code></pre><p>None of the above configs will grant roleB read access to lookupB.csv. For the rest of this discussion, we assume that roleB should have access to lookupB.csv only.</p><pre><code class="hljs md"><span class="hljs-section"># Interaction of ACLs across app-level, category level, and specific object configuration:</span><span class="hljs-bullet">-</span> To access/use an object, users must have read access to:<span class="hljs-bullet">  -</span> the app containing the object<span class="hljs-bullet">  -</span> the generic category within the app (for example, [views])<span class="hljs-bullet">  -</span> the object itself<span class="hljs-bullet">-</span> If any layer does not permit read access, the object will not be accessible.</code></pre><blockquote><p>For brevity, this article will only discuss about read access which has slightly different interaction of ACLs compared to write access. Don’t worry, once you understood read access, it’s much easier to understand write access.</p></blockquote><p>Notice a role must at least have read access to the app. The simplest way to grant roleB read access is,</p><pre><code class="hljs conf">[]access = read : [ roleA, roleB ], write : [ ]</code></pre><p>While the above config is effective, but it does not meet the access requirement: roleB is granted read access to every objects in that app.</p><p>roleB can be restricted as such:</p><pre><code class="hljs conf">[]access = read : [ roleA, roleB ], write : [ ][lookups/lookupA.csv]access = read : [ roleA ], write : [ ][lookups/lookupB.csv]access = read : [ roleA, roleB ], write : [ ][lookups/lookupC.csv]access = read : [ roleA ], write : [ ]</code></pre><p>It is effective and meets the requirement, but there is an issue. Every new lookup&#x2F;object will now need to specify <code>access = read : [ roleA ], write : [ ]</code> to restrict roleB’s access. This is similar to a default-allow firewall.</p><h2 id="Default-deny-ACL">Default-deny ACL <a href="#Default-deny-ACL" class="headerlink" title="Default-deny ACL">§</a></h2><p>How to implement default-deny ACL? We can achieve it by separating into two apps: appA is accessible to roleA only, appB is accessible to roleA and roleB. Any object we want to share with roleA and roleB, we put it in appB instead.</p><pre><div class="caption"><span>appA</span></div><code class="hljs conf">[]access = read : [ roleA ], write : [ ]</code></pre><pre><div class="caption"><span>appB</span></div><code class="hljs conf">[]access = read : [ roleA, roleB ], write : [ ]</code></pre><p>In this approach, every new objects created in appA will not be accessible to roleB because it does not have app access.</p><h2 id="Non-removable-lookup-file">Non-removable lookup file <a href="#Non-removable-lookup-file" class="headerlink" title="Non-removable lookup file">§</a></h2><p>I noticed lookup files that have object-level ACL, e.g.</p><pre><code class="hljs conf">[lookups/lookupC.csv]access = read : [ roleA ], write : [ ]</code></pre><p>makes it non-removable, even with admin&#x2F;sc-admin role.</p><p>My theory is that the object is non-removable to prevent the ACL from being orphaned. But this theory does not hold, at least for a lookup file that is shipped with an app; deleting a lookup file merely resets its content back to the app’s version. Deleting a lookup file is necessary during an app update that also have updated content of a bundled lookup file. Even when a lookup was never modified, Splunk will keep the content during an app update. Updating an app does not automatically update the bundled lookup, the lookup will only be updated after a delete operation.</p><p>Similar limitation (i.e. app update does not update the app’s object) also applies to dashboards. However, there is no way to delete a dashboard xml in Splunk Cloud, so updating a dashboard through app update always require app uninstallation beforehand.</p>]]></content>
    
    
    <summary type="html">Isolate access between roles</summary>
    
    
    
    <category term="splunk" scheme="https://mdleom.com/tags/splunk/"/>
    
  </entry>
  
  <entry>
    <title>Query LOCKOUT and PASSWORD_EXPIRED flags on Splunk SA-ldapsearch</title>
    <link href="https://mdleom.com/blog/2023/10/01/splunk-ldapsearch-useraccountcontrol/"/>
    <id>https://mdleom.com/blog/2023/10/01/splunk-ldapsearch-useraccountcontrol/</id>
    <published>2023-10-01T00:00:00.000Z</published>
    <updated>2023-10-01T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://splunkbase.splunk.com/app/1151">SA-ldapsearch</a> (Splunk Supporting Add-on for Active Directory) has a useful feature that parses “userAccountControl” flags into a multivalue. For example, instead of showing “514”, it shows <code>[ACCOUNTDISABLE, NORMAL_ACCOUNT]</code> instead. However, I noticed <code>LOCKOUT</code> and <code>PASSWORD_EXPIRED</code> flags are not shown even though I was sure the accounts I queried have either of those flags set. Those flags are indeed listed under documentations for “userAccountControl”: <a href="https://learn.microsoft.com/en-us/troubleshoot/windows-server/identity/useraccountcontrol-manipulate-account-properties#list-of-property-flags">Windows Server</a> and <a href="https://learn.microsoft.com/en-gb/windows/win32/adschema/a-useraccountcontrol">Active Directory Schema</a>.</p><p>Despite being mentioned in the documentations, in that Windows Server doc, there is a note that says those flags have been moved to “<a href="https://learn.microsoft.com/en-gb/windows/win32/adschema/a-msds-user-account-control-computed">msDS-User-Account-Control-Computed</a>“ attribute since Windows Server 2003. But when I queried that attribute, I got a decimal value which meant the parsing function was not applied.</p><p>To apply flag-parsing function on “msDS-User-Account-Control-Computed”:</p><pre><div class="caption"><span>SA-ldapsearch/bin/packages/app/formatting_extensions.py</span></div><code class="hljs python"><span class="hljs-string">&#x27;1.2.840.113556.1.4.8&#x27;</span>:             format_user_flag_enum,         <span class="hljs-comment"># User-Account-Control</span><span class="hljs-string">&#x27;1.2.840.113556.1.4.1460&#x27;</span>:          format_user_flag_enum,         <span class="hljs-comment"># ms-DS-User-Account-Control-Computed</span></code></pre><p>First line is an existing one, the second line is the new one.</p><p>For the sake of completeness, that function can also be patched to parse other flags of “msDS-User-Account-Control-Computed”. I created <a href="https://gitlab.com/curben/splunk-scripts/-/tree/main/SA-ldapsearch?ref_type=heads">a script</a> to apply the following patch directly on “<a href="https://splunkbase.splunk.com/app/1151">splunk-supporting-add-on-for-active-directory_*.tgz</a>“ and save it to a new app package “SA-ldapsearch_*.tgz”.</p><pre><code class="hljs patch"><span class="hljs-comment">--- SA-ldapsearch/bin/packages/app/formatting_extensions.py  2023-09-06 00:00:00.000000000 +0000</span><span class="hljs-comment">+++ SA-ldapsearch/bin/packages/app/formatting_extensions.py  2023-09-06 00:00:00.000000001 +0000</span><span class="hljs-meta">@@ -721,6 +721,12 @@</span>         names.append(&#x27;PASSWORD_EXPIRED&#x27;)     if flags &amp; 0x1000000:         names.append(&#x27;TRUSTED_TO_AUTHENTICATE_FOR_DELEGATION&#x27;)<span class="hljs-addition">+    if flags &amp; 0x2000000:</span><span class="hljs-addition">+        names.append(&#x27;NO_AUTH_DATA_REQUIRED&#x27;)</span><span class="hljs-addition">+    if flags &amp; 0x4000000:</span><span class="hljs-addition">+        names.append(&#x27;PARTIAL_SECRETS_ACCOUNT&#x27;)</span><span class="hljs-addition">+    if flags &amp; 0x8000000:</span><span class="hljs-addition">+        names.append(&#x27;USE_AES_KEYS&#x27;)</span>     # Zero or one of these flags may be set<span class="hljs-meta">@@ -822,6 +828,7 @@</span>     &#x27;1.2.840.113556.1.4.1303&#x27;:          format_sid,                    # Token-Groups-No-GC-Acceptable     &#x27;1.2.840.113556.1.4.8&#x27;:             format_user_flag_enum,         # User-Account-Control<span class="hljs-addition">+    &#x27;1.2.840.113556.1.4.1460&#x27;:          format_user_flag_enum,         # ms-DS-User-Account-Control-Computed</span>     # formatter specially for msExchMailboxSecurityDescriptor     &#x27;1.2.840.113556.1.4.7000.102.80&#x27; : format_security_descriptor,     # msExchMailboxSecurityDescriptor</code></pre>]]></content>
    
    
    <summary type="html">userAccountControl vs. msDS-User-Account-Control-Computed</summary>
    
    
    
    <category term="splunk" scheme="https://mdleom.com/tags/splunk/"/>
    
  </entry>
  
  <entry>
    <title>Azure AD SSO integration with ServiceNow</title>
    <link href="https://mdleom.com/blog/2023/08/27/saml-scim/"/>
    <id>https://mdleom.com/blog/2023/08/27/saml-scim/</id>
    <published>2023-08-27T00:00:00.000Z</published>
    <updated>2023-08-27T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>Single sign-on (SSO) enables a user to access multiple systems using one login. Whenever a user wants to access a system, the system will redirect the user to an identity provider which has an existing account for that user; once the user authenticates with the identity provider successfully, the identity provider will redirect the user back to the system and the user can then access it. The system does not have the user’s password and the identity provider does not share it either.</p><p>In an enterprise environment, SSO provides convenience to the staff and several benefits to the enterprise. Three benefits to the enterprise:</p><ol><li>Less accounts to create (onboarding), maintain and disable&#x2F;delete (offboarding).</li><li>During offboarding, disabling an account from the identity provider will also revoke access to SSO-enabled systems, thus providing better security.</li><li>Identity provider is much more likely to support multi-factor authentication (MFA), enabling more systems to be MFA-secured.</li></ol><p>SSO does not necessarily provide better security all the time. Threat actor can utilise a compromised account to access any SSO-enabled system that the account has access prior, leading to wider blast radius. There are three mitigations to reduce such risk:</p><ol><li>Enforce MFA to minimise the chance of accounts being compromised.</li><li>Limit access to SSO-enabled systems through access control list (ACL).</li><li>Enforce conditional access. For example, identity provider can be configured to prompt for second-factor authentication when accessing a sensitive system, even when the user is already logged in using MFA before. Identity provider could also enforce phish-resistant MFA for access to sensitive systems.</li></ol><h2 id="SSO-in-Azure-AD">SSO in Azure AD <a href="#SSO-in-Azure-AD" class="headerlink" title="SSO in Azure AD">§</a></h2><p>Configuring a system to utilise Azure Active Directory (AAD) involves setting up <a href="https://en.wikipedia.org/wiki/Security_Assertion_Markup_Language">SAML</a> and optionally <a href="https://en.wikipedia.org/wiki/System_for_Cross-domain_Identity_Management">SCIM</a>. SCIM is only used to provision users, SAML can supply the necessary information (email, name, phone, etc) to the SSO-enabled system to create users on-demand upon first login (of that user) and update the user information in subsequent logins. In ServiceNow SAML configuration, under “User Provisioning” tab, on-demand user provision can be enabled by ticking “Auto Provisioning User” and “Update User Record Upon Each Login”.</p><p>During the initial SAML setup in ServiceNow, it requires a successful test login (using an AAD account, in this case) before SSO can be activated. This will fail if the user does not exist in ServiceNow yet. To pass it, simply create a new ServiceNow user that has the same email as the test AAD account. If you are confident the SAML setting is correct, the test login can be <a href="https://docs.servicenow.com/en-US/bundle/vancouver-platform-security/page/integrate/single-sign-on/task/t_TestIdPConnections.html">made optional</a>. It is easier to utilise the “<a href="https://learn.microsoft.com/en-us/azure/active-directory/saas-apps/servicenow-tutorial#configure-servicenow">Automatically configure</a> ServiceNow” option because it will also configure the transform mapping in ServiceNow which enables it to map SAML attributes (emailaddress, name, etc) to the respective ServiceNow’s sys_user table columns.</p><p>In SAML configuration, AAD uses the “user.userprincipalname” (UPN) attribute as the unique user identifier. UPN is <em>usually</em> equivalent to the email address, so the <a href="https://learn.microsoft.com/en-us/azure/active-directory/saas-apps/servicenow-tutorial#configure-servicenow">AAD guide</a> recommends to change the user identifier to “email” in ServiceNow’s Multi-Provider SSO. However, it is possible for UPN to be different to email and will prevent affected users from accessing ServiceNow. UPN or email is also not immutable, a user may change their email to reflect a name change. This can results in duplicate users, if “Auto Provisioning User” is enabled in ServiceNow.</p><p>Even though <a href="#scim">SCIM</a> can avoid duplicates, users with a recently changed email may still face access issue for a while because AAD SCIM is not real-time and each sync can take up to <a href="https://learn.microsoft.com/en-us/azure/active-directory/app-provisioning/application-provisioning-when-will-provisioning-finish-specific-user#how-long-will-it-take-to-provision-users">30 minutes</a>, longer if the attribute is sourced from on-premise AD (which will needs to be synced-up to AAD using AD Connect, and then to ServiceNow using SCIM).</p><p>To avoid this issue, there are three choices of source attribute that are immutable, each of them is suitable as a unique user identifier in SAML. They do not map with existing ServiceNow sys_user columns, so you will need a new column and a new mapping in the transform map.</p><ol><li><code>user.objectid</code>: for AAD-only environment.</li><li><code>user.onpremisesimmutableid</code>: refers to GUID. AAD uses this attribute as the primary key to identify on-premise AD user.</li><li><code>user.onpremisesecurityidentifier</code>: refers to SID, may not necessarily synced-up to AAD.</li></ol><h2 id="SCIM">SCIM <a href="#SCIM" class="headerlink" title="SCIM">§</a></h2><p>With on-demand user provision, it is possible to use SAML without SCIM. However, since a user is only created after the initial SSO login, user lookup will be limited. For example in ServiceNow, a support staff will not be able to enter the “this incident affects user X” field if that user has never login to ServiceNow before. SCIM can provision all users found in an identity provider into a target system. It is also possible to provision based on conditions, such as to exclude generic or service accounts.</p><p>Prior to configuring SCIM in ServiceNow, it is essential to disable SAML on-demand user provision “Auto Provisioning User” and “Update User Record Upon Each Login”. This is to avoid SAML-sourced attribute from overwriting SCIM’s in sys_user table, because SAML mapping does not necessarily match SCIM’s.</p><p>In AAD SCIM, the default primary mapping is userPrincipalName → user_name with user_name being set as the primary key (Show advanced options → Edit attribute list for ServiceNow). A mapping is considered as primary when it has “<a href="https://learn.microsoft.com/en-us/azure/active-directory/app-provisioning/customize-application-attributes">Match objects using this attribute</a>“ enabled and has the lowest value in “Matching precedence”. “Match objects…” is to configure SCIM to utilise a mapping to check existence of each user, i.e. provision a user in the target system if it does not exist. Multiple mappings can be used in different order, in case a source attribute is empty. At least one mapping must have “Match objects…” enabled.</p><table><thead><tr><th>user</th><th>employeeId (AAD)</th><th>mail (AAD)</th><th>employee_number (SNow)</th><th>email (SNow)</th></tr></thead><tbody><tr><td>A</td><td>123</td><td><em>empty</em></td><td>123</td><td><em>empty</em></td></tr><tr><td>B</td><td><em>empty</em></td><td><a href="mailto:&#98;&#x40;&#101;&#x78;&#97;&#109;&#x70;&#x6c;&#x65;&#x2e;&#x63;&#x6f;&#109;">&#98;&#x40;&#101;&#x78;&#97;&#109;&#x70;&#x6c;&#x65;&#x2e;&#x63;&#x6f;&#109;</a></td><td><em>empty</em></td><td><a href="mailto:&#98;&#64;&#x65;&#x78;&#x61;&#109;&#112;&#108;&#x65;&#x2e;&#99;&#x6f;&#109;">&#98;&#64;&#x65;&#x78;&#x61;&#109;&#112;&#108;&#x65;&#x2e;&#99;&#x6f;&#109;</a></td></tr></tbody></table><p>What if user B has employeeId later on? There is a (unconfirmed) possibility that it can results in duplicate user B in the target system.</p><table><thead><tr><th>user</th><th>employeeId (AAD)</th><th>mail (AAD)</th><th>employee_number (SNow)</th><th>email (SNow)</th></tr></thead><tbody><tr><td>A</td><td>123</td><td><em>empty</em></td><td>123</td><td><em>empty</em></td></tr><tr><td>B</td><td>456</td><td><a href="mailto:&#98;&#x40;&#x65;&#x78;&#97;&#109;&#x70;&#108;&#101;&#46;&#99;&#x6f;&#x6d;">&#98;&#x40;&#x65;&#x78;&#97;&#109;&#x70;&#108;&#101;&#46;&#99;&#x6f;&#x6d;</a></td><td><em>empty</em></td><td><a href="mailto:&#x62;&#x40;&#101;&#x78;&#x61;&#x6d;&#112;&#x6c;&#x65;&#46;&#x63;&#111;&#x6d;">&#x62;&#x40;&#101;&#x78;&#x61;&#x6d;&#112;&#x6c;&#x65;&#46;&#x63;&#111;&#x6d;</a></td></tr><tr><td>B (<em>duplicate in SNow</em>)</td><td>456</td><td><a href="mailto:&#x62;&#x40;&#x65;&#x78;&#97;&#109;&#112;&#x6c;&#101;&#46;&#x63;&#x6f;&#x6d;">&#x62;&#x40;&#x65;&#x78;&#97;&#109;&#112;&#x6c;&#101;&#46;&#x63;&#x6f;&#x6d;</a></td><td>456</td><td><a href="mailto:&#x62;&#64;&#x65;&#120;&#x61;&#109;&#x70;&#108;&#x65;&#46;&#99;&#111;&#x6d;">&#x62;&#64;&#x65;&#120;&#x61;&#109;&#x70;&#108;&#x65;&#46;&#99;&#111;&#x6d;</a></td></tr></tbody></table><p>This can be avoided by using a <strong>mandatory</strong> and <strong>immutable</strong> AAD attribute. Similar to the three options mentioned in the previous section, they are:</p><ol><li><code>objectId</code></li><li><code>immutableId</code></li><li><code>onPremisesSecurityIdentifier</code></li></ol><p>Steps to configure:</p><ol><li>In ServiceNow, add a new column in sys_user ServiceNow table.</li><li>In AAD SCIM, Show advanced options → Edit attribute list for ServiceNow, add a new attribute with the same name as configured in previous step. Tick “Required” and “Primary”, untick “Primary” in existing attribute (usually “user_name”).</li><li>Add a new mapping with “Match objects” enabled.</li><li>Disable it in existing mapping (usually “userPrincipalName → user_name”).</li><li>Save</li></ol><h2 id="Single-space-value">Single-space value <a href="#Single-space-value" class="headerlink" title="Single-space value">§</a></h2><p>An interesting issue I encountered which was ultimately caused by an AAD attribute that had a value of just a single space. I initially configured a SCIM mapping as follow: Coalesce([attributeA], [attributeB]) → u*column_z. Coalesce() returns the first non-empty value. I knew attributeB is never empty, however somehow some users had *(blank)_ value in their u_column_z.</p><p>I fired up the Expression Builder in AAD SCIM and tried “Coalesce([attributeA], [attributeB])” on one of the affected users. It returned “Your expression is valid, but your expression evaluated to an empty string”. Tried “ToUpper([attributeA])”, same. Tried “IsNullorEmpty([attributeA])”, got “false”. If an attribute has empty value, it will return “null”. So, this meant attributeA is not empty. But what could it be?</p><pre><code class="hljs plaintext">IIF([attributeA]=&quot; &quot;, &quot;space&quot;, &quot;no space&quot;)space</code></pre><p>AAD SCIM trims any leading and trailing whitespaces in the output, similar to <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/trim"><code>trim()</code></a> JavaScript method.</p><p>Aside from an obvious fix by removing that space in AAD, a workaround like “Coalesce(Trim([attributeA]), [attributeB])” works too.</p>]]></content>
    
    
    <summary type="html">Difference of SAML and SCIM</summary>
    
    
    
    <category term="sso" scheme="https://mdleom.com/tags/sso/"/>
    
    <category term="servicenow" scheme="https://mdleom.com/tags/servicenow/"/>
    
    <category term="azure-ad" scheme="https://mdleom.com/tags/azure-ad/"/>
    
  </entry>
  
  <entry>
    <title>Mapping Ctrl+H to Backspace in terminal emulator</title>
    <link href="https://mdleom.com/blog/2023/07/17/ctrl-h-backspace/"/>
    <id>https://mdleom.com/blog/2023/07/17/ctrl-h-backspace/</id>
    <published>2023-07-17T00:00:00.000Z</published>
    <updated>2023-07-17T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>A few months ago, there was <a href="https://www.masteringemacs.org/article/keyboard-shortcuts-every-command-line-hacker-should-know-about-gnu-readline">an article</a> which encouraged Linux users to use more readline keyboard shortcuts. readline keyboard shortcuts are based on Emacs keybindings, while also support switching to vi keybindings. At that time, I was only familiar with <code>Ctrl+a</code> (line start) and <code>Ctrl+e</code> (line end). Interested to learn more tricks, I went on search for a cheatsheet and <a href="https://clementc.github.io/blog/2018/01/25/moving_cli/">found this</a>. I then added two missing shortcuts (<code>Ctrl+h</code> &amp; <code>Ctrl+d</code>), printed it out and stick it to my desk.</p><p><a href="/img/20230717/readline-shortcuts.png"><img srcset="/img/20230717/readline-shortcuts.png?f=auto&width=320 320w,/img/20230717/readline-shortcuts.png?f=auto&width=468 468w,/img/20230717/readline-shortcuts.png?f=auto&width=768 768w,/img/20230717/readline-shortcuts.png?f=auto 800w" sizes="(max-width: 320px) 320px,(max-width: 468px) 468px,(max-width: 768px) 768px,800px" src="/img/20230717/readline-shortcuts.png?f=auto" title="readline keyboard shortcuts" alt="readline keyboard shortcuts" loading="lazy"></a></p><p>However there were two shortcuts which did not work as intended: <code>Ctrl+h</code> and <code>Ctrl+Backspace</code>. The first one is <a href="https://en.wikipedia.org/wiki/GNU_Readline#Emacs_keyboard_shortcuts">supposed to</a> be equivalent to backspace, but it was deleting previous word just like <code>Ctrl+Backspace</code> or <code>Ctrl+w</code>. The second one did not work on PowerShell’s Emacs mode.</p><p>While looking for a workaround for other terminal and shell, I find it helpful to remember these two facts so that you can stay on the right track.</p><ul><li>$TERM does not refer to the terminal emulator</li><li>Shell does not recognise Ctrl+Backspace</li></ul><h2 id="TERM-is-not-the-terminal-emulator">$TERM is not the terminal emulator <a href="#TERM-is-not-the-terminal-emulator" class="headerlink" title="$TERM is not the terminal emulator">§</a></h2><p>In Kitty, <code>$TERM</code> is “xterm-kitty”; most other Linux terminals output it as “xterm-256color”. The value actually refers to the “<a href="https://en.wikipedia.org/wiki/Terminfo">terminfo</a>“ being used and not the <a href="https://en.wikipedia.org/wiki/Xterm">terminal emulator</a>.</p><h2 id="Shell-does-not-recognise-Ctrl-Backspace">Shell does not recognise Ctrl+Backspace <a href="#Shell-does-not-recognise-Ctrl-Backspace" class="headerlink" title="Shell does not recognise Ctrl+Backspace">§</a></h2><p>When Ctrl+Backspace is pressed, a terminal emulator either sends “^?” or “^H” <a href="https://en.wikipedia.org/wiki/C0_and_C1_control_codes#C0_controls">control character</a> to the shell, which then initiate an action (e.g. “backward-kill-word”).</p><p>“^[character]“ is first and foremost a <a href="https://en.wikipedia.org/wiki/Caret_notation">caret notation</a> of a control character, a friendlier representation of hexadecimal, much like hexadecimal is a nicer representation of binary. “^H” actually means control-code-8 (H is the eighth letter), instead of representing <code>Ctrl+h</code>. “^H” can be entered using <code>Ctrl+h</code> simply because it is more practical than having a dedicated key for each control character on a keyboard.</p><h2 id="Remap-Ctrl-h-to">Remap Ctrl+h to ^? <a href="#Remap-Ctrl-h-to" class="headerlink" title="Remap Ctrl+h to ^?">§</a></h2><p>Most terminal emulators map <code>Backspace</code> to “^?” and <code>Ctrl+Backspace</code> to “^H”. Since <code>Ctrl+h</code> is also mapped to “^H”, thus sharing a similar action (“backward-kill-word”) with <code>Ctrl+Backspace</code>. The easiest fix is to remap <code>Ctrl+h</code> to “^?”. This approach only needs to configure the terminal emulator.</p><p>To check which control character is mapped to:</p><pre><code class="hljs plaintext">$ showkey -a# backspace^?   127 0177 0x7f# ctrl+ backspace^H    8 0010 0x08</code></pre><h3 id="kitty">kitty <a href="#kitty" class="headerlink" title="kitty">§</a></h3><p><code>map ctrl+h send_text normal \x7f</code></p><p>Add the above line to the end of “$HOME&#x2F;.config&#x2F;kitty&#x2F;kitty.conf”. “7f” is the hex of “^?”.</p><p>Press <code>Ctrl+Shirt+F5</code> to reload the config and run <code>showkey -a</code> to verify <code>Ctrl+h</code> has been remapped.</p><pre><code class="hljs plaintext">$ showkey -a# ctrl+h^?   127 0177 0x7f</code></pre><h3 id="Windows-Terminal">Windows Terminal <a href="#Windows-Terminal" class="headerlink" title="Windows Terminal">§</a></h3><p>Go Settings → Open JSON file which will open “$home\AppData\Local\Packages\Microsoft.WindowsTerminal_xxx\LocalState\settings.json”. Under <code>&quot;actions&quot;</code> list, append the following object.</p><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;command&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>    <span class="hljs-attr">&quot;action&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sendInput&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;input&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;\u007F&quot;</span>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;keys&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ctrl+h&quot;</span><span class="hljs-punctuation">&#125;</span></code></pre><h2 id="Map-Ctrl-Backspace-to-backward-kill-word">Map Ctrl+Backspace to backward-kill-word <a href="#Map-Ctrl-Backspace-to-backward-kill-word" class="headerlink" title="Map Ctrl+Backspace to backward-kill-word">§</a></h2><p><code>Ctrl+Backspace</code> does not work as expected when I switch the PowerShell’s edit mode to Emacs <code>Set-PSReadLineOption -EditMode Emacs</code>, even though it works in the default <code>Cmd</code> mode. This is because PowerShell binds it to <a href="https://learn.microsoft.com/en-us/powershell/module/psreadline/about/about_psreadline_functions#backwarddeletechar"><code>BackwardDeleteChar</code></a> in Emacs mode. Somehow I could not remap it to “^H” (<code>\b</code>).</p><p>Some xterm users also have this issue and a workaround is by <a href="https://www.vinc17.net/unix/ctrl-backspace.en.html">mapping it</a> to an unused escape sequence, then bind it to backward-kill-word in the shell. While Windows Terminal <a href="https://learn.microsoft.com/en-us/windows/terminal/customize-settings/actions#send-input">supports</a> sending an escape sequence, the corresponding binding is <a href="https://github.com/PowerShell/PSReadLine/issues/3430">not supported</a> in PowerShell. Instead of using escape sequence, let’s use a unicode character, specifically a character within the range of <a href="https://en.wikipedia.org/wiki/Private_Use_Areas">private use area</a> (<code>U+E888-U+F8FF</code>) to avoid conflict with existing characters. I choose <code>U+E888</code> for this example.</p><p>Anyhow, it is only a tiny issue for me since I can always use <code>Ctrl+w</code>.</p><h3 id="Windows-Terminal-1">Windows Terminal <a href="#Windows-Terminal-1" class="headerlink" title="Windows Terminal">§</a></h3><p>Go Settings → Open JSON file which will open “$home\AppData\Local\Packages\Microsoft.WindowsTerminal_xxx\LocalState\settings.json”. Under <code>&quot;actions&quot;</code> list, append the following object.</p><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;command&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>    <span class="hljs-attr">&quot;action&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sendInput&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;input&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;\uE888&quot;</span>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;keys&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ctrl+backspace&quot;</span><span class="hljs-punctuation">&#125;</span></code></pre><h4 id="PowerShell">PowerShell <a href="#PowerShell" class="headerlink" title="PowerShell">§</a></h4><pre><div class="caption"><span>$PROFILE</span></div><code class="hljs ps"><span class="hljs-built_in">Set-PSReadLineKeyHandler</span> <span class="hljs-literal">-Chord</span> <span class="hljs-string">&quot;`u&#123;E888&#125;&quot;</span> <span class="hljs-literal">-Function</span> BackwardKillWord</code></pre><p>The following Windows Terminal + PowerShell configs did not work for me. Windows Terminal did yield the correct control character, but somehow PowerShell could not recognise it.</p><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;command&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>    <span class="hljs-attr">&quot;action&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sendInput&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;input&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;\u007F&quot;</span>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;keys&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;backspace&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;command&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>    <span class="hljs-attr">&quot;action&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sendInput&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;input&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;\b&quot;</span>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;keys&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ctrl+backspace&quot;</span><span class="hljs-punctuation">&#125;</span></code></pre><pre><div class="caption"><span>$PROFILE</span></div><code class="hljs ps"><span class="hljs-built_in">Set-PSReadLineKeyHandler</span> <span class="hljs-literal">-Chord</span> <span class="hljs-string">&quot;`u&#123;007F&#125;&quot;</span> <span class="hljs-literal">-Function</span> BackwardDeleteChar<span class="hljs-built_in">Set-PSReadLineKeyHandler</span> <span class="hljs-literal">-Chord</span> <span class="hljs-string">&quot;`b&quot;</span> <span class="hljs-literal">-Function</span> BackwardKillWord</code></pre><h4 id="zsh">zsh <a href="#zsh" class="headerlink" title="zsh">§</a></h4><pre><div class="caption"><span>$HOME/.zshrc</span></div><code class="hljs sh"><span class="hljs-built_in">bindkey</span> <span class="hljs-string">&#x27;\uE888&#x27;</span> backward-kill-word</code></pre><h4 id="bash">bash <a href="#bash" class="headerlink" title="bash">§</a></h4><pre><div class="caption"><span>$HOME/.bashrc</span></div><code class="hljs sh"><span class="hljs-built_in">bind</span> <span class="hljs-string">&#x27;&quot;\uE888&quot;:backward-kill-word&#x27;</span></code></pre>]]></content>
    
    
    <summary type="html">Also fix Ctrl+Backspace in PowerShell</summary>
    
    
    
    <category term="linux" scheme="https://mdleom.com/tags/linux/"/>
    
    <category term="zsh" scheme="https://mdleom.com/tags/zsh/"/>
    
    <category term="powershell" scheme="https://mdleom.com/tags/powershell/"/>
    
  </entry>
  
  <entry>
    <title>Configure Splunk Universal Forwarder to ingest JSON files</title>
    <link href="https://mdleom.com/blog/2023/06/17/json-splunk-uf/"/>
    <id>https://mdleom.com/blog/2023/06/17/json-splunk-uf/</id>
    <published>2023-06-17T00:00:00.000Z</published>
    <updated>2024-01-05T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>The recommended logging format according to <a href="https://dev.splunk.com/enterprise/docs/developapps/addsupport/logging/loggingbestpractices/#Use-developer-friendly-formats">Splunk best practice</a> looks like this:</p><pre><div class="caption"><span>example.log</span></div><code class="hljs json"><span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;datetime&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1672531212123456</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;event_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key1&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key2&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key3&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value3&quot;</span> <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;datetime&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1672531213789012</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;event_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key1&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key2&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key3&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value3&quot;</span> <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;datetime&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1672531214345678</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;event_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key1&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key2&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key3&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value3&quot;</span> <span class="hljs-punctuation">&#125;</span></code></pre><ul><li>Each <strong>event</strong> is in JSON, not the file.<ul><li>This also means the log file is not a valid JSON file.</li></ul></li><li>Each event is separated by newline.</li></ul><p>The format can be achieved by exporting live event in JSON and append to a log file. However, I encountered a situation where the log file can only be generated by batch. Exporting the equivalent of the previous “example.log” in JSON without string manipulation looks like this:</p><pre><div class="caption"><span>example.json</span></div><code class="hljs json"><span class="hljs-punctuation">[</span><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;datetime&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1672531212123456</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;event_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key1&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key2&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key3&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value3&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;datetime&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1672531213789012</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;event_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key1&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key2&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key3&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value3&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;datetime&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1672531214345678</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;event_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key1&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key2&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key3&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value3&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">]</span></code></pre><p>I will detail the required configurations in this post, so that Splunk is able to parse it correctly even though “example.json” is not a valid JSON file.</p><h2 id="UF-inputs-conf">UF inputs.conf <a href="#UF-inputs-conf" class="headerlink" title="UF inputs.conf">§</a></h2><pre><div class="caption"><span>$SPLUNK_HOME/etc/deployment-apps/foo/local/inputs.conf</span></div><code class="hljs conf">[monitor:///var/log/app_a]disabled = 0index = index_namesourcetype = app_a_event</code></pre><p><a href="https://docs.splunk.com/Documentation/Splunk/latest/Admin/Inputsconf#MONITOR:"><strong>monitor</strong></a> directive is made up of two parts: <code>monitor://</code> and the path, e.g. <code>/var/log/app_a</code>. Unlike most Splunk configs, this directive does’t require the backslash (used in Windows path) to be escaped, e.g. <code>monitor://C:\foo\bar</code>.</p><p>A path can be a file or a folder. When (*) wildcard matching is used to match multiple folders, another wildcard needs to be specified again to match files in those matched folders. The wildcard works for a single path segment only. For example, to match all the following files, use <code>monitor:///var/log/app_*/*</code>. Splunk also supports “…” for recursive matching.</p><pre><code class="hljs plaintext">/var/log/├── app_a│   ├── 1.log│   ├── 2.log│   └── 3.log├── app_b│   ├── 1.log│   ├── 2.log│   └── 3.log└── app_c    ├── 1.log    ├── 2.log    └── 3.log</code></pre><p>Specify an appropriate value in <strong>sourcetype</strong> config, the value will be the value of <code>sourcetype</code> field in the ingested events under the “monitor” directive. Take note of the value you have configured, it will be used in the rest of configurations.</p><h2 id="Forwarder-props-conf">Forwarder props.conf <a href="#Forwarder-props-conf" class="headerlink" title="Forwarder props.conf">§</a></h2><pre><div class="caption"><span>props.conf</span></div><code class="hljs conf">[app_a_event]description = App A logsINDEXED_EXTRACTIONS = JSON# separate each object into a lineLINE_BREAKER = &#125;(,)&#123;\&quot;datetime\&quot;# a line represents an eventSHOULD_LINEMERGE = 0TIMESTAMP_FIELDS = datetimeTIME_FORMAT = %s## default is 2000# MAX_DAYS_AGO = 3560</code></pre><p>The directive name should be the <strong>sourcetype</strong> value specified in the <a href="#App-specific-inputs-conf">inputs.conf</a>. The following configs apply to the universal forwarder is because <a href="https://docs.splunk.com/Documentation/Splunk/latest/Data/Extractfieldsfromfileswithstructureddata#Field_extraction_settings_for_forwarded_structured_data_must_be_configured_on_the_forwarder"><code>INDEXED_EXTRACTIONS</code></a> is used.</p><ul><li>LINE_BREAKER: Search for string that matches the regex and replace only the capturing group with newline (\n). This is to separate each event into separate line.<ul><li><code>&#125;(,)&#123;\&quot;datetime\&quot;</code> searches for <code>&#125;,&#123;&quot;datetime&quot;</code> and replaces “,” with “\n”.</li></ul></li><li>SHOULD_LINEMERGE: only used for event that spans multiple lines. In this case, it’s the reverse, the log file has all events in one line.</li><li>TIMESTAMP_FIELDS: Refers to <code>datetime</code> key in the <code>example.json</code>.</li><li>MAX_DAYS_AGO (optional): Specify the value if there are events older than 2,000 days.</li><li>TIME_FORMAT: Optional if Unix time is used, but recommended to specify whenever possible. When Unix time is used, it is not necessary to specify <code>%s%3N</code> when there is <a href="https://docs.splunk.com/Documentation/Splunk/latest/SearchReference/Commontimeformatvariables">subsecond</a>.</li></ul><p>The location of “props.conf” depends on whether the universal forwarder is centrally managed by a deployment server.</p><p>Path A: $SPLUNK_HOME&#x2F;etc&#x2F;deployment-apps&#x2F;foo&#x2F;local&#x2F;props.conf<br>Path B: $SPLUNK_HOME&#x2F;etc&#x2F;apps&#x2F;foo&#x2F;local&#x2F;props.conf</p><p>If there is a deployment server, then the config file should be in path A, in which the server will automatically deploy it to path B in the UF. If the UF is not centrally managed, it should head straight to path B.</p><h2 id="Search-head-props-conf">Search head props.conf <a href="#Search-head-props-conf" class="headerlink" title="Search head props.conf">§</a></h2><pre><div class="caption"><span>props.conf</span></div><code class="hljs conf">[app_a_event]description = App A logsKV_MODE = noneAUTO_KV_JSON = 0SHOULD_LINEMERGE = 0</code></pre><p>Since index-time field extraction is already enabled using <code>INDEXED_EXTRACTIONS</code>, search-time field extraction is no longer necessary. If <code>KV_MODE</code> and <code>AUTO_KV_JSON</code> are not disabled, there will be duplicate fields in the search result.</p><p>In Splunk Enterprise, the above file can be saved in a custom app, e.g. “$SPLUNK_HOME&#x2F;etc&#x2F;app&#x2F;custom-app&#x2F;default&#x2F;props.conf”</p><p>For Splunk Cloud deployment, the above configuration can be added through a custom app or Splunk Web: <strong>Settings &gt; <a href="https://docs.splunk.com/Documentation/SplunkCloud/latest/Data/Managesourcetypes">Source types</a></strong>.</p><h2 id="Ingesting-API-response">Ingesting API response <a href="#Ingesting-API-response" class="headerlink" title="Ingesting API response">§</a></h2><p>It is important to note <code>SEDCMD</code> <a href="https://www.aplura.com/assets/pdf/props_conf_order.pdf">runs</a> <a href="https://wiki.splunk.com/Community:HowIndexingWorks">after</a> <code>INDEXED_EXTRACTIONS</code>. I noticed <a href="https://community.splunk.com/t5/Getting-Data-In/SEDCMD-not-actually-replacing-data-during-indexing/m-p/387812/highlight/true#M69511">this behaviour</a> when I tried to ingest API response of <a href="https://gitlab.com/curben/splunk-scripts/-/tree/main/TA-librenms-data-poller?ref_type=heads">LibreNMS</a>.</p><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;status&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ok&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;devices&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;device_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key1&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key2&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value2&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;device_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key1&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key2&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value2&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;device_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key1&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;key2&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;value2&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;count&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">&#125;</span></code></pre><p>In this scenario, I only wanted to ingest “devices” array where each item is an event. The previous approach not only did not split the array, but “status” and “count” fields still existed in each event despite the use of SEDCMD to remove them.</p><p>The solution is not to use INDEXED_EXTRACTIONS (index-time field extraction), but use KV_MODE (search-time field extraction) instead. INDEXED_EXTRACTIONS is not enabled so that SEDCMD works more reliably.  If it’s enabled, the JSON parser can unpredictably split part of the prefix (in this case <code>&#123;&quot;status&quot;: &quot;ok&quot;, &quot;devices&quot;: [</code>) or suffix into separate events and SEDCMD does not work across events. SEDCMD does work with INDEXED_EXTRACTIONS, but you have to make sure the replacement is within an event</p><pre><div class="caption"><span>props.conf</span></div><code class="hljs conf"># heavy forwarder or indexer[api_a_response]description = API A response# remove bracket at the start and end of each lineSEDCMD-remove_prefix = s/^\&#123;&quot;status&quot;: &quot;ok&quot;, &quot;devices&quot;: \[//gSEDCMD-remove_suffix = s/\], &quot;count&quot;: [0-9]+\&#125;$//g# separate each object into a lineLINE_BREAKER = &#125;(, )&#123;\&quot;device_id\&quot;# if each line/event is very long# TRUNCATE = 0# a line represents an eventSHOULD_LINEMERGE = 0</code></pre><pre><div class="caption"><span>props.conf</span></div><code class="hljs conf"># search head[api_a_response]description = API A responseKV_MODE = jsonAUTO_KV_JSON = 1</code></pre>]]></content>
    
    
    <summary type="html">Parse single-line JSON into separate events</summary>
    
    
    
    <category term="splunk" scheme="https://mdleom.com/tags/splunk/"/>
    
  </entry>
  
  <entry>
    <title>Malicious website detection on Splunk using malware-filter</title>
    <link href="https://mdleom.com/blog/2023/04/16/splunk-lookup-malware-filter/"/>
    <id>https://mdleom.com/blog/2023/04/16/splunk-lookup-malware-filter/</id>
    <published>2023-04-16T00:00:00.000Z</published>
    <updated>2023-04-16T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://gitlab.com/malware-filter/splunk-malware-filter">Splunk Add-on for malware-filter</a> includes the following CSV files:</p><ul><li>botnet-filter-splunk.csv</li><li>botnet_ip.csv</li><li>opendbl_ip.csv</li><li>phishing-filter-splunk.csv</li><li>pup-filter-splunk.csv</li><li>urlhaus-filter-splunk-online.csv</li><li>vn-badsite-filter-splunk.csv</li></ul><p>These CSV files can be used as <a href="https://docs.splunk.com/Documentation/Splunk/latest/Knowledge/Aboutlookupsandfieldactions">lookups</a> to find potentially malicious traffic. They contain a list of bad IPs&#x2F;domains&#x2F;URLs and we are going to look for those values in the <a href="https://docs.splunk.com/Splexicon:Event">events</a>.</p><p>We can view the content of a lookup file by using <a href="https://docs.splunk.com/Documentation/Splunk/latest/SearchReference/Inputlookup"><code>inputlookup</code></a>. When using that command, there should always be a leading pipe character “|” because it is an <a href="https://docs.splunk.com/Splexicon:Generatingcommand">event-generating</a> command.</p><h2 id="Lookup-file-locations">Lookup file locations <a href="#Lookup-file-locations" class="headerlink" title="Lookup file locations">§</a></h2><p>Lookup file can be uploaded via <a href="https://docs.splunk.com/Documentation/Splunk/latest/Knowledge/Usefieldlookupstoaddinformationtoyourevents#Upload_the_lookup_table_file">Splunk Web</a> or creating the file in the following locations:</p><ul><li><code>$SPLUNK_HOME/etc/users/&lt;username&gt;/&lt;app_name&gt;/lookups/</code></li><li><code>$SPLUNK_HOME/etc/apps/&lt;app_name&gt;/lookups/</code></li><li><code>$SPLUNK_HOME/etc/system/lookups/</code></li></ul><p>In Splunk Web, setting the permission to app-sharing or global-sharing will automatically moves the file to the second or third location respectively. Uploaded lookup file can be used straight away without having to reload app or restart Splunk, regardless of which way it was created.</p><h2 id="inputlookup-basics">inputlookup basics <a href="#inputlookup-basics" class="headerlink" title="inputlookup basics">§</a></h2><pre><code class="hljs spl">| inputlookup botnet_ip.csv</code></pre><blockquote><p><code>_time</code> field is omitted for brevity.</p></blockquote><table><thead><tr><th>first_seen_utc</th><th>dst_ip</th><th>dst_port</th><th>c2_status</th><th>last_online</th><th>malware</th><th>updated</th></tr></thead><tbody><tr><td>2021-05-16 19:49:33</td><td>1.2.3.4</td><td>1234</td><td>online</td><td>2023-03-05</td><td>Lorem</td><td>2023-03-04T16:41:17Z</td></tr></tbody></table><p>The output is no different to any other event, we can specify which fields to be displayed and then rename the fields.</p><pre><code class="hljs spl">| inputlookup botnet_ip.csv | fields dst_ip | rename dst_ip AS dst</code></pre><table><thead><tr><th>dst</th></tr></thead><tbody><tr><td>178.128.23.9</td></tr></tbody></table><h2 id="Search-for-specific-events">Search for specific events <a href="#Search-for-specific-events" class="headerlink" title="Search for specific events">§</a></h2><p>Example firewall events:</p><pre><code class="hljs spl">index=firewall</code></pre><table><thead><tr><th>src</th><th>src_port</th><th>dst</th><th>action</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>45454</td><td>1.2.3.4</td><td>allowed</td></tr><tr><td>192.168.1.3</td><td>45452</td><td>7.6.5.4</td><td>allowed</td></tr><tr><td>192.168.1.4</td><td>45457</td><td>4.3.2.1</td><td>allowed</td></tr><tr><td>192.168.1.6</td><td>45451</td><td>7.7.5.5</td><td>allowed</td></tr></tbody></table><p>Notice the second row’s <code>dst</code> value matches <code>dst_port</code> value of the example lookup table shown in the <a href="#inputlookup-basics">previous section</a>.</p><p>To match for <code>dst</code> value of the firewall events and <code>dst_ip</code> of the lookup file, use a <a href="https://docs.splunk.com/Documentation/SplunkCloud/latest/SearchTutorial/Useasubsearch">subsearch</a> with <code>inputlookup</code>. In this example, the subsearch extracts only the <code>dst_ip</code> field and rename it to <code>dst</code> in order to match the same field in the firewall events.</p><pre><code class="hljs spl">index=firewall [| inputlookup botnet_ip.csv | fields dst_ip | rename dst_ip AS dst]</code></pre><table><thead><tr><th>src</th><th>src_port</th><th>dst</th><th>action</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>45454</td><td>1.2.3.4</td><td>allowed</td></tr></tbody></table><p>To display events in table format, append <code>| table *</code></p><h2 id="Wildcard">Wildcard <a href="#Wildcard" class="headerlink" title="Wildcard">§</a></h2><p>Asterisk character (<code>*</code>) in the lookup file does work as a <a href="https://docs.splunk.com/Documentation/SCS/current/Search/Wildcards">wildcard</a>.</p><pre><code class="hljs spl">index=proxy</code></pre><table><thead><tr><th>src</th><th>url</th><th>dst_port</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>foo.com&#x2F;path1</td><td>443</td></tr><tr><td>192.168.1.3</td><td>foo.com&#x2F;path2</td><td>443</td></tr><tr><td>192.168.1.4</td><td>bar.com&#x2F;path3</td><td>443</td></tr></tbody></table><p>The lookup files do not include wildcard affix.</p><pre><code class="hljs spl">| inputlookup urlhaus-filter-splunk-online.csv</code></pre><table><thead><tr><th>host</th><th>path</th><th>message</th><th>updated</th></tr></thead><tbody><tr><td>foo.com</td><td></td><td>urlhaus-filter malicious website detected</td><td>2023-03-13T00:11:20Z</td></tr></tbody></table><p>The add-on includes <a href="https://gitlab.com/malware-filter/splunk-malware-filter#geturlhausfilter"><code>geturlhausfilter</code></a> command along with other commands to update their respective lookup file. Those commands has <code>wildcard_suffix</code> argument to append wildcard to the field’s values.</p><pre><code class="hljs plaintext">| geturlhausfilter wildcard_suffix=host| outputlookup override_if_empty=false urlhaus-filter-splunk-online.csv</code></pre><table><thead><tr><th>host</th><th>path</th><th>message</th><th>updated</th><th>host_wildcard_suffix</th></tr></thead><tbody><tr><td>foo.com</td><td></td><td>urlhaus-filter malicious website detected</td><td>2023-03-13T00:11:20Z</td><td>foo.com*</td></tr></tbody></table><pre><code class="hljs spl">index=proxy [| inputlookup urlhaus-filter-splunk-online.csv | fields host_wildcard_suffix | rename host_wildcard_suffix AS url ]</code></pre><table><thead><tr><th>src</th><th>url</th><th>dst_port</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>foo.com&#x2F;path1</td><td>443</td></tr><tr><td>192.168.1.3</td><td>foo.com&#x2F;path2</td><td>443</td></tr></tbody></table><h3 id="Wildcard-prefix">Wildcard prefix <a href="#Wildcard-prefix" class="headerlink" title="Wildcard prefix">§</a></h3><p>Previous section showed an example using wildcard suffix (“foo.com*“). Wildcard also works as a prefix (“*foo.com”) or even in the middle (“f*o.com”), though these are <a href="https://docs.splunk.com/Documentation/SCS/current/Search/Wildcards#When_to_avoid_wildcard_characters">discouraged</a>.</p><pre><code class="hljs spl">index=proxy</code></pre><table><thead><tr><th>src</th><th>domain</th><th>dst_port</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>foo.com</td><td>443</td></tr><tr><td>192.168.1.3</td><td>lorem.foo.com</td><td>443</td></tr><tr><td>192.168.1.4</td><td>bar.com</td><td>443</td></tr></tbody></table><pre><code class="hljs spl">| geturlhausfilter wildcard_prefix=host| outputlookup override_if_empty=false urlhaus-filter-splunk-online.csv</code></pre><table><thead><tr><th>host</th><th>path</th><th>message</th><th>updated</th><th>host_wildcard_prefix</th></tr></thead><tbody><tr><td>foo.com</td><td></td><td>urlhaus-filter malicious website detected</td><td>2023-03-13T00:11:20Z</td><td>*foo.com</td></tr></tbody></table><pre><code class="hljs spl">index=proxy [| inputlookup urlhaus-filter-splunk-online.csv | fields host_wildcard_prefix | rename host_wildcard_prefix AS domain ]</code></pre><table><thead><tr><th>src</th><th>domain</th><th>dst_port</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>foo.com</td><td>443</td></tr><tr><td>192.168.1.3</td><td>lorem.foo.com</td><td>443</td></tr></tbody></table><h2 id="Matching-multiple-fields">Matching multiple fields <a href="#Matching-multiple-fields" class="headerlink" title="Matching multiple fields">§</a></h2><p>File hosting services like Google Docs and Dropbox are commonly abused to host phishing website. For those sites, the lookup should match both domain and path. When specifying more than one field in <code>fields</code> command, all fields will be matched using AND condition.</p><pre><code class="hljs spl">index=proxy</code></pre><table><thead><tr><th>src</th><th>domain</th><th>path</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>foo.com</td><td>document1.html</td></tr><tr><td>192.168.1.3</td><td>foo.com</td><td>document2.html</td></tr><tr><td>192.168.1.4</td><td>foo.com</td><td>document3.html</td></tr></tbody></table><pre><code class="hljs spl">| inputlookup urlhaus-filter-splunk-online.csv</code></pre><table><thead><tr><th>host</th><th>path</th><th>message</th><th>updated</th></tr></thead><tbody><tr><td>foo.com</td><td>document1.html</td><td>urlhaus-filter malicious website detected</td><td>2023-03-13T00:11:20Z</td></tr></tbody></table><pre><code class="hljs spl">index=proxy [| inputlookup urlhaus-filter-splunk-online.csv | fields host, path | rename host AS domain ]</code></pre><table><thead><tr><th>src</th><th>domain</th><th>path</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>foo.com</td><td>document1.html</td></tr></tbody></table><h3 id="Matching-individual-and-multiple-fields">Matching individual and multiple fields <a href="#Matching-individual-and-multiple-fields" class="headerlink" title="Matching individual and multiple fields">§</a></h3><p>A lookup file may have rows with empty <code>path</code> to denote a <code>domain</code> should be blocked regardless of paths, while also having rows with both <code>domain</code> and <code>path</code> to denote a specific URL should be blocked instead. The syntax is the same as what was shown in the <a href="#Matching-multiple-fields">previous section</a> because Splunk will only match <strong>non-empty</strong> values, empty values will be ignored instead.</p><pre><code class="hljs spl">index=proxy</code></pre><table><thead><tr><th>src</th><th>domain</th><th>path</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>bad-domain.com</td><td>lorem-ipsum.html</td></tr><tr><td>192.168.1.3</td><td>bad-domain.com</td><td>foo-bar.html</td></tr><tr><td>192.168.1.4</td><td>docs.google.com</td><td>malware.exe</td></tr><tr><td>192.168.1.4</td><td>docs.google.com</td><td>safe.doc</td></tr></tbody></table><pre><code class="hljs spl">| inputlookup urlhaus-filter-splunk-online.csv</code></pre><table><thead><tr><th>host</th><th>path</th><th>message</th><th>updated</th></tr></thead><tbody><tr><td>bad-domain.com</td><td></td><td>urlhaus-filter malicious website detected</td><td>2023-03-13T00:11:20Z</td></tr><tr><td>docs.google.com</td><td>malware.exe</td><td>urlhaus-filter malicious website detected</td><td>2023-03-13T00:11:20Z</td></tr></tbody></table><pre><code class="hljs spl">index=proxy [| inputlookup urlhaus-filter-splunk-online.csv | fields host, path | rename host AS domain ]</code></pre><table><thead><tr><th>src</th><th>domain</th><th>path</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>bad-domain.com</td><td>lorem-ipsum.html</td></tr><tr><td>192.168.1.3</td><td>bad-domain.com</td><td>foo-bar.html</td></tr><tr><td>192.168.1.4</td><td>docs.google.com</td><td>malware.exe</td></tr></tbody></table><h2 id="Case-insensitive">Case-insensitive <a href="#Case-insensitive" class="headerlink" title="Case-insensitive">§</a></h2><p>Lookup file is case-insensitive. If case-sensitive matching is required, use <code>lookup</code> and lookup definition.</p><pre><code class="hljs spl">index=proxy</code></pre><table><thead><tr><th>src</th><th>domain</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>loremipsum.com</td></tr></tbody></table><pre><code class="hljs spl">| inputlookup urlhaus-filter-splunk-online.csv</code></pre><table><thead><tr><th>host</th><th>path</th><th>message</th><th>updated</th></tr></thead><tbody><tr><td>lOrEmIpSuM.com</td><td></td><td>urlhaus-filter malicious website detected</td><td>2023-03-13T00:11:20Z</td></tr><tr><td>docs.google.com</td><td>malware.exe</td><td>urlhaus-filter malicious website detected</td><td>2023-03-13T00:11:20Z</td></tr></tbody></table><pre><code class="hljs spl">index=proxy [| inputlookup urlhaus-filter-splunk-online.csv | fields host, path | rename host AS domain ]</code></pre><table><thead><tr><th>src</th><th>domain</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>loremipsum.com</td></tr></tbody></table><h2 id="CIDR-matching">CIDR matching <a href="#CIDR-matching" class="headerlink" title="CIDR matching">§</a></h2><p>Splunk automatically detects CIDR-like value in a lookup file and performs CIDR-matching accordingly. However, this behaviour is on best-effort basis and may not work as intended. To explicitly use lookup fields for CIDR-matching, use <code>lookup</code> and lookup definition.</p><pre><code class="hljs spl">index=firewall</code></pre><table><thead><tr><th>src</th><th>src_port</th><th>dst</th><th>action</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>45454</td><td>187.190.252.167</td><td>allowed</td></tr><tr><td>192.168.1.3</td><td>45452</td><td>7.6.5.4</td><td>allowed</td></tr><tr><td>192.168.1.4</td><td>45457</td><td>4.3.2.1</td><td>allowed</td></tr><tr><td>192.168.1.6</td><td>45451</td><td>89.248.163.100</td><td>allowed</td></tr></tbody></table><pre><code class="hljs spl">| inputlookup opendbl_ip.csv</code></pre><table><thead><tr><th>start</th><th>end</th><th>netmask</th><th>cidr_range</th><th>name</th><th>updated</th></tr></thead><tbody><tr><td>187.190.252.167</td><td>187.190.252.167</td><td>32</td><td>187.190.252.167&#x2F;32</td><td>Emerging Threats: Known Compromised Hosts</td><td>2023-01-30T08:03:00Z</td></tr><tr><td>89.248.163.0</td><td>89.248.163.255</td><td>24</td><td>89.248.163.0&#x2F;24</td><td>Dshield</td><td>2023-01-30T08:01:00Z</td></tr></tbody></table><pre><code class="hljs spl">index=firewall [| inputlookup opendbl_ip.csv | fields cidr_range | rename cidr_range AS dst ]</code></pre><table><thead><tr><th>src</th><th>src_port</th><th>dst</th><th>action</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>45454</td><td>187.190.252.167</td><td>allowed</td></tr><tr><td>192.168.1.6</td><td>45451</td><td>89.248.163.100</td><td>allowed</td></tr></tbody></table><h2 id="inputlookup-lookup">inputlookup + lookup <a href="#inputlookup-lookup" class="headerlink" title="inputlookup + lookup">§</a></h2><p>When using as a subsearch, <code>inputlookup</code> filters the event data and only outputs rows with matching values of specified field(s). <code>lookup</code> enriches the event data by appending new fields to the rows with matching field values. Another way to understand the difference is that <code>inputlookup</code> performs <a href="https://en.wikipedia.org/wiki/Join_(SQL)#Inner_join">inner join</a> while <code>lookup</code> performs <a href="https://en.wikipedia.org/wiki/Join_(SQL)#Left_outer_join">left outer join</a> where the event data is the left table and the lookup file is the right table.</p><p>Despite their difference, it can be useful to use both at the same time to enrich filtered event data, even when using the same lookup file.</p><pre><code class="hljs spl">| inputlookup botnet_ip.csv</code></pre><blockquote><p><code>_time</code> field is omitted for brevity.</p></blockquote><table><thead><tr><th>first_seen_utc</th><th>dst_ip</th><th>dst_port</th><th>c2_status</th><th>last_online</th><th>malware</th><th>updated</th></tr></thead><tbody><tr><td>2021-05-16 19:49:33</td><td>1.2.3.4</td><td>1234</td><td>online</td><td>2023-03-05</td><td>Lorem</td><td>2023-03-04T16:41:17Z</td></tr><tr><td>2021-05-16 19:49:33</td><td>4.3.2.1</td><td>1234</td><td>online</td><td>2023-03-05</td><td>Ipsum</td><td>2023-03-04T16:41:17Z</td></tr></tbody></table><pre><code class="hljs spl">index=firewall</code></pre><table><thead><tr><th>src</th><th>src_port</th><th>dst</th><th>action</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>45454</td><td>1.2.3.4</td><td>allowed</td></tr><tr><td>192.168.1.3</td><td>45452</td><td>7.6.5.4</td><td>allowed</td></tr><tr><td>192.168.1.4</td><td>45457</td><td>4.3.2.1</td><td>allowed</td></tr><tr><td>192.168.1.6</td><td>45451</td><td>7.7.5.5</td><td>allowed</td></tr></tbody></table><pre><code class="hljs spl">index=firewall [| inputlookup botnet_ip.csv | fields dst_ip | rename dst_ip AS dst]</code></pre><table><thead><tr><th>src</th><th>src_port</th><th>dst</th><th>action</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>45454</td><td>1.2.3.4</td><td>allowed</td></tr><tr><td>192.168.1.3</td><td>45452</td><td>7.6.5.4</td><td>allowed</td></tr><tr><td>192.168.1.4</td><td>45457</td><td>4.3.2.1</td><td>allowed</td></tr><tr><td>192.168.1.6</td><td>45451</td><td>7.7.5.5</td><td>allowed</td></tr></tbody></table><pre><code class="hljs spl">index=firewall [| inputlookup botnet_ip.csv | fields dst_ip | rename dst_ip AS dst]| lookup botnet_ip.csv dst_ip AS dst OUTPUT c2_status, malware</code></pre><table><thead><tr><th>src</th><th>src_port</th><th>dst</th><th>action</th><th>c2_status</th><th>malware</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>45454</td><td>1.2.3.4</td><td>allowed</td><td>online</td><td>Lorem</td></tr><tr><td>192.168.1.4</td><td>45457</td><td>4.3.2.1</td><td>allowed</td><td>online</td><td>Ipsum</td></tr></tbody></table><p>It is also possible to rename lookup destination fields.</p><pre><code class="hljs spl">index=firewall [| inputlookup botnet_ip.csv | fields dst_ip | rename dst_ip AS dst]| lookup botnet_ip.csv dst_ip AS dst OUTPUT c2_status AS &quot;C2 Server Status&quot;, malware AS &quot;Malware Family&quot;</code></pre><table><thead><tr><th>src</th><th>src_port</th><th>dst</th><th>action</th><th>C2 Server Status</th><th>Malware Family</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>45454</td><td>1.2.3.4</td><td>allowed</td><td>online</td><td>Lorem</td></tr><tr><td>192.168.1.4</td><td>45457</td><td>4.3.2.1</td><td>allowed</td><td>online</td><td>Ipsum</td></tr></tbody></table><h2 id="Lookup-definition">Lookup definition <a href="#Lookup-definition" class="headerlink" title="Lookup definition">§</a></h2><p>Lookup definition provides matching rules for a lookup file. It can be configured for case-sensitivity, wildcard, CIDR-matching and others through <a href="https://docs.splunk.com/Documentation/Splunk/latest/Admin/Transformsconf">transforms.conf</a>. It can also be configured via Splunk Web: Settings → Lookups → Lookup definitions.</p><p>A bare minimum lookup definition is as such:</p><pre><div class="caption"><span>transforms.conf</span></div><code class="hljs conf">[lookup-definition-name]filename = lookup-filename.csv</code></pre><p>transforms.conf can be saved in the following directories in <a href="https://docs.splunk.com/Documentation/Splunk/latest/Admin/Wheretofindtheconfigurationfiles">order of priority</a> (highest to lowest):</p><ul><li><code>$SPLUNK_HOME/etc/users/&lt;username&gt;/&lt;app_name&gt;/local/</code></li><li><code>$SPLUNK_HOME/etc/apps/&lt;app_name&gt;/local/</code></li><li><code>$SPLUNK_HOME/etc/system/local/</code></li></ul><p>My naming convention for lookup definition is simply removing the <code>.csv</code> extension, e.g. “example.csv” (lookup file), “example” (lookup definition). While it is possible to name a lookup definition with file extension (“example.csv”), I discourage it to avoid confusion.</p><p>It is imperative to note that lookup definition only applies to <code>lookup</code> search command and does <em>not</em> apply to <code>inputlookup</code>. Although <code>inputlookup</code> supports lookup definition as a lookup table (in addition to lookup file), its matching rules will be ignored.</p><h3 id="Case-sensitive">Case-sensitive <a href="#Case-sensitive" class="headerlink" title="Case-sensitive">§</a></h3><pre><div class="caption"><span>transforms.conf</span></div><code class="hljs conf">[urlhaus-filter-splunk-online]filename = urlhaus-filter-splunk-online.csv# applies to all fieldscase_sensitive_match = 1</code></pre><pre><code class="hljs spl">index=proxy</code></pre><table><thead><tr><th>src</th><th>domain</th><th>path</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>bad-domain.com</td><td>lorem-ipsum.html</td></tr><tr><td>192.168.1.3</td><td>bad-domain.com</td><td>lOrEm-iPsUm.hTmL</td></tr></tbody></table><pre><code class="hljs spl">| inputlookup urlhaus-filter-splunk-online</code></pre><table><thead><tr><th>host</th><th>path</th><th>message</th><th>updated</th></tr></thead><tbody><tr><td>bad-domain.com</td><td>lorem-ipsum.html</td><td>urlhaus-filter malicious website detected</td><td>2023-03-13T00:11:20Z</td></tr></tbody></table><pre><code class="hljs spl">index=proxy| lookup urlhaus-filter-splunk-online host AS domain, path OUTPUT message</code></pre><table><thead><tr><th>src</th><th>domain</th><th>path</th><th>message</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>bad-domain.com</td><td>lorem-ipsum.html</td><td>urlhaus-filter malicious website detected</td></tr><tr><td>192.168.1.3</td><td>bad-domain.com</td><td>lOrEm-iPsUm.hTmL</td><td></td></tr></tbody></table><h3 id="Wildcard-lookup">Wildcard (lookup) <a href="#Wildcard-lookup" class="headerlink" title="Wildcard (lookup)">§</a></h3><pre><div class="caption"><span>transforms.conf</span></div><code class="hljs conf">[urlhaus-filter-splunk-online]filename = urlhaus-filter-splunk-online.csvmatch_type = WILDCARD(host_wildcard_suffix)</code></pre><pre><code class="hljs spl">index=proxy</code></pre><table><thead><tr><th>src</th><th>url</th><th>dst_port</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>foo.com&#x2F;path1</td><td>443</td></tr><tr><td>192.168.1.3</td><td>foo.com&#x2F;path2</td><td>443</td></tr><tr><td>192.168.1.4</td><td>bar.com&#x2F;path3</td><td>443</td></tr></tbody></table><p>The lookup files do not include wildcard affix.</p><pre><code class="hljs spl">| inputlookup urlhaus-filter-splunk-online</code></pre><table><thead><tr><th>host</th><th>path</th><th>message</th><th>updated</th><th>host_wildcard_suffix</th></tr></thead><tbody><tr><td>foo.com</td><td></td><td>urlhaus-filter malicious website detected</td><td>2023-03-13T00:11:20Z</td><td>foo.com*</td></tr></tbody></table><pre><code class="hljs spl">index=proxy| lookup urlhaus-filter-splunk-online host_wildcard_suffix AS url OUTPUT message</code></pre><table><thead><tr><th>src</th><th>url</th><th>dst_port</th><th>message</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>foo.com&#x2F;path1</td><td>443</td><td>urlhaus-filter malicious website detected</td></tr><tr><td>192.168.1.3</td><td>foo.com&#x2F;path2</td><td>443</td><td>urlhaus-filter malicious website detected</td></tr></tbody></table><h3 id="CIDR-matching-lookup">CIDR-matching (lookup) <a href="#CIDR-matching-lookup" class="headerlink" title="CIDR-matching (lookup)">§</a></h3><pre><div class="caption"><span>transforms.conf</span></div><code class="hljs conf">[opendbl_ip]filename = opendbl_ip.csvmatch_type = CIDR(cidr_range)</code></pre><pre><code class="hljs spl">index=firewall</code></pre><table><thead><tr><th>src</th><th>src_port</th><th>dst</th><th>action</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>45454</td><td>187.190.252.167</td><td>allowed</td></tr><tr><td>192.168.1.3</td><td>45452</td><td>7.6.5.4</td><td>allowed</td></tr><tr><td>192.168.1.4</td><td>45457</td><td>4.3.2.1</td><td>allowed</td></tr><tr><td>192.168.1.6</td><td>45451</td><td>89.248.163.100</td><td>allowed</td></tr></tbody></table><pre><code class="hljs spl">| inputlookup opendbl_ip</code></pre><table><thead><tr><th>start</th><th>end</th><th>netmask</th><th>cidr_range</th><th>name</th><th>updated</th></tr></thead><tbody><tr><td>187.190.252.167</td><td>187.190.252.167</td><td>32</td><td>187.190.252.167&#x2F;32</td><td>Emerging Threats: Known Compromised Hosts</td><td>2023-01-30T08:03:00Z</td></tr><tr><td>89.248.163.0</td><td>89.248.163.255</td><td>24</td><td>89.248.163.0&#x2F;24</td><td>Dshield</td><td>2023-01-30T08:01:00Z</td></tr></tbody></table><pre><code class="hljs spl">index=firewall| lookup opendbl_ip cidr_range AS dst OUTPUT name AS threat</code></pre><table><thead><tr><th>src</th><th>src_port</th><th>dst</th><th>action</th><th>threat</th></tr></thead><tbody><tr><td>192.168.1.5</td><td>45454</td><td>187.190.252.167</td><td>allowed</td><td>Emerging Threats: Known Compromised Hosts</td></tr><tr><td>192.168.1.3</td><td>45452</td><td>7.6.5.4</td><td>allowed</td><td></td></tr><tr><td>192.168.1.4</td><td>45457</td><td>4.3.2.1</td><td>allowed</td><td></td></tr><tr><td>192.168.1.6</td><td>45451</td><td>89.248.163.100</td><td>allowed</td><td>Dshield</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">A guide on using malware-filter lookups</summary>
    
    
    
    <category term="splunk" scheme="https://mdleom.com/tags/splunk/"/>
    
  </entry>
  
  <entry>
    <title>SSH certificate using Cloudflare Tunnel</title>
    <link href="https://mdleom.com/blog/2023/02/13/ssh-certificate-cloudflare-tunnel/"/>
    <id>https://mdleom.com/blog/2023/02/13/ssh-certificate-cloudflare-tunnel/</id>
    <published>2023-02-13T00:00:00.000Z</published>
    <updated>2023-02-21T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>This article provides a quick-start guide to SSH certificate using Cloudflare Tunnel. More information can be found in the official docs.</p><ul><li><a href="https://blog.cloudflare.com/public-keys-are-not-enough-for-ssh-security/">Public keys are not enough for SSH security</a></li><li><a href="https://developers.cloudflare.com/cloudflare-one/tutorials/ssh-cert-bastion/">SSH with short-lived certificates</a></li><li><a href="https://developers.cloudflare.com/cloudflare-one/identity/users/short-lived-certificates/">Configure short-lived certificates</a></li><li><a href="https://developers.cloudflare.com/cloudflare-one/applications/configure-apps/self-hosted-apps/">Self-hosted applications</a></li><li><a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/use_cases/ssh/">Connect with SSH through Cloudflare Tunnel</a></li></ul><h2 id="Introduction">Introduction <a href="#Introduction" class="headerlink" title="Introduction">§</a></h2><p>One unpleasant task I had previously in an enterprise with Linux servers was SSH key management, specifically checking the SSH public keys of departed staff have been removed from the Ansible config. Then I learned from <a href="https://smallstep.com/blog/use-ssh-certificates/">this article</a> that it is possible to SSH using a short-lived (&lt;1 day) certificate that is only issued to the user after successfully authenticate with the enterprise identity provider’s (e.g. Azure AD) single sign-on (SSO). This means once a user is revoked from the identity provider, that user would not be issued with a new certificate to SSH again the next day. At that time, I didn’t feel like configuring and integrating an identity provider, so I held off trying the feature.</p><p>Recently, I wanted to try out the Cloudflare Zero Trust free tier. While reading through the <a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/use_cases/ssh/">SSH configuration</a> guide, I found out that Cloudflare support issuing <a href="https://developers.cloudflare.com/cloudflare-one/identity/users/short-lived-certificates/">SSH user certificate</a>. While Cloudflare supports several <a href="https://developers.cloudflare.com/cloudflare-one/identity/idp-integration/">SSO integration</a>, it also supports authenticating using <a href="https://developers.cloudflare.com/cloudflare-one/identity/one-time-pin/">one-time PIN</a> sent to an email address that does not have to be a Cloudflare account. Cloudflare also supports browser-based shell, just like the AWS <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager.html">Session Manager</a>.</p><h2 id="Prerequisites">Prerequisites <a href="#Prerequisites" class="headerlink" title="Prerequisites">§</a></h2><ul><li>A domain hosted on Cloudflare DNS</li><li>Cloudflare Zero Trust (free for 50 users)</li><li>A VM or cloud instance (optional, easier to clean up)</li></ul><h2 id="Cloudflare-Zero-Trust">Cloudflare Zero Trust <a href="#Cloudflare-Zero-Trust" class="headerlink" title="Cloudflare Zero Trust">§</a></h2><p>Navigate to <strong>Zero Trust</strong> page shown on the sidebar after you login to <a href="https://dash.cloudflare.com/">dash.cloudflare.com</a>. If this is your first time, Cloudflare will ask for billing info in which you can use an existing one or add a new credit card. You won’t get charged as long as you stay within the <strong>free tier</strong> (50 users), I will show you how to check later in this article.</p><p>The setup will then ask you to name your team domain <em>team-name</em>.cloudflareaccess.com. Just create a random name for now, you can always change it later.</p><h2 id="Add-an-application">Add an application <a href="#Add-an-application" class="headerlink" title="Add an application">§</a></h2><p>Once you’re in Zero Trust console, navigate to <strong>Access</strong> → <strong>Applications</strong>. <strong>Add an application</strong> and choose <strong>Self-hosted</strong>.</p><p><strong>Configure app</strong> tab,</p><ul><li>Application name: any name</li><li>Session duration: 15 minutes.<ul><li>In a corporate environment, “6 hours” is probably more user-friendly.</li><li>For sensitive server, consider “No duration”.</li></ul></li><li>Application domain: test.yourdomain.com<ul><li>The subdomain should not have an existing website.</li><li>It may be possible to use an existing website, by specifying test.yourdomain.com&#x2F;custom-path for SSH, though I haven’t try it.</li></ul></li><li>App Launcher visbility: No</li><li>Accept all available identity providers: No, unless you have integrated an identity provider.</li><li>Select One-time PIN</li><li>Instant Auth: Yes</li></ul><p><strong>Add policies</strong> tab,</p><ul><li>Policy name: any name</li><li>Action: Allow</li><li>Session duration: same</li><li>Configure rules: (Include) Emails &#x3D; an email address<ul><li>Any of your email is fine, regardless whether it’s a Cloudflare account.</li><li>Cloudflare <em>will not</em> create an account using that email, it will only be used to receive one-time PIN.</li></ul></li></ul><p><strong>Setup</strong> tab:</p><ul><li>CORS settings: leave it as is</li><li>Cookies settings:<ul><li>SameSite Attribute: blank or Lax<ul><li>Either setting is practically the same, browsers default to Lax when SameSite is not set.</li><li>“Strict” value cannot be used because Cloudflare will authenticate the user on <em>team-name</em>.cloudflareaccess.com and issue a cookie on test.yourdomain.com.</li></ul></li><li>HTTP Only: Yes</li></ul></li><li>Additional settings:<ul><li>Enable automatic cloudflared authentication: Yes</li><li>Browser rendering: SSH</li></ul></li></ul><h2 id="Generate-a-CA-certificate">Generate a CA certificate <a href="#Generate-a-CA-certificate" class="headerlink" title="Generate a CA certificate">§</a></h2><p>Navigate to <strong>Access</strong> → <strong>Service Auth</strong> → <strong>SSH</strong> tab. Select the application you just created and <strong>Generate certificate</strong>.</p><p>Copy the generated public key and save it to <code>/etc/ssh/ca.pub</code> in your host (the host you’re going to SSH into).</p><pre><code class="hljs plaintext">sudo -e /etc/ssh/ca.pub</code></pre><h2 id="Create-a-tunnel">Create a tunnel <a href="#Create-a-tunnel" class="headerlink" title="Create a tunnel">§</a></h2><p>Navigate to <strong>Access</strong> → <strong>Tunnels</strong></p><ul><li>Name: any name</li></ul><p><strong>Install connector</strong> tab, choose the relevant OS and run the installation command. Once installed, you should see “connected” status.</p><p><strong>Route tunnel</strong> tab,</p><ul><li>Public hostname: test.yourdomain.com<ul><li>This is the application domain in the <a href="#Add-an-application">Add an application</a> step.</li></ul></li><li>Service<ul><li>SSH type: URL &#x3D; localhost:22<ul><li>Replace 22 with the custom SSH port you are going to use.</li></ul></li></ul></li></ul><p>After finishing creating a tunnel, you should have a new CNAME DNS record that points to <em>tunnel-id</em>.cfargotunnel.com. If there is no CNAME entry, grab the tunnel ID and create a new DNS record.</p><h2 id="Start-SSH-server">Start SSH server <a href="#Start-SSH-server" class="headerlink" title="Start SSH server">§</a></h2><p>Install <code>openssh-server</code>.</p><p><code>sudo -e /etc/ssh/sshd_config.d/cf.conf</code></p><pre><div class="caption"><span>/etc/ssh/sshd_config.d/cf.conf</span></div><code class="hljs plain">TrustedUserCAKeys /etc/ssh/ca.pubListenAddress 127.0.0.1ListenAddress ::1PasswordAuthentication no# Uncomment below line for custom port# Port 1234</code></pre><p><code>systemctl restart ssh</code> or <code>systemctl restart sshd</code></p><h2 id="Create-a-test-user">Create a test user <a href="#Create-a-test-user" class="headerlink" title="Create a test user">§</a></h2><p>The easiest setup is one where a Unix username matches the email that you configured to receive one-time PIN in previous steps. For example, if you set <strong>loremipsum</strong>@youremail.com, then create a new user <strong>loremipsum</strong>.</p><p><code>sudo adduser loremipsum</code></p><p>Set a random password and leave everything else blank.</p><h3 id="Matching-email-to-different-username">Matching email to different username <a href="#Matching-email-to-different-username" class="headerlink" title="Matching email to different username">§</a></h3><p>To match <strong>loremipsum</strong>@youremail.com to <strong>lipsum</strong> user:</p><pre><div class="caption"><span>/etc/ssh/sshd_config.d/cf.conf</span></div><code class="hljs plain">Match user lipsum  AuthorizedPrincipalsCommand /bin/echo &#x27;loremipsum&#x27;  AuthorizedPrincipalsCommandUser nobody</code></pre><p><strong>loremipsum+somealias</strong>@youremail.com also works.</p><pre><div class="caption"><span>/etc/ssh/sshd_config.d/cf.conf</span></div><code class="hljs plain">Match user lipsum  AuthorizedPrincipalsCommand /bin/echo &#x27;loremipsum+somealias&#x27;  AuthorizedPrincipalsCommandUser nobody</code></pre><h3 id="AuthorizedPrincipalsFile">AuthorizedPrincipalsFile <a href="#AuthorizedPrincipalsFile" class="headerlink" title="AuthorizedPrincipalsFile">§</a></h3><p>For NixOS user, <code>AuthorizedPrincipalsCommand</code> will not work because the command will run within “&#x2F;nix&#x2F;store” but it is read-only. Instead, you should use <code>AuthorizedPrincipalsFile</code>. This config also enables you to match multiple emails to a username, just separate each email user by newline. This applies to all OpenSSH instances, not just NixOS.</p><p><code>echo &#39;loremipsum&#39; | sudo tee /etc/ssh/authorized_principals</code></p><pre><div class="caption"><span>/etc/nixos/configuration.nix</span></div><code class="hljs nix">  services.<span class="hljs-attr">openssh</span> = &#123;    <span class="hljs-attr">enable</span> = <span class="hljs-literal">true</span>;    <span class="hljs-attr">permitRootLogin</span> = <span class="hljs-string">&quot;no&quot;</span>;    <span class="hljs-attr">passwordAuthentication</span> = <span class="hljs-literal">false</span>;    <span class="hljs-comment"># ports = [ 1234 ];</span>    <span class="hljs-attr">extraConfig</span> =      <span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">        TrustedUserCAKeys /etc/ssh/ca.pub</span><span class="hljs-string">        Match User lipsum</span><span class="hljs-string">          AuthorizedPrincipalsFile /etc/ssh/authorized_principals</span><span class="hljs-string">          # if there is no existing AuthenticationMethods</span><span class="hljs-string">          AuthenticationMethods publickey</span><span class="hljs-string">      &#x27;&#x27;</span>;  &#125;;```<span class="hljs-comment">### Other use cases</span>https://developers.cloudflare.com/cloudflare-one/identity/users/short-lived-certificates/<span class="hljs-comment">#2-ensure-unix-usernames-match-user-sso-identities</span><span class="hljs-comment">## Initiate SSH connection</span>Install `cloudflared` on the host that you&#x27;re going to SSH from.`cloudflared access ssh-config --hostname test.yourdomain.com --short-lived-cert`Example output:```plain ~/.ssh/configMatch host test.yourdomain.com exec <span class="hljs-string">&quot;/usr/local/bin/cloudflared access ssh-gen --hostname %h&quot;</span>    ProxyCommand /usr/local/bin/cloudflared access ssh --hostname %h    IdentityFile ~/.cloudflared/%h-cf_key    CertificateFile ~/.cloudflared/%h-cf_key-cert.pub</code></pre><p>or</p><pre><div class="caption"><span>~/.ssh/config</span></div><code class="hljs plain">Host test.yourdomain.com    ProxyCommand bash -c &#x27;/usr/local/bin/cloudflared access ssh-gen --hostname %h; ssh -tt %r@cfpipe-test.yourdomain.com &gt;&amp;2 &lt;&amp;1&#x27;Host cfpipe-test.yourdomain.com    HostName test.yourdomain.com    ProxyCommand /usr/local/bin/cloudflared access ssh --hostname %h    IdentityFile ~/.cloudflared/test.yourdomain.com-cf_key    CertificateFile ~/.cloudflared/test.yourdomain.com-cf_key-cert.pub</code></pre><p>Save the output to <code>$HOME/.ssh/config</code>.</p><p>Now, the moment of truth.</p><p><code>ssh loremipsum@test.yourdomain.com</code> (replace the username with the one you created in <a href="#Create-a-test-user">Create a test user</a> step.)</p><p>The terminal should launch a website to <em>team-name</em>.cloudflareaccess.com. Enter the email you configured in <a href="#Add-an-application">Add an application</a> step and then enter the received 6-digit PIN.</p><p>Back to the terminal, wait for at least 5 seconds and you should see the usual SSH authentication.</p><blockquote><p>You may wondering why you still see fingerprint warning, I find this article <a href="https://goteleport.com/blog/how-to-ssh-properly/">SSH Best Practices using Certificates, 2FA and Bastions</a> explains it well.</p></blockquote><h2 id="Browser-based-shell">Browser-based shell <a href="#Browser-based-shell" class="headerlink" title="Browser-based shell">§</a></h2><p>As a bonus, head to test.yourdomain.com (see <a href="#Add-an-application">Add an application</a> step) which will redirect you to a login page just the previous step. After login with a 6-digit PIN, you shall see a browser-based shell.</p><h2 id="Usage-monitoring">Usage monitoring <a href="#Usage-monitoring" class="headerlink" title="Usage monitoring">§</a></h2><p>Head to <strong>Settings</strong> → <strong>Account</strong> to monitor how many users you have, each email address you configured to receive one-time PIN is counted as one user.</p><p>To delete user(s), head to <strong>Users</strong>, tick the relevant users, <strong>Update status</strong> and then <strong>Remove</strong>. The seat usage column should show <em>Inactive</em>.</p><h2 id="Inspect-user-certificate">Inspect user certificate <a href="#Inspect-user-certificate" class="headerlink" title="Inspect user certificate">§</a></h2><p><code>ssh-keygen -L -f ~/.cloudflared/test.yourdomain.com-cf_key-cert.pub</code></p>]]></content>
    
    
    <summary type="html">A quick quide to SSH certificate without using an identity provider.</summary>
    
    
    
    <category term="cloudflare" scheme="https://mdleom.com/tags/cloudflare/"/>
    
  </entry>
  
  <entry>
    <title>Enable LUKS2 and Argon2 support for Grub in Manjaro/Arch</title>
    <link href="https://mdleom.com/blog/2022/11/27/grub-luks2-argon2/"/>
    <id>https://mdleom.com/blog/2022/11/27/grub-luks2-argon2/</id>
    <published>2022-11-27T00:00:00.000Z</published>
    <updated>2022-11-27T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>I recently refreshed my Manjaro installation using the official ISO. My last installation used Manjaro Architect, which is my preferred method. Unfortunately, it was removed from all official ISOs due to lack of maintainer. I tried installing it in Live USB but it couldn’t install some base packages due to keyring issue, same issue with the <a href="https://github.com/manjaro-architect/download/releases">nightly ISO</a>. As such, I had to use the GUI installer instead.</p><p>I ticked “Encrypt system” and Manjaro created two partitions in my NVMe drive <em>without</em> LVM. <a href="https://wiki.archlinux.org/title/btrfs#Subvolumes">Btrfs subvolume</a> can provide LVM-like functionality.</p><table><thead><tr><th>Partition</th><th>Filesystem</th><th>Mount</th><th>Encrypted</th></tr></thead><tbody><tr><td>&#x2F;dev&#x2F;nvme0n1p1</td><td>FAT32</td><td><code>/boot/efi</code></td><td>No</td></tr><tr><td>&#x2F;dev&#x2F;nvme0n1p2</td><td>Btrfs</td><td><code>/</code></td><td>LUKS1</td></tr></tbody></table><p>The implication of the above layout is that <code>/boot</code> (where the kernel resides) is encrypted, except for <code>/boot/efi</code> (Grub resides here)—p1 is not encrypted, p2 is LUKS-encrypted. So, Grub has to unlock the LUKS partition first (using password), before the rest of <code>/</code> can be unlocked (using keyfile). Keyfile is used in this layout so that password is not <a href="https://leo3418.github.io/collections/gentoo-config-luks2-grub-systemd/auto-unlock.html">prompted twice</a>.</p><p>There are two disadvantages of using Grub to unlock LUKS:</p><ol><li>Slow unlocking due to lack of cryptography acceleration</li><li>Limited LUKS2 support, i.e. Argon2 is not supported</li></ol><p>Fortunately, there is an AUR package <a href="https://aur.archlinux.org/packages/grub-improved-luks2-git">grub-improved-luks2-git</a> that has been patched for Argon2 support. I will also show how to tune Argon2 parameters for faster unlock (while sacrificing security).</p><h2 id="Prerequisite">Prerequisite <a href="#Prerequisite" class="headerlink" title="Prerequisite">§</a></h2><ul><li>Manjaro&#x2F;Arch live USB&#x2F;CD, for offline (unmounted) LUKS1 to LUKS2 keyslot conversion<ul><li>Keyslot technically can be updated in mounted partition since it is only used to unlock the encryption key, once unlocked, subsequent data encryption&#x2F;decryption uses only the encryption key.</li><li>I just feel uneasy doing this while the partition has active I&#x2F;O, so I opt for live USB instead.</li></ul></li></ul><h2 id="grub-improved-luks2-git">grub-improved-luks2-git <a href="#grub-improved-luks2-git" class="headerlink" title="grub-improved-luks2-git">§</a></h2><p>Use your favourite AUR helper to install <a href="https://aur.archlinux.org/packages/grub-improved-luks2-git">grub-improved-luks2-git</a>. This will take a while to compile patched Grub.</p><pre><code class="hljs plaintext">yay -S grub-improved-luks2-git</code></pre><p>There should be a confirmation to remove <code>grub</code> to avoid package conflict.</p><h2 id="Live-USB">Live USB <a href="#Live-USB" class="headerlink" title="Live USB">§</a></h2><p>Reboot into live USB. Identify the location of encrypted location using GParted. The partition filesystem should be “[Encrypted] btrfs”. In my case, it is <code>/dev/nvme0n1p2</code>.</p><h2 id="LUKS1-to-LUKS2-conversion">LUKS1 to LUKS2 conversion <a href="#LUKS1-to-LUKS2-conversion" class="headerlink" title="LUKS1 to LUKS2 conversion">§</a></h2><pre><code class="hljs plaintext">sudo cryptsetup convert --type luks2 /dev/nvme0n1p2</code></pre><p><em>If you want to revert back to LUKS1,</em></p><pre><code class="hljs plaintext">sudo cryptsetup convert --type luks1 /dev/nvme0n1p2</code></pre><p><em>Before reverting back to LUKS1, the keyslot must be using PBKDF2 not Argon2, otherwise you will encounter “Cannot convert to LUKS1 format” error.</em></p><pre><code class="hljs plaintext">sudo cryptsetup luksConvertKey --pbkdf pbkdf2 /dev/nvme0n1p2</code></pre><h2 id="Load-LUKS2-Grub-module">Load LUKS2 Grub module <a href="#Load-LUKS2-Grub-module" class="headerlink" title="Load LUKS2 Grub module">§</a></h2><p>At this stage, the Grub bootloader (not the package) cannot unlock the LUKS2 partition yet. It needs to be reinstalled so that it can detect LUKS2 partition and load the relevant module.</p><p>First, unlock the partition and mount it.</p><pre><code class="hljs plaintext">sudo cryptsetup open /dev/nvme0n1p2 rootsudo mount -o subvol=@ /dev/mapper/root /mntsudo mount /dev/nvme0n1p1 /mnt/boot/efi</code></pre><p>Notice in the “grub.cfg”, it loads <code>luks</code> module instead of <code>luks2</code>, this explains why Grub couldn’t unlock it.</p><pre><code class="hljs plaintext">$ sudo less /mnt/boot/grub/grub.cfgmenuentry &#x27;Manjaro Linux&#x27; &#123;  insmod luks&#125;</code></pre><p>While you <em>could</em> manually update the config and replace <code>luks</code> with <code>luks2</code>, it is better to automate it using <code>grub-mkconfig</code>.</p><pre><code class="hljs plaintext">sudo manjaro-chroot /mnt /bin/bash# or `sudo arch-chroot /mnt /bin/bash`grub-install --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=manjaro --recheckgrub-mkconfig -o /boot/grub/grub.cfg</code></pre><p>Now, inspect “grub.cfg” again while still in chroot, you should see <code>luks2</code> instead.</p><pre><code class="hljs plaintext">$ less /boot/grub/grub.cfgmenuentry &#x27;Manjaro Linux&#x27; &#123;  insmod luks2&#125;</code></pre><h2 id="Verify-LUKS2-unlock">Verify LUKS2 unlock <a href="#Verify-LUKS2-unlock" class="headerlink" title="Verify LUKS2 unlock">§</a></h2><p>Before proceed to the next step, I recommend reboot into your Manjaro&#x2F;Arch to check whether Grub can unlock LUKS2. Once that is done, reboot again to live USB.</p><h2 id="PBKDF2-to-Argon2">PBKDF2 to Argon2 <a href="#PBKDF2-to-Argon2" class="headerlink" title="PBKDF2 to Argon2">§</a></h2><p><em>This step should be done in live USB</em></p><p>All keyslot parameters are retained during conversion to LUKS2, so the pbkdf algorithm is still PBKDF2 + SHA256. To convert to Argon2 + SHA512,</p><pre><code class="hljs plaintext">sudo cryptsetup luksConvertKey --pbkdf argon2id --hash sha512 /dev/nvme0n1p2</code></pre><p>You may notice <code>insmod gcry_sha256</code> line in the “grub.cfg”, this module is not used for LUKS2 unlocking, so there is no need to add <code>insmod gcry_sha512</code>. As long as <code>insmod luks2</code> is there, Grub should be able to unlock LUKS2 regardless of pbkdf or hash algorithm.</p><h2 id="Enable-TRIM-and-disable-workqueue-for-SSD-performance-optional">Enable TRIM and disable workqueue for SSD performance (optional) <a href="#Enable-TRIM-and-disable-workqueue-for-SSD-performance-optional" class="headerlink" title="Enable TRIM and disable workqueue for SSD performance (optional)">§</a></h2><p><em>Still in live USB</em></p><pre><code class="hljs plaintext">sudo cryptsetup --allow-discards --perf-no_read_workqueue --perf-no_write_workqueue --persistent open /dev/nvme0n1p2 root</code></pre><p>Verify the flags are set.</p><pre><code class="hljs plaintext">$ sudo cryptsetup luksDump /dev/nvme0n1p2 | grep FlagsFlags:         allow-discards no-read-workqueue no-write-workqueue</code></pre><p>More details:</p><ul><li><a href="https://wiki.archlinux.org/title/Dm-crypt/Specialties#Discard/TRIM_support_for_solid_state_drives_(SSD)">SSD TRIM</a></li><li><a href="https://wiki.archlinux.org/title/Dm-crypt/Specialties#Disable_workqueue_for_increased_solid_state_drive_(SSD)_performance">Workqueue</a></li></ul><h2 id="Faster-unlock-in-Grub">Faster unlock in Grub <a href="#Faster-unlock-in-Grub" class="headerlink" title="Faster unlock in Grub">§</a></h2><p><em>This step can be done while the drive is mounted (as in not in live USB)</em></p><p>Due to lack of cryptography acceleration, Grub takes half a minute to unlock LUKS. For faster unlock, Argon2 parameters can be tuned to <em>less security</em>.</p><p>To start off, have a try with these parameters:</p><ul><li>4 iterations</li><li>256MB memory cost</li></ul><pre><code class="hljs plaintext">sudo cryptsetup luksConvertKey /dev/nvme0n1p2 --pbkdf-force-iterations 4 --pbkdf-memory 262100sudo cryptsetup luksConvertKey /dev/nvme0n1p2 --pbkdf-force-iterations 4 --pbkdf-memory 262100 --key-file /crypto_keyfile.bin</code></pre><p><a href="https://leo3418.github.io/collections/gentoo-config-luks2-grub-systemd/tune-parameters.html#change-the-parameters">This page</a> explains why keyfile also needs to be updated.</p><p>Reboot and check how fast is the unlock. Fine tune the <code>--pbkdf-memory</code> option until the unlock speed is satisfactory (not too slow and not too fast). The option takes a value in kilobyte (KB).</p><table><thead><tr><th>MB</th><th>KB</th></tr></thead><tbody><tr><td>128</td><td>131100</td></tr><tr><td>256</td><td>262100</td></tr><tr><td>512</td><td>524300</td></tr><tr><td>1024</td><td>1049000</td></tr></tbody></table><h2 id="References">References <a href="#References" class="headerlink" title="References">§</a></h2><ul><li><a href="https://wiki.archlinux.org/title/Dm-crypt/Encrypting_an_entire_system">Dm-crypt&#x2F;Encrypting_an_entire_system</a></li><li><a href="https://leo3418.github.io/collections/gentoo-config-luks2-grub-systemd.html">Gentoo Configuration Guide</a></li><li><a href="https://wiki.manjaro.org/index.php/GRUB/Restore_the_GRUB_Bootloader">Restore the GRUB Bootloader</a></li></ul>]]></content>
    
    
    <summary type="html">Convert LUKS1 to LUKS2</summary>
    
    
    
    <category term="linux" scheme="https://mdleom.com/tags/linux/"/>
    
    <category term="manjaro" scheme="https://mdleom.com/tags/manjaro/"/>
    
    <category term="arch" scheme="https://mdleom.com/tags/arch/"/>
    
    <category term="luks" scheme="https://mdleom.com/tags/luks/"/>
    
  </entry>
  
  <entry>
    <title>Bulk remove old GitLab CI job artifacts</title>
    <link href="https://mdleom.com/blog/2022/08/09/remove-gitlab-artifacts/"/>
    <id>https://mdleom.com/blog/2022/08/09/remove-gitlab-artifacts/</id>
    <published>2022-08-09T00:00:00.000Z</published>
    <updated>2022-08-09T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>On 8 Aug 2022, GitLab <a href="https://docs.gitlab.com/ee/user/usage_quotas.html#namespace-storage-limit-enforcement-schedule">announced</a> they will enforce 5 GB storage quota on free account from 9 November 2022. My <a href="https://gitlab.com/malware-filter">malware-filter</a> group was using 25.3 GB prior to a cleanup where some projects were more than 5 GB. I did apply malware-filter for GitLab for <a href="https://about.gitlab.com/solutions/open-source/join/">Open Source Program</a>, so I get Ultimate tier with 250 GB storage limit (per project). While I’m still far off from the storage limit, I still went ahead to clean them up in case they reduce storage quota for Open Source Program.</p><h2 id="Expire-new-job-artifacts">Expire new job artifacts <a href="#Expire-new-job-artifacts" class="headerlink" title="Expire new job artifacts">§</a></h2><p>In all my projects that were using more than 5 GB, 99% of the usage came from job artifacts. I believe most of the cases are like this. The first thing I did was to set <em>new</em> job artifacts to expire in a week, the default is <a href="https://docs.gitlab.com/ee/user/gitlab_com/index.html#gitlab-cicd">30 days</a>. Existing job artifacts are not affected by this setting.</p><p>If your job artifacts created in a month are much less than 5 GB in total yet still exceed the quota, it is likely caused by very old artifacts which have no expiry. In that case, reducing the default expiry may not be relevant, those old artifacts should be removed instead.</p><pre><div class="caption"><span>.gitlab-ci.yml</span></div><code class="hljs diff">build:  artifacts:    paths:      - public/<span class="hljs-addition">+    expire_in: 1 week</span></code></pre><h2 id="Remove-old-job-artifacts">Remove old job artifacts <a href="#Remove-old-job-artifacts" class="headerlink" title="Remove old job artifacts">§</a></h2><p>As for cleaning up existing job artifacts, I found the following bash script on the GitLab forum. I fixed some variable typo and modified the starting page to “2”, all job artifacts will be removed except for the first page, retaining 100 most recent job artifacts. The only dependencies are <strong>curl</strong> and <strong>jq</strong>.</p><p>This script is especially useful for removing job artifacts were created before 22 Jun 2020, artifacts created before that date do not expire.</p><pre><div class="caption"><span>cleanup-gitlab.sh</span><a href="https://forum.gitlab.com/t/remove-all-artifact-no-expire-options/9274/12">source</a></div><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><span class="hljs-comment"># https://forum.gitlab.com/t/remove-all-artifact-no-expire-options/9274/12</span><span class="hljs-comment"># Copyright 2021 &quot;Holloway&quot; Chew, Kean Ho &lt;kean.ho.chew@zoralab.com&gt;</span><span class="hljs-comment"># Copyright 2020 Benny Powers (https://forum.gitlab.com/u/bennyp/summary)</span><span class="hljs-comment"># Copyright 2017 Adam Boseley (https://forum.gitlab.com/u/adam.boseley/summary)</span><span class="hljs-comment">#</span><span class="hljs-comment"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><span class="hljs-comment"># you may not use this file except in compliance with the License.</span><span class="hljs-comment"># You may obtain a copy of the License at</span><span class="hljs-comment">#</span><span class="hljs-comment"># http://www.apache.org/licenses/LICENSE-2.0</span><span class="hljs-comment">#</span><span class="hljs-comment"># Unless required by applicable law or agreed to in writing, software</span><span class="hljs-comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><span class="hljs-comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><span class="hljs-comment"># See the License for the specific language governing permissions and</span><span class="hljs-comment"># limitations under the License.</span><span class="hljs-comment">##############</span><span class="hljs-comment"># user input #</span><span class="hljs-comment">##############</span><span class="hljs-comment"># project ID (Help: goto &quot;Settings&quot; &gt; &quot;General&quot;)</span>projectID=<span class="hljs-string">&quot;&quot;</span><span class="hljs-comment"># user API token (Help: &quot;User Settings&quot; &gt; &quot;Access Tokens&quot; &gt; tick &quot;api&quot;)</span>token=<span class="hljs-string">&quot;&quot;</span><span class="hljs-comment"># gitlab server instance</span>server=<span class="hljs-string">&quot;gitlab.com&quot;</span><span class="hljs-comment"># CI Jobs pagination (Help: &quot;CI/CD&quot; &gt; &quot;Jobs&quot; &gt; see bottom pagination bar)</span><span class="hljs-comment">#</span><span class="hljs-comment"># <span class="hljs-doctag">NOTE:</span> user interface might be bug. If so, you need to manually calculate.</span><span class="hljs-comment"># By default, maximum 10,000 (end_page * per_page) job artifacts will be removed, while retaining 100 most recent artifacts.</span><span class="hljs-comment"># Example:</span><span class="hljs-comment">#   1. For 123 jobs in the past and per_page is &quot;100&quot; (maximum), it has 2 pages (end_page) in total</span><span class="hljs-comment">#      [end_page = ROUND_UP(total_job / per_page)].</span><span class="hljs-comment">#   2. To retain most recent 200 jobs</span><span class="hljs-comment">#      [start_page = num_job_retain / per_page + 1]</span>start_page=<span class="hljs-string">&quot;2&quot;</span>end_page=<span class="hljs-string">&quot;100&quot;</span>per_page=<span class="hljs-string">&quot;100&quot;</span><span class="hljs-comment"># GitLab API version</span>api=<span class="hljs-string">&quot;v4&quot;</span><span class="hljs-comment">#####################</span><span class="hljs-comment"># internal function #</span><span class="hljs-comment">#####################</span><span class="hljs-function"><span class="hljs-title">delete</span></span>() &#123;  <span class="hljs-comment"># page</span>  page=<span class="hljs-string">&quot;<span class="hljs-variable">$1</span>&quot;</span>  1&gt;&amp;2 <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;Cleaning page <span class="hljs-variable">$&#123;page&#125;</span>...\n&quot;</span>  <span class="hljs-comment"># build internal variables</span>  baseURL=<span class="hljs-string">&quot;https://<span class="hljs-variable">$&#123;server&#125;</span>/api/<span class="hljs-variable">$&#123;api&#125;</span>/projects&quot;</span>  <span class="hljs-comment"># get list from servers for the page</span>  url=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;baseURL&#125;</span>/<span class="hljs-variable">$&#123;projectID&#125;</span>/jobs/?page=<span class="hljs-variable">$&#123;page&#125;</span>&amp;per_page=<span class="hljs-variable">$&#123;per_page&#125;</span>&quot;</span>  1&gt;&amp;2 <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;Calling API to get lob list: <span class="hljs-variable">$&#123;url&#125;</span>\n&quot;</span>  list=$(curl --globoff --header <span class="hljs-string">&quot;PRIVATE-TOKEN:<span class="hljs-variable">$&#123;token&#125;</span>&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$url</span>&quot;</span> \    | jq -r <span class="hljs-string">&quot;.[].id&quot;</span>)  <span class="hljs-keyword">if</span> [ <span class="hljs-variable">$&#123;#list[@]&#125;</span> -eq 0 ]; <span class="hljs-keyword">then</span>    1&gt;&amp;2 <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;list is empty\n&quot;</span>    <span class="hljs-built_in">return</span> 0  <span class="hljs-keyword">fi</span>  <span class="hljs-comment"># remove all jobs from page</span>  <span class="hljs-keyword">for</span> jobID <span class="hljs-keyword">in</span> <span class="hljs-variable">$&#123;list[@]&#125;</span>; <span class="hljs-keyword">do</span>    url=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;baseURL&#125;</span>/<span class="hljs-variable">$&#123;projectID&#125;</span>/jobs/<span class="hljs-variable">$&#123;jobID&#125;</span>/erase&quot;</span>    1&gt;&amp;2 <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;Calling API to erase job: <span class="hljs-variable">$&#123;url&#125;</span>\n&quot;</span>    curl --request POST --header <span class="hljs-string">&quot;PRIVATE-TOKEN:<span class="hljs-variable">$&#123;token&#125;</span>&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$url</span>&quot;</span>    1&gt;&amp;2 <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;\n\n&quot;</span>  <span class="hljs-keyword">done</span>&#125;<span class="hljs-function"><span class="hljs-title">main</span></span>() &#123;  <span class="hljs-comment"># check dependencies</span>  <span class="hljs-keyword">if</span> [ -z $(<span class="hljs-built_in">type</span> -p jq) ]; <span class="hljs-keyword">then</span>    1&gt;&amp;2 <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;[ ERROR ] need &#x27;jq&#x27; dependency to parse json.&quot;</span>    <span class="hljs-built_in">exit</span> 1  <span class="hljs-keyword">fi</span>  <span class="hljs-comment"># loop through each pages from given start_page to end_page inclusive</span>  <span class="hljs-keyword">for</span> ((i=start_page; i&lt;=end_page; i++)); <span class="hljs-keyword">do</span>    delete <span class="hljs-variable">$i</span>  <span class="hljs-keyword">done</span>  <span class="hljs-comment"># return</span>  <span class="hljs-built_in">exit</span> 0&#125;main <span class="hljs-variable">$@</span></code></pre><h2 id="Before-amp-after">Before &amp; after <a href="#Before-amp-after" class="headerlink" title="Before &amp; after">§</a></h2><table><thead><tr><th>Project</th><th>Before</th><th>After</th><th>Runtime</th></tr></thead><tbody><tr><td><a href="https://gitlab.com/malware-filter/malware-filter">malware-filter</a> (project)</td><td>15.12 GB</td><td>6.3 GB</td><td>46m 15s</td></tr><tr><td><a href="https://gitlab.com/malware-filter/phishing-filter">phishing-filter</a></td><td>6.02 GB</td><td>949 MB</td><td>1h 35m 17s</td></tr><tr><td><a href="https://gitlab.com/malware-filter/pup-filter">pup-filter</a></td><td>1.16 GB</td><td>480.4 MB</td><td>57m 45s</td></tr><tr><td><a href="https://gitlab.com/malware-filter/tracking-filter">tracking-filter</a></td><td>106.68 MB</td><td>105.3 MB</td><td>4m 38s</td></tr><tr><td><a href="https://gitlab.com/malware-filter/urlhaus-filter">urlhaus-filter</a></td><td>2.64 GB</td><td>908 MB</td><td>1h 50m 19s</td></tr><tr><td><a href="https://gitlab.com/malware-filter/vn-badsite-filter">vn-badsite-filter</a></td><td>283.12 MB</td><td>114.8 MB</td><td>19m 52s</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">Use this script to unlock a repository that has exceeded the 5 GB usage quota</summary>
    
    
    
    <category term="gitlab" scheme="https://mdleom.com/tags/gitlab/"/>
    
  </entry>
  
  <entry>
    <title>Installing Caddy plugins in NixOS</title>
    <link href="https://mdleom.com/blog/2021/12/27/caddy-plugins-nixos/"/>
    <id>https://mdleom.com/blog/2021/12/27/caddy-plugins-nixos/</id>
    <published>2021-12-27T00:00:00.000Z</published>
    <updated>2023-02-26T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="#Custom-package">Previous method</a> no longer works on 22.11. Refer to <a href="#xcaddy">xcaddy</a> section instead.</p></blockquote><p>Caddy, like any other web servers, is extensible through plugins. Plugin is usually installed using <a href="https://github.com/caddyserver/xcaddy">xcaddy</a>; using it is as easy as <code>$ xcaddy build --with github.com/caddyserver/ntlm-transport</code> to build the latest caddy binary with <a href="https://github.com/caddyserver/ntlm-transport">ntlm-transport</a> plugin.</p><p>NixOS has its <a href="https://nixos.org/manual/nixpkgs/stable/#sec-language-go">own way</a> of building Go package (Caddy is written in Go), so using xcaddy may be counterintuitive. The <em>Nix</em>-way to go is to build a custom package using a “*.nix” file and instruct the service (also known as a <em>module</em> in Nix ecosystem) to use that package instead of the repo’s.</p><p>In NixOS, the Caddy module has long included <a href="https://search.nixos.org/options?channel=21.11&show=services.caddy.package&from=0&size=50&sort=relevance&type=packages&query=caddy"><code>services.caddy.package</code></a> option to specify custom package. It was primarily used as a way to install Caddy 2 from the unstable channel (<code>unstable.caddy</code>) because the package in stable channel (<code>pkgs.caddy</code>) of NixOS 20.03 is still Caddy 1. I talked about that option in a <a href="/blog/2020/05/24/caddy-v2-nixos/" title="Running Caddy 2 in NixOS 20.03">previous post</a>.</p><p>Aside from installing Caddy from different channel, that option can also be used to specify a custom package by using <a href="https://nixos.org/guides/nix-pills/callpackage-design-pattern.html"><code>pkgs.callPackage</code></a>. I <a href="/blog/2021/07/02/custom-package-nixos-module/" title="Using custom package in a NixOS module">previously used</a> <code>callPackage</code> as a workaround to install cloudflared in an IPv6-only instance from a repository other than GitHub because GitHub doesn’t support IPv6 yet.</p><p>If a custom package is defined in “&#x2F;etc&#x2F;caddy&#x2F;custom-package.nix”, then the configuration will be:</p><pre><div class="caption"><span>/etc/nixos/configuration.nix</span></div><code class="hljs nix">services.<span class="hljs-attr">caddy</span> = &#123;  <span class="hljs-attr">enable</span> = <span class="hljs-literal">true</span>;  <span class="hljs-attr">package</span> = pkgs.callPackage /etc/caddy/custom-package.nix &#123; &#125;;&#125;;</code></pre><h2 id="Custom-package">Custom package <a href="#Custom-package" class="headerlink" title="Custom package">§</a></h2><p>The following package patches the “<a href="https://github.com/caddyserver/caddy/blob/master/cmd/main.go">main.go</a>“ file of the upstream source to insert additional plugins. The code snippet is courtesy of <a href="https://github.com/diamondburned">@diamondburned</a>. The marked lines show how plugins are specified through the <code>plugins</code> option.</p><pre><div class="caption"><span>/etc/caddy/custom-package.nix</span><a href="https://github.com/NixOS/nixpkgs/issues/89268#issuecomment-636529668">source</a></div><code class="hljs nix">&#123; lib, buildGoModule, fetchFromGitHub, plugins ? [], vendorSha256 ? <span class="hljs-string">&quot;&quot;</span> &#125;:<span class="hljs-keyword">with</span> lib;<mark><span class="hljs-keyword">let</span> <span class="hljs-attr">imports</span> = flip concatMapStrings plugins (pkg: <span class="hljs-string">&quot;\t\t\t_ \&quot;</span>$&#123;pkg&#125;\<span class="hljs-string">&quot;\n&quot;</span>);</mark>  <span class="hljs-attr">main</span> = <span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">    package main</span><span class="hljs-string"></span><span class="hljs-string">    import (</span><span class="hljs-string">      caddycmd &quot;github.com/caddyserver/caddy/v2/cmd&quot;</span><span class="hljs-string"></span><span class="hljs-string">      _ &quot;github.com/caddyserver/caddy/v2/modules/standard&quot;</span><mark><span class="hljs-string"><span class="hljs-subst">$&#123;imports&#125;</span></span></mark><span class="hljs-string">    )</span><span class="hljs-string"></span><span class="hljs-string">    func main() &#123;</span><span class="hljs-string">      caddycmd.Main()</span><span class="hljs-string">    &#125;</span><span class="hljs-string">  &#x27;&#x27;</span>;<span class="hljs-keyword">in</span> buildGoModule <span class="hljs-keyword">rec</span> &#123;  <span class="hljs-attr">pname</span> = <span class="hljs-string">&quot;caddy&quot;</span>;  <span class="hljs-attr">version</span> = <span class="hljs-string">&quot;2.4.6&quot;</span>;  <span class="hljs-attr">subPackages</span> = [ <span class="hljs-string">&quot;cmd/caddy&quot;</span> ];  <span class="hljs-attr">src</span> = fetchFromGitHub &#123;    <span class="hljs-attr">owner</span> = <span class="hljs-string">&quot;caddyserver&quot;</span>;    <span class="hljs-attr">repo</span> = pname;    <span class="hljs-comment"># https://github.com/NixOS/nixpkgs/blob/nixos-21.11/pkgs/servers/caddy/default.nix</span>    <span class="hljs-attr">rev</span> = <span class="hljs-string">&quot;v<span class="hljs-subst">$&#123;version&#125;</span>&quot;</span>;    <span class="hljs-attr">sha256</span> = <span class="hljs-string">&quot;sha256-xNCxzoNpXkj8WF9+kYJfO18ux8/OhxygkGjA49+Q4vY=&quot;</span>;  &#125;;  <span class="hljs-keyword">inherit</span> vendorSha256;  <span class="hljs-attr">overrideModAttrs</span> = (_: &#123;    <span class="hljs-attr">preBuild</span>    = <span class="hljs-string">&quot;echo &#x27;<span class="hljs-subst">$&#123;main&#125;</span>&#x27; &gt; cmd/caddy/main.go&quot;</span>;    <span class="hljs-attr">postInstall</span> = <span class="hljs-string">&quot;cp go.sum go.mod $out/ &amp;&amp; ls $out/&quot;</span>;  &#125;);  <span class="hljs-attr">postPatch</span> = <span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">    echo &#x27;<span class="hljs-subst">$&#123;main&#125;</span>&#x27; &gt; cmd/caddy/main.go</span><span class="hljs-string">    cat cmd/caddy/main.go</span><span class="hljs-string">  &#x27;&#x27;</span>;  <span class="hljs-attr">postConfigure</span> = <span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">    cp vendor/go.sum ./</span><span class="hljs-string">    cp vendor/go.mod ./</span><span class="hljs-string">  &#x27;&#x27;</span>;  <span class="hljs-attr">meta</span> = <span class="hljs-keyword">with</span> lib; &#123;    <span class="hljs-attr">homepage</span> = https://caddyserver.com;    <span class="hljs-attr">description</span> = <span class="hljs-string">&quot;Fast, cross-platform HTTP/2 web server with automatic HTTPS&quot;</span>;    <span class="hljs-attr">license</span> = licenses.asl20;    <span class="hljs-attr">maintainers</span> = <span class="hljs-keyword">with</span> maintainers; [ rushmorem fpletz zimbatm ];  &#125;;&#125;</code></pre><h3 id="Install-custom-package">Install custom package <a href="#Install-custom-package" class="headerlink" title="Install custom package">§</a></h3><p>Specify the desired plugins in <code>services.caddy.package.plugins</code>:</p><pre><div class="caption"><span>/etc/nixos/configuration.nix</span></div><code class="hljs nix">services.<span class="hljs-attr">caddy</span> = &#123;  <span class="hljs-attr">enable</span> = <span class="hljs-literal">true</span>;  <span class="hljs-attr">package</span> = (pkgs.callPackage /etc/caddy/custom-package.nix &#123;    <span class="hljs-attr">plugins</span> = [      <span class="hljs-string">&quot;github.com/caddyserver/ntlm-transport&quot;</span>      <span class="hljs-string">&quot;github.com/caddyserver/forwardproxy&quot;</span>    ];    <span class="hljs-attr">vendorSha256</span> = <span class="hljs-string">&quot;0000000000000000000000000000000000000000000000000000&quot;</span>;  &#125;);&#125;;</code></pre><p>The above example will install ntlm-transport and <a href="https://github.com/caddyserver/forwardproxy">forwardproxy</a> plugins. The first run of <code>nixos-rebuild</code> will fail due to mismatched <code>vendorSha256</code>, simply replace the “000…” with the expected value and the second run should be ok.</p><h2 id="xcaddy">xcaddy <a href="#xcaddy" class="headerlink" title="xcaddy">§</a></h2><h3 id="Nix-sandbox">Nix sandbox <a href="#Nix-sandbox" class="headerlink" title="Nix sandbox">§</a></h3><p>Since the Nix-way of building custom caddy plugins no longer works in 22.11, I resort to the <em>caddy</em>-way instead, by using <a href="https://github.com/caddyserver/xcaddy">xcaddy</a>. The implication of using xcaddy is that Nix sandbox can no longer be enabled because the sandbox does not even allow network access. Nix sandbox is enabled by default in NixOS, to disable:</p><pre><div class="caption"><span>/etc/nixox/configuration.nix</span></div><code class="hljs nix">nix.settings.<span class="hljs-attr">sandbox</span> = <span class="hljs-literal">false</span>;</code></pre><p>Then run <code>sudo nixos-rebuild switch</code> to apply the config. Verify the generated config in <code>/etc/nix/nix.conf</code>.</p><p><a href="https://nixos.wiki/wiki/Nix_package_manager#Sandboxing">Nix sandbox</a> is not a security feature, rather it is used to provide reproducibility, its fundamental feature. When enabled, each build will run in an isolated environment not affected by the system configuration. This feature is essential when contributing to <a href="https://github.com/NixOS/nixpkgs">Nixpkgs</a> to ensure that a successful build does not depend on the contributor’s system configuration. For example, all dependencies should be declared even when the contributor’s system already installed all or some beforehand; a build will fail if there is any undeclared dependency.</p><h3 id="Build-custom-plugins-with-xcaddy">Build custom plugins with xcaddy <a href="#Build-custom-plugins-with-xcaddy" class="headerlink" title="Build custom plugins with xcaddy">§</a></h3><p>The following package will always use the <a href="https://github.com/caddyserver/caddy/releases/latest"><code>latest</code></a> caddy release.</p><pre><div class="caption"><span>/etc/caddy/custom-package.nix</span><a href="https://discourse.nixos.org/t/build-caddy-with-modules-in-devenv-shell/25125/4">source</a></div><code class="hljs nix">&#123; pkgs, config, plugins, ... &#125;:<span class="hljs-keyword">with</span> pkgs;stdenv.mkDerivation <span class="hljs-keyword">rec</span> &#123;  <span class="hljs-attr">pname</span> = <span class="hljs-string">&quot;caddy&quot;</span>;<mark>  <span class="hljs-comment"># https://github.com/NixOS/nixpkgs/issues/113520</span></mark>  <span class="hljs-attr">version</span> = <span class="hljs-string">&quot;latest&quot;</span>;  <span class="hljs-attr">dontUnpack</span> = <span class="hljs-literal">true</span>;  <span class="hljs-attr">nativeBuildInputs</span> = [ git go xcaddy ];  <span class="hljs-attr">configurePhase</span> = <span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">    export GOCACHE=$TMPDIR/go-cache</span><span class="hljs-string">    export GOPATH=&quot;$TMPDIR/go&quot;</span><span class="hljs-string">  &#x27;&#x27;</span>;  <span class="hljs-attr">buildPhase</span> = <span class="hljs-keyword">let</span>    <span class="hljs-attr">pluginArgs</span> = lib.concatMapStringsSep <span class="hljs-string">&quot; &quot;</span> (plugin: <span class="hljs-string">&quot;--with <span class="hljs-subst">$&#123;plugin&#125;</span>&quot;</span>) plugins;  <span class="hljs-keyword">in</span> <span class="hljs-string">&#x27;&#x27;</span><mark><span class="hljs-string">    runHook preBuild</span></mark><span class="hljs-string">    <span class="hljs-subst">$&#123;xcaddy&#125;</span>/bin/xcaddy build latest <span class="hljs-subst">$&#123;pluginArgs&#125;</span></span><span class="hljs-string">    runHook postBuild</span><span class="hljs-string">  &#x27;&#x27;</span>;  <span class="hljs-attr">installPhase</span> = <span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">    runHook preInstall</span><span class="hljs-string">    mkdir -p $out/bin</span><span class="hljs-string">    mv caddy $out/bin</span><span class="hljs-string">    runHook postInstall</span><span class="hljs-string">  &#x27;&#x27;</span>;&#125;</code></pre><p>If you prefer to specify a version, modify the following lines:</p><pre><code class="hljs nix"><span class="hljs-comment"># line 7</span><span class="hljs-attr">version</span> = <span class="hljs-string">&quot;2.6.4&quot;</span>;<span class="hljs-comment"># line 12</span>$&#123;xcaddy&#125;/bin/xcaddy build <span class="hljs-string">&quot;v<span class="hljs-subst">$&#123;version&#125;</span>&quot;</span> $&#123;pluginArgs&#125;</code></pre><p>To install the above package, use the same config shown in the <a href="#Install-custom-package">Install custom package</a> but remove the <code>vendorSha256</code> line. Remember to <code>nixos-rebuild</code> again.</p>]]></content>
    
    
    <summary type="html">By using custom package</summary>
    
    
    
    <category term="caddy" scheme="https://mdleom.com/tags/caddy/"/>
    
    <category term="nixos" scheme="https://mdleom.com/tags/nixos/"/>
    
  </entry>
  
  <entry>
    <title>Parsing NGINX log in Splunk</title>
    <link href="https://mdleom.com/blog/2021/12/25/nginx-splunk-field-extractor/"/>
    <id>https://mdleom.com/blog/2021/12/25/nginx-splunk-field-extractor/</id>
    <published>2021-12-25T00:00:00.000Z</published>
    <updated>2021-12-25T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>For web server’s access log, Splunk has built-in support for Apache only. Splunk has a feature called field extractor. It is powered by delimiter and regex, and enables user to add new <a href="https://docs.splunk.com/Documentation/Splunk/8.2.3/Knowledge/Aboutfields"><em>fields</em></a> to be used in a search query. This post will only covers the regex patterns to parse nginx log, for instruction on field extractor, I recommend perusing the <a href="https://docs.splunk.com/Documentation/Splunk/8.2.3/Knowledge/ExtractfieldsinteractivelywithIFX">official documentation</a>.</p><p>To illustrate, say we have a log format like this:</p><pre><code class="hljs plaintext">&#123;id&#125; &quot;&#123;http.request.host&#125;&quot; &quot;&#123;http.request.header.user-agent&#125;&quot;</code></pre><p>An example log is:</p><pre><code class="hljs plaintext">123 &quot;example.com&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:95.0) Gecko/20100101 Firefox/95.0&quot;</code></pre><p>While you could search for a specific keyword, e.g. attempts of <a href="/blog/2021/12/17/log4shell-log4j-unbound-dns/" title="Check Log4Shell vulnerability using Unbound DNS server">Log4shell exploit</a>, since there are no fields, you cannot run any statistics like <a href="https://docs.splunk.com/Documentation/Splunk/latest/SearchReference/Table"><code>table</code></a> or <a href="https://docs.splunk.com/Documentation/Splunk/latest/SearchReference/stats"><code>stats</code></a> on the search results.</p><p>Splunk is able to understand Apache log format because its field extractor already includes the necessary regex patterns to parse the relevant fields of each line in a log. Choosing a source type is equivalent of choosing a log format. If a format is not listed in <a href="https://docs.splunk.com/Documentation/Splunk/8.2.3/Data/Listofpretrainedsourcetypes">the default list</a>, we can either use an add-on or create new fields using field extractor. There is a Splunk <a href="https://docs.splunk.com/Documentation/AddOns/latest/NGINX">add-on</a> for nginx and I suggest to try it before resorting to field extractor.</p><p>I create five patterns which cover most of the nginx events I encountered during my work. Refer to the documentation for <a href="https://docs.splunk.com/Documentation/Splunk/8.2.3/Knowledge/AboutSplunkregularexpressions">supported syntax</a>.</p><p>A field is extracted through “capturing group”.</p><pre><code class="hljs plaintext">(?&lt;field_name&gt;capture pattern)</code></pre><p>For example, <code>(?&lt;month&gt;\w+)</code> searches for one or more (<code>+</code>) alphanumeric characters (<code>\w</code>) and names the field as <code>month</code>. I opted for lazier matching, mostly using unbounded quantifier <code>+</code> instead of a stricter range of occurrences <code>&#123;M,N&#125;</code> despite knowing the exact pattern of a field. I found some fields may stray off slightly from the expected pattern, so a lazier matching tends match more events without matching unwanted’s.</p><h2 id="Web-request">Web request <a href="#Web-request" class="headerlink" title="Web request">§</a></h2><h3 id="Regex">Regex <a href="#Regex" class="headerlink" title="Regex">§</a></h3><pre><code class="hljs plaintext">(?&lt;month&gt;\w+)\s+(?&lt;day&gt;\d+)\s(?&lt;time&gt;[\d\:]+)\s(?&lt;proxy_ip&gt;[\d\.]+)(?:\snginx\:\s)(?&lt;remote_ip&gt;[\d\.]+)(?:\s\d+\s\S+\s\S+\s)\[(?&lt;time_local&gt;\S+)\s(?&lt;timezone&gt;\+\d&#123;4&#125;)\]\s&quot;(?&lt;http_method&gt;\w+)\s(?&lt;http_path&gt;.+)\s(?&lt;http_version&gt;HTTP/\d\.\d)&quot;\s(?&lt;http_status&gt;\d&#123;3&#125;)\s(?:\d+)\s&quot;(?&lt;request_url&gt;.[^&quot;]*)&quot;\s&quot;(?&lt;http_user_agent&gt;.[^&quot;]*)&quot;\s(?&lt;server_ip&gt;[\d\.]+)\:(?&lt;server_port&gt;\d+)(?:\s\d+\s\d+\s)(?&lt;ssl_version&gt;\S+)\s(?&lt;ssl_cipher&gt;\S+)\s(?&lt;http_cookie&gt;\S+)</code></pre><h3 id="Event">Event <a href="#Event" class="headerlink" title="Event">§</a></h3><pre><code class="hljs plaintext">Dec 24 01:23:45 192.168.0.2 nginx: 1.2.3.4 55763 - - [24/Dec/2021:01:23:45 +0000] &quot;GET /page.html HTTP/2.0&quot; 200 494 &quot;https://www.example.com&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:95.0) Gecko/20100101 Firefox/95.0&quot; 192.168.1.2:8080 123 4 TLSv1.2 ECDHE-RSA-AES128-GCM-SHA256 abcdef .</code></pre><h3 id="Fields">Fields <a href="#Fields" class="headerlink" title="Fields">§</a></h3><table><thead><tr><th>Field</th><th>Value</th><th>Regex</th><th>Explanation</th></tr></thead><tbody><tr><td>month</td><td>Dec</td><td><code>(?&lt;month&gt;\w+)</code></td><td>One or more alphanumeric</td></tr><tr><td>day</td><td>24</td><td><code>(?&lt;day&gt;\d+)</code></td><td>One or more digit</td></tr><tr><td>time</td><td>01:23:45</td><td><code>(?&lt;time&gt;[\d\:]+)</code></td><td>One or more digit or semicolon</td></tr><tr><td>proxy_ip</td><td>192.168.0.2</td><td><code>(?&lt;proxy_ip&gt;[\d\.]+)</code></td><td>One or more digit or dot</td></tr><tr><td>remote_ip</td><td>1.2.3.4</td><td><code>(?&lt;remote_ip&gt;[\d\.]+)</code></td><td></td></tr><tr><td>time_local</td><td>24&#x2F;Dec&#x2F;2021:01:23:45</td><td><code>(?&lt;time_local&gt;\S+)</code></td><td>One or more non-whitespace characters</td></tr><tr><td>timezone</td><td>+0000</td><td><code>(?&lt;timezone&gt;[\+\-]\d&#123;4&#125;)</code></td><td>Four digits with plus or minus prefix</td></tr><tr><td>http_method</td><td>GET</td><td><code>(?&lt;http_method&gt;\w+)</code></td><td></td></tr><tr><td>http_path</td><td>&#x2F;page.html</td><td><code>(?&lt;http_path&gt;.+)</code></td><td>One or more of any character</td></tr><tr><td>http_version</td><td>HTTP&#x2F;2.0</td><td><code>(?&lt;http_version&gt;HTTP/\d\.\d)</code></td><td>“HTTP”, a digit, dot and digit</td></tr><tr><td>http_status</td><td>200</td><td><code>(?&lt;http_status&gt;\d&#123;3&#125;)</code></td><td>Three digits</td></tr><tr><td>request_url</td><td><a href="https://www.example.com/">https://www.example.com</a></td><td><code>(?&lt;request_url&gt;.[^&quot;]*)</code></td><td>Zero or more of any character except double quote</td></tr><tr><td>http_user_agent</td><td>Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64; rv:95.0) Gecko&#x2F;20100101 Firefox&#x2F;95.0</td><td><code>(?&lt;http_user_agent&gt;.[^&quot;]*)</code></td><td></td></tr><tr><td>server_ip</td><td>192.168.1.2</td><td><code>(?&lt;server_ip&gt;[\d\.]+)</code></td><td></td></tr><tr><td>server_port</td><td>8080</td><td><code>(?&lt;server_port&gt;\d+)</code></td><td></td></tr><tr><td>ssl_version</td><td>TLSv1.2</td><td><code>(?&lt;ssl_version&gt;\S+)</code></td><td></td></tr><tr><td>ssl_cipher</td><td>ECDHE-RSA-AES128-GCM-SHA256</td><td><code>(?&lt;ssl_cipher&gt;\S+)</code></td><td></td></tr><tr><td>http_cookie</td><td>abcdef</td><td><code>(?&lt;http_cookie&gt;\S+)</code></td><td></td></tr></tbody></table><p>nginx is configured as a reverse proxy, <code>proxy_ip</code> is its ip whereas <code>server_ip</code> is the upstream’s.</p><h2 id="Proxy-request">Proxy request <a href="#Proxy-request" class="headerlink" title="Proxy request">§</a></h2><h3 id="Regex-1">Regex <a href="#Regex-1" class="headerlink" title="Regex">§</a></h3><pre><code class="hljs plaintext">(?&lt;month&gt;\w+)\s+(?&lt;day&gt;\d+)\s(?&lt;time&gt;[\d\:]+)\s(?&lt;proxy_ip&gt;[\d\.]+)(?:\snginx\:\s)(?&lt;year&gt;\d&#123;4&#125;)\/(?&lt;nmonth&gt;\d&#123;2&#125;)(?:\/\d&#123;2&#125;\s[\d\:]+\s)\[(?&lt;log_level&gt;\w+)\](?:\s\d+#\d+\:\s\*\d+\sclient\s)(?&lt;remote_ip&gt;[\d\.]+)\:(?&lt;remote_port&gt;\d+)(?:\sconnected\sto\s)(?&lt;server_ip&gt;[\d\.]+)\:(?&lt;server_port&gt;\d+)</code></pre><h3 id="Event-1">Event <a href="#Event-1" class="headerlink" title="Event">§</a></h3><pre><code class="hljs plaintext">Dec 24 01:23:45 192.168.0.2 nginx: 2021/12/24 01:23:45 [info] 1776#1776:*114333142 client 1.2.3.4:19802 connected to 192.168.1.2:8080</code></pre><h3 id="Fields-1">Fields <a href="#Fields-1" class="headerlink" title="Fields">§</a></h3><table><thead><tr><th>Field</th><th>Value</th><th>Regex</th><th>Explanation</th></tr></thead><tbody><tr><td>month</td><td>Dec</td><td><code>(?&lt;month&gt;\w+)</code></td><td></td></tr><tr><td>day</td><td>24</td><td><code>(?&lt;day&gt;\d+)</code></td><td></td></tr><tr><td>time</td><td>01:23:45</td><td><code>(?&lt;time&gt;[\d\:]+)</code></td><td></td></tr><tr><td>proxy_ip</td><td>192.168.0.2</td><td><code>(?&lt;proxy_ip&gt;[\d\.]+)</code></td><td></td></tr><tr><td>year</td><td>2021</td><td><code>(?&lt;year&gt;\d&#123;4&#125;)</code></td><td></td></tr><tr><td>nmonth</td><td>12</td><td><code>(?&lt;nmonth&gt;\d&#123;2&#125;)</code></td><td></td></tr><tr><td>log_level</td><td>info</td><td><code>(?&lt;log_level&gt;\w+)</code></td><td></td></tr><tr><td>remote_ip</td><td>1.2.3.4</td><td><code>(?&lt;remote_ip&gt;[\d\.]+)</code></td><td></td></tr><tr><td>remote_port</td><td>19802</td><td><code>(?&lt;remote_port&gt;\d+)</code></td><td></td></tr><tr><td>server_ip</td><td>192.168.1.2</td><td><code>(?&lt;server_ip&gt;[\d\.]+)</code></td><td></td></tr><tr><td>server_port</td><td>8080</td><td><code>(?&lt;server_port&gt;\d+)</code></td><td></td></tr></tbody></table><h2 id="Upstream-error-response">Upstream error response <a href="#Upstream-error-response" class="headerlink" title="Upstream error response">§</a></h2><h3 id="Regex-2">Regex <a href="#Regex-2" class="headerlink" title="Regex">§</a></h3><pre><code class="hljs plaintext">(?&lt;month&gt;\w+)\s+(?&lt;day&gt;\d+)\s(?&lt;time&gt;[\d\:]+)\s(?&lt;proxy_ip&gt;[\d\.]+)(?:\snginx\:\s)(?&lt;year&gt;\d&#123;4&#125;)\/(?&lt;nmonth&gt;\d&#123;2&#125;)(?:\/\d&#123;2&#125;\s[\d\:]+\s)\[(?&lt;log_level&gt;\w+)\](?:\s\d+#\d+\:\s\*\d+\s)(?&lt;upstream_error&gt;.[^,]*)(?:,\sclient\:\s)(?&lt;remote_ip&gt;[\d\.]+)(?:,\sserver\:\s)(?&lt;server_host&gt;.[^,]*)(?:,\srequest\:\s&quot;)(?&lt;http_method&gt;\w+)\s(?&lt;http_path&gt;\S+)\s(?&lt;http_version&gt;HTTP/\d\.\d)(?:&quot;,\supstream\:\s&quot;)(?&lt;upstream_url&gt;.[^&quot;]*)&quot;,\shost\:\s&quot;(?&lt;upstream_host&gt;.[^&quot;]*)</code></pre><h3 id="Event-2">Event <a href="#Event-2" class="headerlink" title="Event">§</a></h3><pre><code class="hljs plaintext">Dec 24 01:23:45 192.168.0.2 nginx: 2021/12/24 01:23:45 [error] 1776#1776:*71197740 upstream timed out (110: Connection timed out) while reading response header from upstream, client: 1.2.3.4, server: example.com, request: &quot;POST /api/path HTTP/2.0&quot;,upstream: &quot;http://192.168.1.2:8080/api/path&quot;, host:&quot;example.com&quot;</code></pre><h3 id="Fields-2">Fields <a href="#Fields-2" class="headerlink" title="Fields">§</a></h3><table><thead><tr><th>Field</th><th>Value</th><th>Regex</th><th>Explanation</th></tr></thead><tbody><tr><td>month</td><td>Dec</td><td><code>(?&lt;month&gt;\w+)</code></td><td></td></tr><tr><td>day</td><td>24</td><td><code>(?&lt;day&gt;\d+)</code></td><td></td></tr><tr><td>time</td><td>01:23:45</td><td><code>(?&lt;time&gt;[\d\:]+)</code></td><td></td></tr><tr><td>proxy_ip</td><td>192.168.0.2</td><td><code>(?&lt;remote_ip&gt;[\d\.]+)</code></td><td></td></tr><tr><td>year</td><td>2021</td><td><code>(?&lt;year&gt;\d&#123;4&#125;)</code></td><td></td></tr><tr><td>nmonth</td><td>12</td><td><code>(?&lt;nmonth&gt;\d&#123;2&#125;)</code></td><td></td></tr><tr><td>log_level</td><td>error</td><td><code>(?&lt;log_level&gt;\w+)</code></td><td></td></tr><tr><td>upstream_error</td><td>upstream timed out (110: Connection timed out) while reading response header from upstream</td><td><code>(?&lt;upstream_error&gt;.[^,]*)</code></td><td>Zero or more of any character except comma</td></tr><tr><td>remote_ip</td><td>1.2.3.4</td><td><code>(?&lt;remote_ip&gt;[\d\.]+)</code></td><td></td></tr><tr><td>server_host</td><td>example.com</td><td><code>(?&lt;server_host&gt;.[^,]*)</code></td><td></td></tr><tr><td>http_method</td><td>POST</td><td><code>(?&lt;http_method&gt;\w+)</code></td><td></td></tr><tr><td>http_path</td><td>&#x2F;api&#x2F;path</td><td><code>(?&lt;http_path&gt;\S+)</code></td><td></td></tr><tr><td>http_version</td><td>HTTP&#x2F;2.0</td><td><code>(?&lt;http_version&gt;HTTP/\d\.\d)</code></td><td></td></tr><tr><td>upstream_url</td><td><a href="http://192.168.1.2:8080/api/path">http://192.168.1.2:8080/api/path</a></td><td><code>(?&lt;upstream_url&gt;.[^&quot;]*)</code></td><td></td></tr><tr><td>upstream_host</td><td>example.com</td><td><code>(?&lt;upstream_host&gt;.[^&quot;]*)</code></td><td></td></tr></tbody></table><h2 id="Upstream-epoll-error">Upstream epoll error <a href="#Upstream-epoll-error" class="headerlink" title="Upstream epoll error">§</a></h2><h3 id="Regex-3">Regex <a href="#Regex-3" class="headerlink" title="Regex">§</a></h3><pre><code class="hljs plaintext">(?&lt;month&gt;\w+)\s+(?&lt;day&gt;\d+)\s(?&lt;time&gt;[\d\:]+)\s(?&lt;proxy_ip&gt;[\d\.]+)(?:\snginx\:\s)(?&lt;year&gt;\d&#123;4&#125;)\/(?&lt;nmonth&gt;\d&#123;2&#125;)(?:\/\d&#123;2&#125;\s[\d\:]+\s)\[(?&lt;log_level&gt;\w+)\](?:\s\d+#\d+\:\s\*\d+\s)(?&lt;upstream_error&gt;[^,]*,[^,]*)(?:,\sclient\:\s)(?&lt;remote_ip&gt;[\d\.]+)(?:,\sserver\:\s)(?&lt;server_host&gt;.[^,]*)(?:,\srequest\:\s&quot;)(?&lt;http_method&gt;\w+)\s(?&lt;http_path&gt;\S+)\s(?&lt;http_version&gt;HTTP/\d\.\d)(?:&quot;,\supstream\:\s&quot;)(?&lt;upstream_url&gt;.[^&quot;]*)(?:&quot;,\shost\:\s&quot;)(?&lt;upstream_host&gt;.[^&quot;]*)</code></pre><h3 id="Event-3">Event <a href="#Event-3" class="headerlink" title="Event">§</a></h3><pre><code class="hljs plaintext">Dec 24 01:23:45 192.168.0.2 nginx: 2021/12/24 01:23:45 [info] 13199#13199: *81574833 epoll_wait() reported that client prematurely closed connection, so upstream connection is closed too while connecting to upstream, client: 1.2.3.4, server: example.com, request: &quot;GET /page.html HTTP/1.1&quot;, upstream:&quot;http://192.168.1.2/page.html&quot;, host: &quot;example.com&quot;</code></pre><h3 id="Fields-3">Fields <a href="#Fields-3" class="headerlink" title="Fields">§</a></h3><table><thead><tr><th>Field</th><th>Value</th><th>Regex</th><th>Explanation</th></tr></thead><tbody><tr><td>month</td><td>Dec</td><td><code>(?&lt;month&gt;\w+)</code></td><td></td></tr><tr><td>day</td><td>24</td><td><code>(?&lt;day&gt;\d+)</code></td><td></td></tr><tr><td>time</td><td>01:23:45</td><td><code>(?&lt;time&gt;[\d\:]+)</code></td><td></td></tr><tr><td>proxy_ip</td><td>192.168.0.2</td><td><code>(?&lt;remote_ip&gt;[\d\.]+)</code></td><td></td></tr><tr><td>year</td><td>2021</td><td><code>(?&lt;year&gt;\d&#123;4&#125;)</code></td><td></td></tr><tr><td>nmonth</td><td>12</td><td><code>(?&lt;nmonth&gt;\d&#123;2&#125;)</code></td><td></td></tr><tr><td>log_level</td><td>info</td><td><code>(?&lt;log_level&gt;\w+)</code></td><td></td></tr><tr><td>upstream_error</td><td>epoll_wait() reported that client prematurely closed connection, so upstream connection is closed too while connecting to upstream</td><td><code>(?&lt;upstream_error&gt;.[^,]*)</code></td><td></td></tr><tr><td>remote_ip</td><td>1.2.3.4</td><td><code>(?&lt;remote_ip&gt;[\d\.]+)</code></td><td></td></tr><tr><td>server_host</td><td>example.com</td><td><code>(?&lt;server_host&gt;.[^,]*)</code></td><td></td></tr><tr><td>http_method</td><td>GET</td><td><code>(?&lt;http_method&gt;\w+)</code></td><td></td></tr><tr><td>http_path</td><td>&#x2F;page.html</td><td><code>(?&lt;http_path&gt;\S+)</code></td><td></td></tr><tr><td>http_version</td><td>HTTP&#x2F;1.1</td><td><code>(?&lt;http_version&gt;HTTP/\d\.\d)</code></td><td></td></tr><tr><td>upstream_url</td><td><a href="http://192.168.1.2/page.html">http://192.168.1.2/page.html</a></td><td><code>(?&lt;upstream_url&gt;.[^&quot;]*)</code></td><td></td></tr><tr><td>upstream_host</td><td>example.com</td><td><code>(?&lt;upstream_host&gt;.[^&quot;]*)</code></td><td></td></tr></tbody></table><h2 id="Upstream-epoll-error-with-referrer">Upstream epoll error with referrer <a href="#Upstream-epoll-error-with-referrer" class="headerlink" title="Upstream epoll error with referrer">§</a></h2><h3 id="Regex-4">Regex <a href="#Regex-4" class="headerlink" title="Regex">§</a></h3><pre><code class="hljs plaintext">(?&lt;month&gt;\w+)\s+(?&lt;day&gt;\d+)\s(?&lt;time&gt;[\d\:]+)\s(?&lt;proxy_ip&gt;[\d\.]+)(?:\snginx\:\s)(?&lt;year&gt;\d&#123;4&#125;)\/(?&lt;nmonth&gt;\d&#123;2&#125;)(?:\/\d&#123;2&#125;\s[\d\:]+\s)\[(?&lt;log_level&gt;\w+)\](?:\s\d+#\d+\:\s\*\d+\s)(?&lt;upstream_error&gt;[^,]*,[^,]*)(?:,\sclient\:\s)(?&lt;remote_ip&gt;[\d\.]+)(?:,\sserver\:\s)(?&lt;server_host&gt;.[^,]*)(?:,\srequest\:\s&quot;)(?&lt;http_method&gt;\w+)\s(?&lt;http_path&gt;\S+)\s(?&lt;http_version&gt;HTTP/\d\.\d)(?:&quot;,\supstream\:\s&quot;)(?&lt;upstream_url&gt;.[^&quot;]*)(?:&quot;,\shost\:\s&quot;)(?&lt;upstream_host&gt;.[^&quot;]*)(?:&quot;,\sreferrer\:\s&quot;)(?&lt;referrer&gt;.[^&quot;]*)</code></pre><h3 id="Event-4">Event <a href="#Event-4" class="headerlink" title="Event">§</a></h3><pre><code class="hljs plaintext">Dec 24 01:23:45 192.168.0.2 nginx: 2021/12/24 01:23:45 [info] 1776#1776:*71220252 epoll_wait() reported that client prematurely closed connection, so upstream connection is closed too while sending request to upstream, client: 1.2.3.4, server: example.com, request: &quot;GET /page.html HTTP/1.1&quot;, upstream: &quot;http://192.168.1.2:8080/page.html&quot;, host: &quot;example.com&quot;, referrer: &quot;https://example.com&quot;</code></pre><h3 id="Fields-4">Fields <a href="#Fields-4" class="headerlink" title="Fields">§</a></h3><table><thead><tr><th>Field</th><th>Value</th><th>Regex</th><th>Explanation</th></tr></thead><tbody><tr><td>month</td><td>Dec</td><td><code>(?&lt;month&gt;\w+)</code></td><td></td></tr><tr><td>day</td><td>24</td><td><code>(?&lt;day&gt;\d+)</code></td><td></td></tr><tr><td>time</td><td>01:23:45</td><td><code>(?&lt;time&gt;[\d\:]+)</code></td><td></td></tr><tr><td>proxy_ip</td><td>192.168.0.2</td><td><code>(?&lt;remote_ip&gt;[\d\.]+)</code></td><td></td></tr><tr><td>year</td><td>2021</td><td><code>(?&lt;year&gt;\d&#123;4&#125;)</code></td><td></td></tr><tr><td>nmonth</td><td>12</td><td><code>(?&lt;nmonth&gt;\d&#123;2&#125;)</code></td><td></td></tr><tr><td>log_level</td><td>info</td><td><code>(?&lt;log_level&gt;\w+)</code></td><td></td></tr><tr><td>upstream_error</td><td>epoll_wait() reported that client prematurely closed connection, so upstream connection is closed too while sending request to upstream</td><td><code>(?&lt;upstream_error&gt;.[^,]*)</code></td><td></td></tr><tr><td>remote_ip</td><td>1.2.3.4</td><td><code>(?&lt;remote_ip&gt;[\d\.]+)</code></td><td></td></tr><tr><td>server_host</td><td>example.com</td><td><code>(?&lt;server_host&gt;.[^,]*)</code></td><td></td></tr><tr><td>http_method</td><td>GET</td><td><code>(?&lt;http_method&gt;\w+)</code></td><td></td></tr><tr><td>http_path</td><td>&#x2F;page.html</td><td><code>(?&lt;http_path&gt;\S+)</code></td><td></td></tr><tr><td>http_version</td><td>HTTP&#x2F;1.1</td><td><code>(?&lt;http_version&gt;HTTP/\d\.\d)</code></td><td></td></tr><tr><td>upstream_url</td><td><a href="http://192.168.1.2:8080/page.html">http://192.168.1.2:8080/page.html</a></td><td><code>(?&lt;upstream_url&gt;.[^&quot;]*)</code></td><td></td></tr><tr><td>upstream_host</td><td>example.com</td><td><code>(?&lt;upstream_host&gt;.[^&quot;]*)</code></td><td></td></tr><tr><td>referrer</td><td><a href="https://example.com/">https://example.com</a></td><td><code>(?&lt;referrer&gt;.[^&quot;]*)</code></td><td></td></tr></tbody></table>]]></content>
    
    
    <summary type="html">Configure regex in field extractor to create relevant fields</summary>
    
    
    
    <category term="splunk" scheme="https://mdleom.com/tags/splunk/"/>
    
    <category term="nginx" scheme="https://mdleom.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>Check Log4Shell vulnerability using Unbound DNS server</title>
    <link href="https://mdleom.com/blog/2021/12/17/log4shell-log4j-unbound-dns/"/>
    <id>https://mdleom.com/blog/2021/12/17/log4shell-log4j-unbound-dns/</id>
    <published>2021-12-17T00:00:00.000Z</published>
    <updated>2022-02-12T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>(Edit: 12 Feb 2022) AWS CDK stack is available at <a href="https://gitlab.com/curben/aws-scripts/-/tree/main/log4shell-stack">curben&#x2F;aws-scripts</a></p></blockquote><p>Most of the publications discussing the Log4Shell&#x2F;<a href="https://blogs.apache.org/foundation/entry/apache-log4j-cves">Log4j</a> vulnerability (<a href="https://www.huntress.com/blog/rapid-response-critical-rce-vulnerability-is-affecting-java">[1]</a>, <a href="https://www.lunasec.io/docs/blog/log4j-zero-day/">[2]</a>, <a href="https://blog.cloudflare.com/inside-the-log4j2-vulnerability-cve-2021-44228/">[3]</a>, <a href="https://arstechnica.com/information-technology/2021/12/minecraft-and-other-apps-face-serious-threat-from-new-code-execution-bug/">[4]</a>) focus on the ability to instruct the JNDI component to load remote code or download payload using <a href="https://en.wikipedia.org/wiki/Lightweight_Directory_Access_Protocol">LDAP</a>. A less known fact is that Log4j also supports DNS protocol by default, at least in versions prior to 2.15.0.</p><p>Huntress, a cyber security company, created an easy-to-use tool at <a href="https://log4shell.huntress.com/">log4shell.huntress.com</a> to detect whether your server is vulnerable using LDAP. Despite the assurance of transparency by the availability of <a href="https://github.com/huntresslabs/log4shell-tester">source code</a> so you could host it yourself, there’s no denying the fact that log4shell.huntress.com is a <em>third-party</em> service; even if anyone could host it, not everyone has the ability to audit the source code. Another third-party service that is mentioned around is <a href="http://www.dnslog.cn/">dnslog.cn</a> which detects (as the name implies) using DNS protocol.</p><p>Since the DNS request made by Log4j is just a simple DNS lookup—similar to a web browser’s request—we can run any kind of DNS server: authoritative or recursive. Recursive DNS server is the easier option because it simply forwards request to upstream authoritative server(s). If a server is vulnerable, we’ll see its IP address in the DNS server’s query logs when we attempt the exploit.</p><h2 id="Setup-DNS-server">Setup DNS server <a href="#Setup-DNS-server" class="headerlink" title="Setup DNS server">§</a></h2><p>Unbound is a popular DNS server due to its simplicity. dnsmasq is another option, it was the default dns caching in Ubuntu before being replaced by systemd-resolved.</p><p>When installing a server (web, DNS, app, etc), Ubuntu usually starts the service immediately after installation. I prefer to properly configure a server before starting it, so I’m going to <em>mask</em> it first to prevent that auto-start.</p><blockquote><p>Except for checking service status, log and dns query, all commands require <code>sudo</code> privilege.</p></blockquote><pre><code class="hljs plaintext">systemctl mask unbound</code></pre><p>Above command may fail in a script, in that case, use <code>ln -s /dev/null /etc/systemd/system/unbound.service</code> instead.</p><p>Then, we can proceed to install and configure it.</p><pre><code class="hljs plaintext">apt updateapt install unboundsudo -e /etc/unbound/unbound.conf.d/custom.conf</code></pre><p><em><code>sudo -e</code> is preferred over <code>sudo nano</code> for <a href="https://teddit.net/r/linux/comments/osah05/ysk_do_not_use_sudo_vimnanoemacs_to_edit_a_file/">security reason</a>.</em></p><p>Paste the following config.</p><pre><code class="hljs yml"><span class="hljs-comment"># Based on https://www.linuxbabe.com/ubuntu/set-up-unbound-dns-resolver-on-ubuntu-20-04-server</span><span class="hljs-attr">server:</span>  <span class="hljs-comment"># the working directory.</span>  <span class="hljs-attr">directory:</span> <span class="hljs-string">&quot;/etc/unbound&quot;</span>  <span class="hljs-comment"># run as the unbound user</span>  <span class="hljs-attr">username:</span> <span class="hljs-string">unbound</span>  <span class="hljs-comment"># uncomment and increase to get more logging</span>  <span class="hljs-comment"># verbosity: 2</span>  <span class="hljs-comment"># log dns queries</span>  <span class="hljs-attr">log-queries:</span> <span class="hljs-literal">yes</span>  <span class="hljs-comment"># listen on all interfaces,</span>  <span class="hljs-attr">interface:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>  <span class="hljs-comment"># comment out to support IPv6.</span>  <span class="hljs-comment"># interface: ::0</span>  <span class="hljs-comment"># answer queries from the local network only, change to your private IP</span>  <span class="hljs-comment"># interface: 192.168.0.2</span>  <span class="hljs-comment"># perform prefetching of almost expired DNS cache entries.</span>  <span class="hljs-attr">prefetch:</span> <span class="hljs-literal">yes</span>  <span class="hljs-comment"># respond to all IP</span>  <span class="hljs-attr">access-control:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><span class="hljs-string">/0</span> <span class="hljs-string">allow</span>  <span class="hljs-comment"># IPv6</span>  <span class="hljs-comment"># access-control: ::0/0 allow</span>  <span class="hljs-comment"># respond to local network only, change the CIDR according to your network</span>  <span class="hljs-comment"># access-control: 192.168.88.0/24 allow</span>  <span class="hljs-comment"># localhost only</span>  <span class="hljs-comment"># access-control: 127.0.0.1/24 allow</span>  <span class="hljs-comment"># hide server info from clients</span>  <span class="hljs-attr">hide-identity:</span> <span class="hljs-literal">yes</span>  <span class="hljs-attr">hide-version:</span> <span class="hljs-literal">yes</span><span class="hljs-attr">remote-control:</span>  <span class="hljs-comment"># Disable unbound-control</span>  <span class="hljs-attr">control-enable:</span> <span class="hljs-literal">no</span><span class="hljs-attr">forward-zone:</span>  <span class="hljs-comment"># Forward all queries to Quad9, use your favourite DNS</span>  <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;.&quot;</span>  <span class="hljs-attr">forward-addr:</span> <span class="hljs-number">9.9</span><span class="hljs-number">.9</span><span class="hljs-number">.9</span>  <span class="hljs-attr">forward-addr:</span> <span class="hljs-number">149.112</span><span class="hljs-number">.112</span><span class="hljs-number">.112</span></code></pre><p><kbd>Ctrl</kbd> + <kbd>X</kbd> to quit, <kbd>Y</kbd> to save, <kbd>Enter</kbd> to confirm.</p><blockquote><p>With the above config, Unbound will respond to <em>all</em> IP, including <em>public</em> IP if exposed to internet.</p></blockquote><p>Since Unbound will listen on all interfaces, it’ll interfere with systemd-resolved which listens on 127.0.0.53:53 by default. So, before we start Unbound, systemd-resolved needs to be disabled first.</p><pre><code class="hljs plaintext">systemctl disable --now systemd-resolved</code></pre><p>We also need to add the server’s hostname to <code>/etc/hosts</code>, otherwise <code>sudo</code> will take a long time to execute. If you’re using AWS EC2, the hostname will be “ip-<em>a</em>-<em>b</em>-<em>c</em>-<em>d</em>“ where <em>abcd</em> is the private IP.</p><pre><code class="hljs plaintext">sudo -e /etc/hosts# append this line127.0.0.1 ip-a-b-c-d</code></pre><p>The last step before we start the service is to configure the firewall to allow inbound DNS traffic. I recommend not to allow all IP (0.0.0.0, ::0), otherwise you’ll get unwanted traffic. In EC2, that means the attached security group.</p><p>After we configure the firewall, we can proceed to unmask and start the DNS server.</p><pre><code class="hljs plaintext">systemctl unmask unboundsystemctl enable --now unbound</code></pre><p>To see whether it’s working, execute some queries:</p><pre><code class="hljs plaintext"># localhostdig example.com @127.0.0.1# other machine, same subnetdig example.com @192.168.0.x# other machine over internetdig example.com @public-ip</code></pre><p>Verify Unbound is logging queries,</p><pre><code class="hljs plaintext">journalctl -xe -u unbound# Dec 14 01:23:45 ip-a-b-c-d unbound[pid]: [pid:0] info: 127.0.0.1 example.com. A IN</code></pre><p>We are now ready to test Log4shell vulnerability.</p><h2 id="Demo-vulnerable-app">Demo vulnerable app <a href="#Demo-vulnerable-app" class="headerlink" title="Demo vulnerable app">§</a></h2><blockquote><p>This is an optional step to demonstrate Log4shell.</p></blockquote><p>A demo vulnerable is available as a Docker image at <a href="https://github.com/christophetd/log4shell-vulnerable-app">christophetd&#x2F;log4shell-vulnerable-app</a>. For best security practice, I recommend:</p><ol><li>Run it in an isolated network or environment.</li><li>Clone (the repo) and build it, instead of running the prebuild image.</li></ol><p>After building the image and just before you run it, configure the relevant firewall to restrict outbound connection to the Unbound DNS server only. If you prefer to use port 80 for the app server, run <code>docker run -p 80:8080 --name vulnerable-app vulnerable-app</code>. Open inbound port 8080 (or port 80) in the firewall.</p><p>To test the app server is reachable, send a test request.</p><pre><code class="hljs plaintext">curl -IL app-server-ip:8080 -H &#x27;X-Api-Version: foo&#x27;</code></pre><p>The app server should respond HTTP 200. The header must be <code>X-Api-Version</code> because that’s what configured in the log4shell-vulnerable-app.</p><p>Once the connection is verified, we can now instruct it to make a DNS request to our Unbound DNS.</p><pre><code class="hljs plaintext">curl -L app-server-ip:8080 -H &#x27;X-Api-Version: $&#123;jndi:dns://dns-server-ip/evil-request&#125;&#x27;</code></pre><p>In the Unbound’s log, the query should be listed.</p><pre><code class="hljs plaintext">journalctl -xe -u unbound# Dec 14 01:23:45 ip-a-b-c-d unbound[pid]: [pid:0] info: app-server-ip evil-request. A IN</code></pre><p>If you want to see the query log in realtime, <code>journalctl -xe -u unbound -f</code>. If it’s not listed, check the inbound firewall rule applied to the DNS server.</p><h2 id="Is-that-server-vulnerable">Is that server vulnerable? <a href="#Is-that-server-vulnerable" class="headerlink" title="Is that server vulnerable?">§</a></h2><pre><code class="hljs plaintext">curl -L https://target-server-domain -H &#x27;User Agent: $&#123;jndi:dns://dns-server-ip/should-not-show-up-in-the-log&#125;&#x27;</code></pre>]]></content>
    
    
    <summary type="html">Check vulnerability without relying on third-party services</summary>
    
    
    
    <category term="aws" scheme="https://mdleom.com/tags/aws/"/>
    
    <category term="security" scheme="https://mdleom.com/tags/security/"/>
    
  </entry>
  
  <entry>
    <title>Managing inventory: AWS Cloud Control vs Config</title>
    <link href="https://mdleom.com/blog/2021/10/08/cloud-control-config/"/>
    <id>https://mdleom.com/blog/2021/10/08/cloud-control-config/</id>
    <published>2021-10-08T00:00:00.000Z</published>
    <updated>2021-10-08T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>AWS announced a new API called <a href="https://aws.amazon.com/blogs/aws/announcing-aws-cloud-control-api/">Cloud Control</a> that provides a standard sets of APIs to manage AWS resources. Imagine running <code>aws cloudcontrol create-resource</code> to launch EC2 and Lambda, instead of using <code>aws ec2 run-instances</code> and <code>aws lambda create-function</code>.</p><p>Aside from CRUD operations, it also supports List operation to discover all deployed resources filtered by a specific resource type (e.g. <code>AWS::ECS::Cluster</code>). When I first read the announcement, I wonder how it compares to <a href="/blog/2021/09/17/aws-config/" title="Using AWS Config for security compliance and inventory">AWS Config</a>, a feature I’m actively using mainly for security audit, but it could also perform inventory task.</p><p>Since Cloud Control is a recent feature, the latest library is required. For Python library, I ran <code>pip install boto3 --upgrade</code> to update it to version xxx. Then, I created a minimal Python script to test out Cloud Control’s <a href="https://docs.aws.amazon.com/cloudcontrolapi/latest/APIReference/API_ListResources.html">ListResources</a>.</p><pre><code class="hljs py"><span class="hljs-comment">#!/usr/bin/env python</span><span class="hljs-comment"># ./cloud-control.py --profile profile-name --region region-name</span><span class="hljs-keyword">from</span> argparse <span class="hljs-keyword">import</span> ArgumentParser<span class="hljs-keyword">import</span> boto3<span class="hljs-keyword">from</span> botocore.config <span class="hljs-keyword">import</span> Config<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> count<span class="hljs-keyword">from</span> json <span class="hljs-keyword">import</span> dump, loadsparser = ArgumentParser(description = <span class="hljs-string">&#x27;Find the latest AMIs.&#x27;</span>)parser.add_argument(<span class="hljs-string">&#x27;--profile&#x27;</span>, <span class="hljs-string">&#x27;-p&#x27;</span>,  <span class="hljs-built_in">help</span> = <span class="hljs-string">&#x27;AWS profile name. Parsed from ~/.aws/config (SSO) or credentials (API key).&#x27;</span>,  required = <span class="hljs-literal">True</span>)parser.add_argument(<span class="hljs-string">&#x27;--region&#x27;</span>, <span class="hljs-string">&#x27;-r&#x27;</span>,  <span class="hljs-built_in">help</span> = <span class="hljs-string">&#x27;AWS Region, e.g. us-east-1&#x27;</span>,  required = <span class="hljs-literal">True</span>)args = parser.parse_args()profile = args.profileregion = args.regionsession = boto3.session.Session(profile_name = profile)my_config = Config(region_name = region)client = session.client(<span class="hljs-string">&#x27;cloudcontrol&#x27;</span>, config = my_config)results = []response = &#123;&#125;<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> count():  <span class="hljs-comment"># https://docs.aws.amazon.com/cloudcontrolapi/latest/APIReference/API_ListResources.html</span>  params = &#123;    <span class="hljs-comment"># https://docs.aws.amazon.com/cloudcontrolapi/latest/userguide/supported-resources.html</span>    <span class="hljs-string">&#x27;TypeName&#x27;</span>: <span class="hljs-string">&#x27;AWS::EC2::FlowLog&#x27;</span>  &#125;  <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> <span class="hljs-string">&#x27;NextToken&#x27;</span> <span class="hljs-keyword">in</span> response:    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;NextToken&#x27;</span> <span class="hljs-keyword">in</span> response:      params[<span class="hljs-string">&#x27;NextToken&#x27;</span>] = response[<span class="hljs-string">&#x27;NextToken&#x27;</span>]    response = client.list_resources(**params)    results.extend(response[<span class="hljs-string">&#x27;ResourceDescriptions&#x27;</span>])  <span class="hljs-keyword">else</span>:    <span class="hljs-keyword">break</span>prop_list = []<span class="hljs-comment"># Extract properties only</span><span class="hljs-keyword">for</span> ele <span class="hljs-keyword">in</span> results:  prop_list.append(loads(ele[<span class="hljs-string">&#x27;Properties&#x27;</span>]))<span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(prop_list) &gt;= <span class="hljs-number">1</span>:  <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;cloud-control.json&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> w:    <span class="hljs-comment"># Save the first dictionary only</span>    dump(<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">sorted</span>(prop_list[<span class="hljs-number">0</span>].items())), w, indent = <span class="hljs-number">2</span>)</code></pre><p>In the first draft of the script, I noticed that the API doesn’t support <code>AWS::EC2::Instance</code> yet. It took me a while to troubleshoot until I found <a href="https://docs.aws.amazon.com/cloudcontrolapi/latest/userguide/supported-resources.html">this list</a> of supported resources. The error wasn’t very helpful, e.g. “Resource type AWS::EC2::Instance does not support LIST action”. It’s more straightforward to just say “Resource type xxx does not support Cloud Control yet”.</p><p>The announcement did mention not all resources are supported, but I didn’t expect AWS’ <em>bread and butter</em> are unsupported, including <code>AWS::S3::Bucket</code>. I’m sure these resources will be supported eventually, it’s just that support of new products are prioritised at the moment as implied from the announcement, “It will support new AWS resources typically on the day of launch”.</p><p>I tested on <code>AWS::EC2::PrefixList</code>, instead of the currently unsupported <code>AWS::EC2::Instance</code>. It worked fine, the output syntax is exactly what the documentation outlines. To compare it to Config, I created another equivalent script.</p><pre><code class="hljs py"><span class="hljs-comment">#!/usr/bin/env python</span><span class="hljs-comment"># ./aws-config.py --profile profile-name --account-id &#123;account-id&#125; --region region-name</span><span class="hljs-keyword">from</span> argparse <span class="hljs-keyword">import</span> ArgumentParser<span class="hljs-keyword">import</span> boto3<span class="hljs-keyword">from</span> botocore.config <span class="hljs-keyword">import</span> Config<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> count<span class="hljs-keyword">from</span> json <span class="hljs-keyword">import</span> dump, loadsparser = ArgumentParser(description = <span class="hljs-string">&#x27;Find the latest AMIs.&#x27;</span>)parser.add_argument(<span class="hljs-string">&#x27;--profile&#x27;</span>, <span class="hljs-string">&#x27;-p&#x27;</span>,  <span class="hljs-built_in">help</span> = <span class="hljs-string">&#x27;AWS profile name. Parsed from ~/.aws/config (SSO) or credentials (API key).&#x27;</span>,  required = <span class="hljs-literal">True</span>)parser.add_argument(<span class="hljs-string">&#x27;--account-id&#x27;</span>, <span class="hljs-string">&#x27;-a&#x27;</span>,  <span class="hljs-built_in">help</span> = <span class="hljs-string">&#x27;AWS account ID. See ~/.aws/config if SSO is used.&#x27;</span>,  required = <span class="hljs-literal">True</span>,  <span class="hljs-built_in">type</span> = <span class="hljs-built_in">str</span>)parser.add_argument(<span class="hljs-string">&#x27;--region&#x27;</span>, <span class="hljs-string">&#x27;-r&#x27;</span>,  <span class="hljs-built_in">help</span> = <span class="hljs-string">&#x27;AWS Region, e.g. us-east-1&#x27;</span>,  required = <span class="hljs-literal">True</span>)args = parser.parse_args()profile = args.profileaccount_id = args.account_idregion = args.regionsession = boto3.session.Session(profile_name = profile)my_config = Config(region_name = region)client = session.client(<span class="hljs-string">&#x27;config&#x27;</span>, config = my_config)results = []response = &#123;&#125;<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> count():  params = &#123;    <span class="hljs-string">&#x27;Expression&#x27;</span>: <span class="hljs-string">&quot;SELECT configuration WHERE resourceType = &#x27;AWS::EC2::FlowLog&#x27;&quot;</span> \      <span class="hljs-string">f&quot; AND accountId = &#x27;<span class="hljs-subst">&#123;account_id&#125;</span>&#x27;&quot;</span> \      <span class="hljs-string">f&quot; AND awsRegion = &#x27;<span class="hljs-subst">&#123;region&#125;</span>&#x27;&quot;</span>,    <span class="hljs-string">&#x27;ConfigurationAggregatorName&#x27;</span>: <span class="hljs-string">&#x27;ConfigAggregator&#x27;</span> <span class="hljs-comment"># may need to update</span>  &#125;  <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> <span class="hljs-string">&#x27;NextToken&#x27;</span> <span class="hljs-keyword">in</span> response:    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;NextToken&#x27;</span> <span class="hljs-keyword">in</span> response:      params[<span class="hljs-string">&#x27;NextToken&#x27;</span>] = response[<span class="hljs-string">&#x27;NextToken&#x27;</span>]    response = client.select_aggregate_resource_config(**params)    results.extend(response[<span class="hljs-string">&#x27;Results&#x27;</span>])  <span class="hljs-keyword">else</span>:    <span class="hljs-keyword">break</span>conf_list = []<span class="hljs-comment"># Extract configuration only</span><span class="hljs-keyword">for</span> ele <span class="hljs-keyword">in</span> results:  conf_list.append(loads(ele).get(<span class="hljs-string">&#x27;configuration&#x27;</span>, &#123;&#125;))<span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(conf_list) &gt;= <span class="hljs-number">1</span>:  <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;aws-config.json&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> w:    <span class="hljs-comment"># Save the first dictionary only</span>    dump(<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">sorted</span>(conf_list[<span class="hljs-number">0</span>].items())), w, indent = <span class="hljs-number">2</span>)</code></pre><p>Before I get to the output comparison, notice the <code>accountId</code> and <code>awsRegion</code> filters I used in the SQL statement. It’s necessary because I’m using an <a href="https://docs.aws.amazon.com/config/latest/developerguide/aggregate-data.html">aggregator</a> that collects data from <strong>all accounts and regions</strong> in an AWS Organization (which have AWS Config enabled). Like most other AWS APIs, Cloud Control only works on a combination of account and region. If you want discover resources in 5 combinations of account and region, that’ll requires 5 API calls, in contrast to just one API call via Config’s aggregator.</p><p>Here is the output of Cloud Control:</p><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;DeliverLogsPermissionArn&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;Id&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;LogDestination&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;LogDestinationType&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;LogFormat&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;LogGroupName&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;MaxAggregationInterval&quot;</span><span class="hljs-punctuation">:</span> Integer<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;ResourceId&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;ResourceType&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;Tags&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> Tag<span class="hljs-punctuation">,</span> ... <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;TrafficType&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">&#125;</span></code></pre><p>Config:</p><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;creationTime&quot;</span><span class="hljs-punctuation">:</span> Float<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;deliverLogsPermissionArn&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;deliverLogsStatus&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;flowLogId&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;flowLogStatus&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;logDestination&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;logDestinationType&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;logFormat&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;logGroupName&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;maxAggregationInterval&quot;</span><span class="hljs-punctuation">:</span> Float<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;resourceId&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;tags&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> Tag<span class="hljs-punctuation">,</span> ... <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;trafficType&quot;</span><span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">&#125;</span></code></pre><p>Syntax used by <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-flowlog.html">CloudFormation template</a>:</p><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;DeliverLogsPermissionArn&quot;</span> <span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;LogDestination&quot;</span> <span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;LogDestinationType&quot;</span> <span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;LogFormat&quot;</span> <span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;LogGroupName&quot;</span> <span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;MaxAggregationInterval&quot;</span> <span class="hljs-punctuation">:</span> Integer<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;ResourceId&quot;</span> <span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;ResourceType&quot;</span> <span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;Tags&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> Tag<span class="hljs-punctuation">,</span> ... <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;TrafficType&quot;</span> <span class="hljs-punctuation">:</span> String<span class="hljs-punctuation">&#125;</span></code></pre>]]></content>
    
    
    <summary type="html">List AWS resources account-level and organisation-level</summary>
    
    
    
    <category term="aws" scheme="https://mdleom.com/tags/aws/"/>
    
  </entry>
  
  <entry>
    <title>Using AWS Config for security compliance and inventory</title>
    <link href="https://mdleom.com/blog/2021/09/17/aws-config/"/>
    <id>https://mdleom.com/blog/2021/09/17/aws-config/</id>
    <published>2021-09-17T00:00:00.000Z</published>
    <updated>2021-09-17T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>How do I check the patch level of my EC2 instances?</p></blockquote><p>AWS Config is introduced as the answer to the above question, in addition to other compliance requirements. This feature enables a security analyst to query across all accounts (of an organisation) and regions through a single interface. Prior to this feature, you would use <a href="https://aws.amazon.com/systems-manager/">SSM</a> to query each and every account and region, which is not efficient.</p><p>It includes a comprehensive list of AWS-managed rules, which should meet most compliance requirements, though you can also create a <a href="https://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_develop-rules.html">custom rule</a> using a Lambda function. Depending on a company’s industry and regulatory requirements, you could also utilise <a href="https://docs.aws.amazon.com/config/latest/developerguide/conformancepack-sample-templates.html">Conformance Pack</a> which is a set of AWS-managed rules designed to meet certain requirement, e.g. FDA, HIPAA, NIST, PCI DSS.</p><p>Compliance report is downloaded using SQL statement. There are two scopes to choose from: either a chosen combination of account and region or organisation level (also known as Configuration Aggregator). To query resource compliance, use <code>AWS::Config::ResourceCompliance</code> resource type. There are many examples included in the Console, you could also run a custom SQL statement using <a href="https://docs.aws.amazon.com/config/latest/developerguide/querying-AWS-resources.html">Advanced Query</a>.</p><p>In addition to resource compliance, you can also use it to build inventories. For example, you can use <code>AWS::EC2::Instance</code> resource type to list all EC2 instances. So, it can functions as a compliance tool and also an inventory tool.</p><p>A major limitation (as listed in the <a href="https://docs.aws.amazon.com/config/latest/developerguide/querying-AWS-resources.html#query-limitations">docs</a>) is that you cannot query compliant-only (or non-compliant-only) resources of a compliance rule, e.g. <code>AND</code> operator may return result of <code>OR</code> instead.</p><p>To get the actual result, you still need some post-processing to filter out irrelevant entries. I wrote a script to list all enabled rules in an organisation (<a href="https://gitlab.com/curben/aws-scripts/-/blob/main/aws-config-rules.py">aws-config-rules.py</a>) and another script to query the output of some of those rules (<a href="https://gitlab.com/curben/aws-scripts/-/blob/main/aws-config.py">aws-config.py</a>).</p>]]></content>
    
    
    <summary type="html">Query across all accounts and regions of an organisation</summary>
    
    
    
    <category term="aws" scheme="https://mdleom.com/tags/aws/"/>
    
    <category term="security" scheme="https://mdleom.com/tags/security/"/>
    
    <category term="aws-config" scheme="https://mdleom.com/tags/aws-config/"/>
    
  </entry>
  
  <entry>
    <title>Calculate Web ACL Capacity Unit (WCU) in AWS WAF</title>
    <link href="https://mdleom.com/blog/2021/07/23/aws-waf-wcu/"/>
    <id>https://mdleom.com/blog/2021/07/23/aws-waf-wcu/</id>
    <published>2021-07-23T00:00:00.000Z</published>
    <updated>2021-07-23T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>As part of my <a href="/blog/2021/06/27/aws-waf/" title="Convert AWS WAF ACLs to human-readable format">routine review</a> of my company’s <a href="https://aws.amazon.com/waf/">AWS WAF</a> access control lists (ACLs), I also check the WCU of existing web ACLs to see if an ACL still can fit in more rules until it reaches the 1,500 <a href="https://docs.aws.amazon.com/waf/latest/developerguide/limits.html">WCU quota</a>. While checking an ACL’s WCU, I also find it useful to also check WCU of individual rules to locate any rule with larger-than-usual WCU.</p><p>While individual and total WCU are shown during ACL creation&#x2F;modification on the management console, a read-only role could only check the total WCU. It may be possible to use <code>CheckCapacity</code> <a href="https://docs.aws.amazon.com/cli/latest/reference/wafv2/check-capacity.html">CLI</a> or <a href="https://docs.aws.amazon.com/waf/latest/APIReference/API_CheckCapacity.html">API</a> by separating each rule as an ACL, but that’ll involve excessive (online) API calls.</p><p>I further improved my script <a href="https://gitlab.com/curben/aws-scripts/-/blob/main/waf-acl.py">waf-acl.py</a> by implementing <em>offline</em> WCU calculation. While the <a href="https://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-statements-list.html">AWS docs</a> has a complete list of WCU of each match statement, I find the text transformation part is not clear enough.</p><blockquote><p> For each Text transformation that you apply, add 10 WCUs.</p></blockquote><p>It implies that any time you use text transformation, you gotta add 10 units. When I used this assumption, my calculation was off by a mile. It is more accurate to say:</p><blockquote><p> For each <em>unique</em> Text transformation that you apply, add 10 WCUs.</p></blockquote><p>For the purpose of WCU, a text transformation is actually made up of two components: <a href="https://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-statement-fields.html#waf-rule-statement-request-component">request component</a> and <a href="https://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-statement-fields.html#waf-rule-statement-transformation">transformation action</a>.</p><p>For example, URI path (request component) is transformed to lowercase (a transformation action), <code>(URI path + lowercase)</code> are considered as one unique text transformation. <code>(URI path + lowercase)</code> can be applied multiple times within a rule (through nested statements) and even <em>within</em> an ACL, it will still be counted one transformation only.</p><p>This means I need to account for repeated text transformation within a rule, so that it’s calculated only once. This is easily achieved through the use of <a href="https://docs.python.org/3/tutorial/datastructures.html#sets">Python Sets</a>. The same applies when calculating total WCU of an ACL. When a unique text transformation is applied across different rules in an ACL, the sum of all rules’ WCU will be less than the ACL’s WCU.</p><p>When transforming a Header, it’s counted based on a specific header. For example, rule A has <code>(Header(User-Agent) + lowercase)</code> and rule B has <code>(Header(Cookies) + lowercase)</code>, these are counted as two transformations, so they’ll use 20 WCUs.</p>]]></content>
    
    
    <summary type="html">Base unit and text transformation</summary>
    
    
    
    <category term="aws" scheme="https://mdleom.com/tags/aws/"/>
    
  </entry>
  
  <entry>
    <title>Get a ECDSA TLS certificate for your onion service</title>
    <link href="https://mdleom.com/blog/2021/07/04/ecdsa-tls-tor-caddy/"/>
    <id>https://mdleom.com/blog/2021/07/04/ecdsa-tls-tor-caddy/</id>
    <published>2021-07-04T00:00:00.000Z</published>
    <updated>2021-07-04T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>While reading through Tor blog, there was <a href="https://blog.torproject.org/tls-certificate-for-onion-site">a post</a> back in March 2021 to announce HARICA, a root CA operator, has started selling <code>.onion</code> TLS certificate. The cert is of domain validation (DV) type, significantly easier to purchase and cheaper than Digicert’s extended validation (EV) cert, which was previously the only CA that supports .onion.</p><p>The post links to an <a href="https://kushaldas.in/posts/get-a-tls-certificate-for-your-onion-service.html">excellent tutorial</a>. Different from the tutorial, I prefer to use ECDSA cert than RSA, just like Cloudflare’s cert. It includes nginx config, whereas I’m using Caddy web server.</p><ol><li>Create a new <a href="https://cm.harica.gr/">Cert Manager</a> account in HARICA.</li><li>From the Server Certificate on the left sidebar, create a new request for your onion address.</li><li>HARICA can generate a Certificate Signing Request (CSR) on your behalf, but I prefer to use an OpenSSL-generated CSR, so I generated and uploaded one.</li><li>To generate a CSR using OpenSSL:</li></ol><pre><code class="hljs plaintext"># Generate an elliptic-curve private key$ openssl ecparam -name prime256v1 -genkey -noout -out myonion.key# prime256v1 is also used by Cloudflare# Generate a CSR$ openssl req -new -key myonion.key -out myonion.csr# Leave everything blank by entering a dot (.), except for Common Name (CN)# Enter your onion address in CN field</code></pre><ol start="5"><li>DV cert only requires a valid CN field, it’s <em>optional</em> to enter personal details in the CSR.</li><li>Back in Cert Manager, choose “upload a text file to a location on your web server” as the validation option. This option enables you to get wildcard (*.onion.com) cert, necessary if you have subdomain(s) under your onion service.</li><li>Instead of uploading a file to web server, I use <a href="https://caddyserver.com/docs/caddyfile/directives/respond"><code>respond</code></a> instead.</li></ol><pre><code class="hljs Caddyfile">http://xw226dvxac7jzcpsf4xb64r4epr6o5hgn46dxlqk7gnjptakik6xnzqd.onion:8080 &#123;  bind ::1  # Harica CA domain validation<mark>  @harica path /.well-known/pki-validation/xxx</mark><mark>  respond @harica &quot;yyy&quot;</mark>&#125;</code></pre><ol start="8"><li><p>Restart Caddy and check the path has correct response. &#96;curl <a href="http://localhost:8080/.well-known/pki-validation/xxx">http://localhost:8080/.well-known/pki-validation/xxx</a> -H “Host: your-onion.onion”</p></li><li><p>After HARICA verified my onion, I received an email notification that it’s ready for purchase and download.</p></li><li><p>Download the PEM bundle.</p><ul><li>HARICA is <a href="https://news.harica.gr/article/2021_harica_tls_roots/">transitioning</a> to new root certs. For compatibility with older browsers that have not include the latest root certs yet, the PEM bundle needs to include a cross-cert.</li><li>To download the cross-cert, heads to <a href="https://repo.harica.gr/rep_dyn.php">HARICA repo</a>, select <strong>HARICA TLS RSA Root CA 2021 Cross Certificate from HARICA ECC Root CA 2015, 2021</strong> and download PEM.</li><li>Append the cross-cert to the PEM bundle, <code>$ cat pem-bundle.pem cross-cert.pem &gt; fixed-pem-bundle.pem</code></li><li><a href="https://chris.partridge.tech/2022/untrusted-harica-onion-certificates/">More details</a></li></ul></li><li><p>Upload “.pem” and “.key” to the server. <code>chown</code> it to the Caddy system user and <code>chmod 600</code>.</p></li><li><p>Install the cert in Caddy. Site address has to be separated to HTTP and HTTPS blocks due to the use of custom port. When custom port is not used, Caddy listens on port 80 and 443 by default.</p></li></ol><pre><code class="hljs Caddyfile"># HTTPhttp://xw226dvxac7jzcpsf4xb64r4epr6o5hgn46dxlqk7gnjptakik6xnzqd.onion:8080 &#123;  bind ::1  # Redirect to HTTPS  redir https://xw226dvxac7jzcpsf4xb64r4epr6o5hgn46dxlqk7gnjptakik6xnzqd.onion&#123;uri&#125; permanent  # HSTS (optional)  header Strict-Transport-Security &quot;max-age=31536000; includeSubDomains; preload&quot;&#125;# HTTPSxw226dvxac7jzcpsf4xb64r4epr6o5hgn46dxlqk7gnjptakik6xnzqd.onion:8079 &#123;  bind ::1  tls /var/lib/caddy/myonion.pem /var/lib/caddy/myonion.key  header Strict-Transport-Security &quot;max-age=31536000; includeSubDomains; preload&quot;  @harica path /.well-known/pki-validation/xxx  respond @harica &quot;yyy&quot;&#125;</code></pre><ol start="13"><li>Finally, update the Tor config. I configured it via NixOS global config.</li></ol><pre><div class="caption"><span>configuration.nix</span></div><code class="hljs nix">services.<span class="hljs-attr">tor</span> = &#123;  <span class="hljs-attr">enable</span> = <span class="hljs-literal">true</span>;  relay.<span class="hljs-attr">onionServices</span> = &#123;    <span class="hljs-attr">myonion</span> = &#123;      <span class="hljs-attr">version</span> = <span class="hljs-number">3</span>;      <span class="hljs-attr">map</span> = [&#123;        <span class="hljs-attr">port</span> = <span class="hljs-number">80</span>;        <span class="hljs-attr">target</span> = &#123;          <span class="hljs-attr">addr</span> = <span class="hljs-string">&quot;[::1]&quot;</span>;          <span class="hljs-attr">port</span> = <span class="hljs-number">8080</span>;        &#125;;      &#125; &#123;<mark>        <span class="hljs-attr">port</span> = <span class="hljs-number">443</span>;</mark><mark>        <span class="hljs-attr">target</span> = &#123;</mark><mark>          <span class="hljs-attr">addr</span> = <span class="hljs-string">&quot;[::1]&quot;</span>;</mark><mark>          <span class="hljs-attr">port</span> = <span class="hljs-number">8079</span>;</mark><mark>        &#125;;</mark>      &#125;];    &#125;;  &#125;;&#125;;</code></pre>]]></content>
    
    
    <summary type="html">TLS cert for mere mortal</summary>
    
    
    
    <category term="caddy" scheme="https://mdleom.com/tags/caddy/"/>
    
    <category term="tor" scheme="https://mdleom.com/tags/tor/"/>
    
  </entry>
  
  <entry>
    <title>Using custom package in a NixOS module</title>
    <link href="https://mdleom.com/blog/2021/07/02/custom-package-nixos-module/"/>
    <id>https://mdleom.com/blog/2021/07/02/custom-package-nixos-module/</id>
    <published>2021-07-02T00:00:00.000Z</published>
    <updated>2021-07-02T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>I recently setup <a href="/blog/2021/06/15/cloudflare-argo-nixos/" title="Setup Cloudflare Argo Tunnel in NixOS">cloudflared</a> on instances that power this website, while I got it working on most of them, it’s not working on IPv6-only instance. There was installation guide which I managed to resolve later (and what this post is about) and Cloudflare tunnel itself <a href="https://github.com/cloudflare/cloudflared/issues/401">doesn’t support</a> IPv6 yet.</p><p>A quick recap on two of the main components of NixOS: module and package. A package is a program that is available on NixOS repository, the repo doesn’t contain the binary, it’s made up of nix files that describe <em>how</em> to compile it. In this case, <a href="https://github.com/NixOS/nixpkgs/blob/master/pkgs/applications/networking/cloudflared/default.nix">cloudflared.nix</a> is a script to download the source code from <a href="https://github.com/cloudflare/cloudflared">GitHub</a> and compile it as a Go program.</p><p>A module is (usually) used to install a program as a service and make it configurable via <code>configuration.nix</code>. For example, <a href="https://github.com/NixOS/nixpkgs/blob/master/nixos/modules/services/networking/i2pd.nix">i2pd.nix</a> module installs i2pd package (<a href="https://github.com/NixOS/nixpkgs/blob/master/pkgs/tools/networking/i2pd/default.nix"><code>pkgs.i2pd</code></a>) when <code>services.i2pd.enable</code> is enabled.</p><p>A major issue is that GitHub <a href="https://github.community/t/github-on-the-ipv6-internet/2794/14">doesn’t support</a> IPv6 yet, so my IPv6-only instance couldn’t download the source code. A common workaround is to mirror the repo somewhere else that does support IPv6, which is what I did. Then, I created a new custom package nix:</p><pre><div class="caption"><span>cloudflared-custom.nix</span><a href="https://github.com/NixOS/nixpkgs/blob/master/pkgs/applications/networking/cloudflared/default.nix">source</a></div><code class="hljs nix">&#123; lib, buildGoModule, fetchgit &#125;:buildGoModule <span class="hljs-keyword">rec</span> &#123;  <span class="hljs-attr">pname</span> = <span class="hljs-string">&quot;cloudflared&quot;</span>;  <span class="hljs-attr">version</span> = <span class="hljs-string">&quot;2021.6.0&quot;</span>;  <span class="hljs-attr">src</span> = fetchgit &#123;<mark>    <span class="hljs-attr">url</span>    = <span class="hljs-string">&quot;https://example.com/example/cloudflared-mirror.git&quot;</span>;</mark>    <span class="hljs-attr">rev</span>    = <span class="hljs-string">&quot;refs/tags/<span class="hljs-subst">$&#123;version&#125;</span>&quot;</span>;    <span class="hljs-attr">sha256</span> = <span class="hljs-string">&quot;sha256-cX0kdBPDgwjHphxGWrnXohHPp1nzs4SnvCry4AxMtp0=&quot;</span>;  &#125;;  <span class="hljs-attr">vendorSha256</span> = <span class="hljs-literal">null</span>;  <span class="hljs-attr">doCheck</span> = <span class="hljs-literal">false</span>;  <span class="hljs-attr">buildFlagsArray</span> = <span class="hljs-string">&quot;-ldflags=-X main.Version=<span class="hljs-subst">$&#123;version&#125;</span>&quot;</span>;  <span class="hljs-attr">meta</span> = <span class="hljs-keyword">with</span> lib; &#123;    <span class="hljs-attr">description</span> = <span class="hljs-string">&quot;CloudFlare Argo Tunnel daemon (and DNS-over-HTTPS client)&quot;</span>;    <span class="hljs-attr">homepage</span>    = <span class="hljs-string">&quot;https://www.cloudflare.com/products/argo-tunnel&quot;</span>;    <span class="hljs-attr">license</span>     = licenses.unfree;    <span class="hljs-attr">platforms</span>   = platforms.unix;    <span class="hljs-attr">maintainers</span> = [ maintainers.thoughtpolice maintainers.enorris ];  &#125;;&#125;</code></pre><p>In my <a href="/blog/2021/06/15/cloudflare-argo-nixos/" title="Setup Cloudflare Argo Tunnel in NixOS">cloudflared module</a>, I updated the following lines:</p><pre><code class="hljs diff">  options.services.argoWeb = &#123;    enable = mkEnableOption &quot;Cloudflare Argo Tunnel&quot;;    config = mkOption &#123;      default = &quot;/etc/caddy/argoWeb.yml&quot;;      type = types.str;      description = &quot;Path to cloudflared config&quot;;    &#125;;    dataDir = mkOption &#123;      default = &quot;/var/lib/argoWeb&quot;;      type = types.path;      description = &#x27;&#x27;        The data directory, for storing credentials.      &#x27;&#x27;;    &#125;;<span class="hljs-addition">+    package = mkOption &#123;</span><span class="hljs-addition">+      default = pkgs.cloudflared;</span><span class="hljs-addition">+      defaultText = &quot;pkgs.cloudflared&quot;;</span><span class="hljs-addition">+      type = types.package;</span><span class="hljs-addition">+      description = &quot;cloudflared package to use.&quot;;</span><span class="hljs-addition">+    &#125;;</span>  &#125;;<span class="hljs-deletion">-        ExecStart = &quot;$&#123;pkgs.cloudflared&#125;/bin/cloudflared --config $&#123;cfg.config&#125; --no-autoupdate tunnel run&quot;;</span><span class="hljs-addition">+        ExecStart = &quot;$&#123;cfg.package&#125;/bin/cloudflared --config $&#123;cfg.config&#125; --no-autoupdate tunnel run&quot;;</span></code></pre><p>Finally, in my <code>configuration.nix</code>, I configured it to use the custom package:</p><pre><code class="hljs diff">  require = [    /etc/caddy/argoWeb.nix  ];  nixpkgs.config.allowUnfree = true;  services.argoWeb = &#123;    enable = true;<span class="hljs-addition">+    package = pkgs.callPackage (import /etc/caddy/cloudflared-custom.nix) &#123; &#125;;</span>    config = &quot;/etc/caddy/argoWeb.yml&quot;;  &#125;;</code></pre>]]></content>
    
    
    <summary type="html">A workaround for installing GitHub-hosted package in a IPv6-only host</summary>
    
    
    
    <category term="nixos" scheme="https://mdleom.com/tags/nixos/"/>
    
  </entry>
  
  <entry>
    <title>Convert AWS WAF ACLs to human-readable format</title>
    <link href="https://mdleom.com/blog/2021/06/27/aws-waf/"/>
    <id>https://mdleom.com/blog/2021/06/27/aws-waf/</id>
    <published>2021-06-27T00:00:00.000Z</published>
    <updated>2021-09-01T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>I regularly need to audit my company’s access control lists (ACLs) implemented in <a href="https://aws.amazon.com/waf/">AWS WAF</a>, as part of my job. Each ACL can be more than a thousand lines which is practically impossible to read. I wrote a script that downloads and summarises the ACLs into human-readable format; each one-thousand-line behemoth is transformed into a fifty-line summary that I can <em>actually</em> audit.</p><p>The script is <a href="https://gitlab.com/curben/aws-scripts/-/blob/main/waf-acl.py">available here</a>. It currently only supports Cloudfront ACL, feel free to extend it to support regional ACL.</p><p>(Edit: 1 Sep 2021) regional ACL is now supported.</p><h2 id="ACL-schema">ACL schema <a href="#ACL-schema" class="headerlink" title="ACL schema">§</a></h2><p>The underlying format of a web ACL is JSON. In this use case, I’m only concern with two keys:</p><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;Name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;Rules&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>    <span class="hljs-punctuation">&#123;</span>      <span class="hljs-attr">&quot;Name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span>      <span class="hljs-attr">&quot;Statement&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span>      <span class="hljs-attr">&quot;Action&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>        <span class="hljs-attr">&quot;Block&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-punctuation">&#125;</span>      <span class="hljs-punctuation">&#125;</span>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span>    <span class="hljs-punctuation">&#123;</span>      <span class="hljs-attr">&quot;Name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span>      <span class="hljs-attr">&quot;Statement&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span>      <span class="hljs-attr">&quot;Action&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>        <span class="hljs-attr">&quot;Allow&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-punctuation">&#125;</span>      <span class="hljs-punctuation">&#125;</span>    <span class="hljs-punctuation">&#125;</span>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">&#125;</span></code></pre><p>The script names each ACL according to the value of “Name”. “Rules” is an array of objects, where each object represents a rule. Each rule has an <a href="https://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-action.html">action</a> of count, allow or block.</p><p>In each rule, there is a statement and it functions as a matching condition. Each <a href="https://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-statements-list.html">statement</a> can contain one or match statements combined using logical rule (AND, NOT, OR).</p><h2 id="Converted-schema">Converted schema <a href="#Converted-schema" class="headerlink" title="Converted schema">§</a></h2><p>A converted ACL has an array of objects, each object has three keys.</p><pre><code class="hljs json"><span class="hljs-punctuation">[</span>  <span class="hljs-punctuation">&#123;</span>    <span class="hljs-attr">&quot;Name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;Action&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;Rule&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">]</span></code></pre><h2 id="And-x2F-OrStatement">And&#x2F;OrStatement <a href="#And-x2F-OrStatement" class="headerlink" title="And&#x2F;OrStatement">§</a></h2><pre><div class="caption"><span>Original</span></div><code class="hljs json"><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;Name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ruleA&quot;</span><span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;Statement&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>    <span class="hljs-attr">&quot;OrStatement&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>      <span class="hljs-attr">&quot;Statements&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>        <span class="hljs-punctuation">&#123;</span>          <span class="hljs-attr">&quot;foo&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-punctuation">&#125;</span>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span>        <span class="hljs-punctuation">&#123;</span>          <span class="hljs-attr">&quot;bar&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-punctuation">&#125;</span>        <span class="hljs-punctuation">&#125;</span>      <span class="hljs-punctuation">]</span>    <span class="hljs-punctuation">&#125;</span>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">&#125;</span></code></pre><pre><div class="caption"><span>Converted</span></div><code class="hljs json"><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;ruleA&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;foo OR bar&quot;</span><span class="hljs-punctuation">&#125;</span></code></pre><h2 id="Nested-And-x2F-OrStatement">Nested And&#x2F;OrStatement <a href="#Nested-And-x2F-OrStatement" class="headerlink" title="Nested And&#x2F;OrStatement">§</a></h2><pre><div class="caption"><span>Original</span></div><code class="hljs json"><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;Name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ruleA&quot;</span><span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;Statement&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>    <span class="hljs-attr">&quot;AndStatement&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>      <span class="hljs-attr">&quot;Statements&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>        <span class="hljs-punctuation">&#123;</span>          <span class="hljs-attr">&quot;OrStatement&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>            <span class="hljs-attr">&quot;Statements&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>              <span class="hljs-punctuation">&#123;</span>                <span class="hljs-attr">&quot;foo&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-punctuation">&#125;</span>              <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span>              <span class="hljs-punctuation">&#123;</span>                <span class="hljs-attr">&quot;bar&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-punctuation">&#125;</span>              <span class="hljs-punctuation">&#125;</span>            <span class="hljs-punctuation">]</span>          <span class="hljs-punctuation">&#125;</span>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span>        <span class="hljs-punctuation">&#123;</span>          <span class="hljs-attr">&quot;baz&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-punctuation">&#125;</span>        <span class="hljs-punctuation">&#125;</span>      <span class="hljs-punctuation">]</span>    <span class="hljs-punctuation">&#125;</span>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">&#125;</span></code></pre><pre><div class="caption"><span>Converted</span></div><code class="hljs json"><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;ruleA&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;(foo OR bar) AND baz&quot;</span><span class="hljs-punctuation">&#125;</span></code></pre><h2 id="NotStatement">NotStatement <a href="#NotStatement" class="headerlink" title="NotStatement">§</a></h2><pre><div class="caption"><span>Original</span></div><code class="hljs json"><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;Name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ruleA&quot;</span><span class="hljs-punctuation">,</span>  <span class="hljs-attr">&quot;Statement&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>    <span class="hljs-attr">&quot;NotStatement&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>      <span class="hljs-attr">&quot;Statement&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>        <span class="hljs-attr">&quot;foo&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-punctuation">&#125;</span>      <span class="hljs-punctuation">&#125;</span>    <span class="hljs-punctuation">&#125;</span>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">&#125;</span></code></pre><pre><div class="caption"><span>Converted</span></div><code class="hljs json"><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;ruleA&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;NOT foo&quot;</span><span class="hljs-punctuation">&#125;</span></code></pre><h2 id="String-match">String match <a href="#String-match" class="headerlink" title="String match">§</a></h2><pre><div class="caption"><span>Orignal</span></div><code class="hljs json"><span class="hljs-punctuation">&#123;</span>  <span class="hljs-attr">&quot;ByteMatchStatement&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>    <span class="hljs-attr">&quot;SearchString&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;.conf&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;FieldToMatch&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span>      <span class="hljs-attr">&quot;UriPath&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-punctuation">&#125;</span>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;PositionalConstraint&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ENDS_WITH&quot;</span>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">&#125;</span></code></pre><pre><div class="caption"><span>Converted</span></div><code class="hljs plain">UriPath=ENDSWITH(.conf)</code></pre>]]></content>
    
    
    <summary type="html">Run the attached script to download and convert ACLs</summary>
    
    
    
    <category term="aws" scheme="https://mdleom.com/tags/aws/"/>
    
    <category term="security" scheme="https://mdleom.com/tags/security/"/>
    
  </entry>
  
  <entry>
    <title>Setup Cloudflare Argo Tunnel in NixOS</title>
    <link href="https://mdleom.com/blog/2021/06/15/cloudflare-argo-nixos/"/>
    <id>https://mdleom.com/blog/2021/06/15/cloudflare-argo-nixos/</id>
    <published>2021-06-15T00:00:00.000Z</published>
    <updated>2021-06-15T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>Cloudflare Argo Tunnel enables a web server to serve websites over the public internet without opening an inbound port. With its built-in NAT traversal, a web server can even operate behind a NAT without resorting to port forwarding. The NAT traversal feature reminds me of Tor onion and I2P Eepsite, though the underlying connection is totally different.</p><p>It operates through a Cloudflare daemon (<a href="https://github.com/cloudflare/cloudflared">cloudflared</a>) that a user installs in a server. The daemon creates outbound tunnel(s) to the CDN and forward incoming request to the local web server. It is available for free since April 2021. However, the latest NixOS at that time was 20.09 and it shipped an older version of the daemon that didn’t support static tunnel.</p><p><a href="https://blog.cloudflare.com/argo-tunnels-that-live-forever/">Static tunnel</a> is a feature introduced in v2020.9.3 that associate a tunnel with a static subdomain (UUID.cfargotunnel.com) that a user can CNAME a website to; without this feature, cloudflared had to recreate DNS record every time a tunnel reconnects.</p><p>I can now use the newer daemon after my recent upgrade to <a href="/blog/2021/06/13/upgrade-note-nixos-21-05/" title="My upgrade note of NixOS 21.05">NixOS 21.05</a>.</p><h2 id="Setup">Setup <a href="#Setup" class="headerlink" title="Setup">§</a></h2><p>Generate a new cert.pem from <a href="https://dash.cloudflare.com/argotunnel">dashboard</a>. This is only required to create a new tunnel. When creating a new tunnel, cloudflared also generate a credentials file (UUID.json) that you use to <em>run</em> a tunnel, so you don’t have upload the cert.pem to your server. Since tunnel can be created anywhere, you can do it from your workstation.</p><p>Grab the cloudflared binary from <a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/install-and-setup/installation">Cloudflare</a> and make it executable without installing it to “&#x2F;usr&#x2F;bin”.</p><h2 id="Create-a-new-tunnel">Create a new tunnel <a href="#Create-a-new-tunnel" class="headerlink" title="Create a new tunnel">§</a></h2><p>This step can be done on your local machine, the actual installation on a server comes later. Once cloudflared binary and cert.pem are downloaded, proceed to creating a new tunnel.</p><pre><code class="hljs plaintext">./cloudflared tunnel --origincert cert.pem create mytunnel</code></pre><p>A new <em>UUID</em>.json will be generated in the current folder.</p><h2 id="Configure-the-tunnel">Configure the tunnel <a href="#Configure-the-tunnel" class="headerlink" title="Configure the tunnel">§</a></h2><p>Create a new yml file.</p><pre><code class="hljs yml"><span class="hljs-attr">tunnel:</span> <span class="hljs-string">mytunnel</span><span class="hljs-attr">credentials-file:</span> <span class="hljs-string">/var/lib/argoWeb/uuid.json</span><span class="hljs-comment"># Optional</span><span class="hljs-comment"># loglevel: warn</span><span class="hljs-attr">ingress:</span>  <span class="hljs-bullet">-</span> <span class="hljs-attr">hostname:</span> <span class="hljs-string">mdleom.com</span>    <span class="hljs-attr">service:</span> <span class="hljs-string">http://localhost:4430</span>  <span class="hljs-bullet">-</span> <span class="hljs-attr">hostname:</span> <span class="hljs-string">www.mdleom.com</span>    <span class="hljs-attr">service:</span> <span class="hljs-string">http://localhost:4430</span>  <span class="hljs-bullet">-</span> <span class="hljs-attr">service:</span> <span class="hljs-string">http_status:404</span></code></pre><p>The last entry is intentionally left without a <code>hostname</code> key as required by cloudflared. Usually, it’s configured with <code>http_status:404</code> so cloudflared returns that status if there is no matching destination hostname for an incoming request. This can happen when say you have a foo.example.com DNS record that points to the daemon, so incoming request does reach the daemon, but either you forgot to configure the daemon to route the traffic to the actual foo.example.com web server or the web server is not running at all. In that case, the daemon will return a HTTP 404 status.</p><h2 id="Configure-NixOS">Configure NixOS <a href="#Configure-NixOS" class="headerlink" title="Configure NixOS">§</a></h2><p>Create a new user and group named “argoWeb” in the server.</p><pre><code class="hljs nix"><span class="hljs-attr">users</span> = &#123;  <span class="hljs-attr">users</span> = &#123;    <span class="hljs-attr">argoWeb</span> = &#123;      <span class="hljs-attr">home</span> = <span class="hljs-string">&quot;/var/lib/argoWeb&quot;</span>;      <span class="hljs-attr">createHome</span> = <span class="hljs-literal">true</span>;      <span class="hljs-attr">isSystemUser</span> = <span class="hljs-literal">true</span>;      <span class="hljs-attr">group</span> = <span class="hljs-string">&quot;argoWeb&quot;</span>;    &#125;;  &#125;;  <span class="hljs-attr">groups</span> = &#123;    caddyProxy.<span class="hljs-attr">members</span> = [ <span class="hljs-string">&quot;argoWeb&quot;</span> ];  &#125;;&#125;;</code></pre><p>Once <code>argoWeb</code> is created via nixos-rebuild, upload and move the json file to “&#x2F;var&#x2F;lib&#x2F;argoWeb” folder. <code>chown argoWeb:argoWeb</code> and <code>chmod 600</code> that file.</p><p>Then, Create a new nix file; in this case, I’m using “&#x2F;etc&#x2F;caddy&#x2F;“ folder (where I put other *.nix files):</p><pre><div class="caption"><span>/etc/caddy/argoWeb.nix</span></div><code class="hljs nix">&#123; config, lib, pkgs, ... &#125;:<span class="hljs-keyword">with</span> lib;<span class="hljs-keyword">let</span>  <span class="hljs-attr">cfg</span> = config.services.argoWeb;<span class="hljs-keyword">in</span> &#123;  options.services.<span class="hljs-attr">argoWeb</span> = &#123;    <span class="hljs-attr">enable</span> = mkEnableOption <span class="hljs-string">&quot;Cloudflare Argo Tunnel&quot;</span>;    <span class="hljs-attr">config</span> = mkOption &#123;      <span class="hljs-attr">default</span> = <span class="hljs-string">&quot;/etc/caddy/argoWeb.yml&quot;</span>;      <span class="hljs-attr">type</span> = types.str;      <span class="hljs-attr">description</span> = <span class="hljs-string">&quot;Path to cloudflared config&quot;</span>;    &#125;;    <span class="hljs-attr">dataDir</span> = mkOption &#123;      <span class="hljs-attr">default</span> = <span class="hljs-string">&quot;/var/lib/argoWeb&quot;</span>;      <span class="hljs-attr">type</span> = types.path;      <span class="hljs-attr">description</span> = <span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">        The data directory, for storing credentials.</span><span class="hljs-string">      &#x27;&#x27;</span>;    &#125;;    <span class="hljs-attr">package</span> = mkOption &#123;      <span class="hljs-attr">default</span> = pkgs.cloudflared;      <span class="hljs-attr">defaultText</span> = <span class="hljs-string">&quot;pkgs.cloudflared&quot;</span>;      <span class="hljs-attr">type</span> = types.package;      <span class="hljs-attr">description</span> = <span class="hljs-string">&quot;cloudflared package to use.&quot;</span>;    &#125;;  &#125;;  <span class="hljs-attr">config</span> = mkIf cfg.enable &#123;    systemd.services.<span class="hljs-attr">argoWeb</span> = &#123;      <span class="hljs-attr">description</span> = <span class="hljs-string">&quot;Cloudflare Argo Tunnel&quot;</span>;      <span class="hljs-attr">after</span> = [ <span class="hljs-string">&quot;network-online.target&quot;</span> ];      <span class="hljs-attr">wants</span> = [ <span class="hljs-string">&quot;network-online.target&quot;</span> ]; <span class="hljs-comment"># systemd-networkd-wait-online.service</span>      <span class="hljs-attr">wantedBy</span> = [ <span class="hljs-string">&quot;multi-user.target&quot;</span> ];      <span class="hljs-attr">serviceConfig</span> = &#123;        <span class="hljs-attr">ExecStart</span> = <span class="hljs-string">&quot;<span class="hljs-subst">$&#123;cfg.package&#125;</span>/bin/cloudflared --config <span class="hljs-subst">$&#123;cfg.config&#125;</span> --no-autoupdate tunnel run&quot;</span>;        <span class="hljs-attr">Type</span> = <span class="hljs-string">&quot;simple&quot;</span>;        <span class="hljs-attr">User</span> = <span class="hljs-string">&quot;argoWeb&quot;</span>;        <span class="hljs-attr">Group</span> = <span class="hljs-string">&quot;argoWeb&quot;</span>;        <span class="hljs-attr">Restart</span> = <span class="hljs-string">&quot;on-failure&quot;</span>;        <span class="hljs-attr">RestartSec</span> = <span class="hljs-string">&quot;5s&quot;</span>;        <span class="hljs-attr">NoNewPrivileges</span> = <span class="hljs-literal">true</span>;        <span class="hljs-attr">LimitNPROC</span> = <span class="hljs-number">512</span>;        <span class="hljs-attr">LimitNOFILE</span> = <span class="hljs-number">1048576</span>;        <span class="hljs-attr">PrivateTmp</span> = <span class="hljs-literal">true</span>;        <span class="hljs-attr">PrivateDevices</span> = <span class="hljs-literal">true</span>;        <span class="hljs-attr">ProtectHome</span> = <span class="hljs-literal">true</span>;        <span class="hljs-attr">ProtectSystem</span> = <span class="hljs-string">&quot;full&quot;</span>;        <span class="hljs-attr">ReadWriteDirectories</span> = cfg.dataDir;      &#125;;    &#125;;  &#125;;&#125;</code></pre><p>Move the yml file to “&#x2F;etc&#x2F;caddy&#x2F;“ and set both yml and nix files to be <code>chown root:root</code> and <code>chmod 644</code>.</p><h2 id="Configure-Caddy">Configure Caddy <a href="#Configure-Caddy" class="headerlink" title="Configure Caddy">§</a></h2><p>Bind the web server to localhost (“127.0.0.1” or “::1”) and <em>optionally</em> disable the tls. If Cloudflare’s authenticated origin pull (client authentication) is configured, that should still work if you prefer to leave tls on, though I haven’t test it. You don’t have to bind it to localhost if you insist so, but it defeats the security purpose of Argo.</p><pre><code class="hljs Caddyfile">mdleom.com:4430 www.mdleom.com:4430 &#123;  bind 127.0.0.1  tls /var/lib/caddyProxy/mdleom.com.pem /var/lib/caddyProxy/mdleom.com.key &#123;    protocols tls1.3    client_auth &#123;      mode require_and_verify      trusted_ca_cert_file /var/lib/caddyProxy/origin-pull-ca.pem    &#125;  &#125;&#125;</code></pre><p>Restart&#x2F;reload Caddy for the changed config to take effect.</p><h2 id="Custom-package-optional">Custom package (optional) <a href="#Custom-package-optional" class="headerlink" title="Custom package (optional)">§</a></h2><p>If your NixOS instance is IPv6-only, you may want to use a <a href="/blog/2021/07/02/custom-package-nixos-module/" title="Using custom package in a NixOS module">custom package</a>. <a href="https://search.nixos.org/packages?channel=21.11&from=0&size=50&sort=relevance&type=packages&query=cloudflared"><code>pkgs.cloudflared</code></a> is installed by compiling the source from the <a href="https://github.com/cloudflare/cloudflared">GitHub repo</a>, instead of using a cached binary from Nix repo. cloudflared’s license restricts the distribution of binary, hence the need of source compilation. However, GitHub doesn’t support IPv6 yet, so we need to clone its repo to other Git repo that supports IPv6 and then download it from there.</p><h2 id="Start-cloudflared">Start cloudflared <a href="#Start-cloudflared" class="headerlink" title="Start cloudflared">§</a></h2><pre><code class="hljs nix"><span class="hljs-attr">require</span> = [  /etc/caddy/argoWeb.nix];<span class="hljs-comment"># cloudflared is not distributed via a free software license</span>nixpkgs.config.<span class="hljs-attr">allowUnfree</span> = <span class="hljs-literal">true</span>;services.<span class="hljs-attr">argoWeb</span> = &#123;  <span class="hljs-attr">enable</span> = <span class="hljs-literal">true</span>;  <span class="hljs-attr">config</span> = <span class="hljs-string">&quot;/etc/caddy/argoWeb.yml&quot;</span>;  <span class="hljs-comment"># custom package</span>  <span class="hljs-comment"># package = pkgs.callPackage (import /etc/caddy/cloudflared-custom.nix) &#123; &#125;;</span>&#125;;</code></pre><h2 id="Create-a-CNAME-record">Create a CNAME record <a href="#Create-a-CNAME-record" class="headerlink" title="Create a CNAME record">§</a></h2><p>The last step is to create a new DNS record to CNAME the relevant hostname to <em>UUID</em>.cfargotunnel.com . Existing A&#x2F;CNAME must be removed beforehand since a hostname cannot have both A and CNAME records at the same time, nor having two similar CNAMEs.</p>]]></content>
    
    
    <summary type="html">No inbound port required</summary>
    
    
    
    <category term="linux" scheme="https://mdleom.com/tags/linux/"/>
    
    <category term="server" scheme="https://mdleom.com/tags/server/"/>
    
    <category term="caddy" scheme="https://mdleom.com/tags/caddy/"/>
    
    <category term="nixos" scheme="https://mdleom.com/tags/nixos/"/>
    
    <category term="cloudflare" scheme="https://mdleom.com/tags/cloudflare/"/>
    
  </entry>
  
  <entry>
    <title>My upgrade note of NixOS 21.05</title>
    <link href="https://mdleom.com/blog/2021/06/13/upgrade-note-nixos-21-05/"/>
    <id>https://mdleom.com/blog/2021/06/13/upgrade-note-nixos-21-05/</id>
    <published>2021-06-13T00:00:00.000Z</published>
    <updated>2021-06-13T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>This post details the changes I made to my NixOS’ configuration when upgrading from 20.09 to 21.05.</p><h2 id="isNormalUser-x2F-isSystemUser">isNormalUser&#x2F;isSystemUser <a href="#isNormalUser-x2F-isSystemUser" class="headerlink" title="isNormalUser&#x2F;isSystemUser">§</a></h2><p>Either <a href="https://search.nixos.org/options?channel=21.05&show=users.users.%3Cname%3E.isNormalUser&from=0&size=50&sort=relevance&query=isnormaluser"><code>isNormalUser</code></a> or <code>isSystemUser</code> must now be set. This mainly affects service user (user that is created solely to run a service).</p><pre><code class="hljs diff">  users = &#123;    users = &#123;      fooService = &#123;        home = &quot;/var/www&quot;;        createHome = true;<span class="hljs-addition">+        isSystemUser = true;</span>      &#125;;    &#125;;  &#125;;</code></pre><h2 id="Make-home-folder-world-readable">Make home folder world-readable <a href="#Make-home-folder-world-readable" class="headerlink" title="Make home folder world-readable">§</a></h2><p>I have a “<a href="/blog/2021/03/15/rsync-setup-nixos/" title="rsync is surprisingly simple to setup">&#x2F;var&#x2F;www</a>“ folder which I use to serve this website. Previously, <code>chmod +xr</code> was persistent but now NixOS always set the permission of a user’s home folder to be <code>chmod 700</code> every time <code>nixos-rebuild</code> is executed. As a workaround, I have to configure nix to execute chmod after <code>nixos-rebuild</code> and during boot.</p><pre><code class="hljs nix">system.<span class="hljs-attr">activationScripts</span> = &#123;   www-data.<span class="hljs-attr">text</span> =   <span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">     chmod +xr &quot;/var/www&quot;</span><span class="hljs-string">   &#x27;&#x27;</span>;&#125;;</code></pre><h2 id="Tor-onion">Tor onion <a href="#Tor-onion" class="headerlink" title="Tor onion">§</a></h2><p>Some settings have been renamed:</p><ol><li>hiddenServices → relay.onionServices</li><li><code>map.*.toHost</code> → <code>map.*.target.addr</code></li><li>extraConfig → settings</li></ol><pre><code class="hljs diff">  services.tor = &#123;    enable = true;    enableGeoIP = false;<span class="hljs-deletion">-    hiddenServices = &#123;</span><span class="hljs-deletion">-      myOnion = &#123;</span><span class="hljs-deletion">-        version = 3;</span><span class="hljs-deletion">-        map = [</span><span class="hljs-deletion">-          &#123;</span><span class="hljs-deletion">-            port = &quot;80&quot;;</span><span class="hljs-deletion">-            toHost = &quot;[::1]&quot;;</span><span class="hljs-deletion">-            toPort = &quot;8080&quot;;</span><span class="hljs-deletion">-          &#125;</span><span class="hljs-deletion">-        ];</span><span class="hljs-deletion">-      &#125;</span><span class="hljs-deletion">-    &#125;</span><span class="hljs-deletion">-    extraConfig =</span><span class="hljs-deletion">-      &#x27;&#x27;</span><span class="hljs-deletion">-        ClientUseIPv4 0</span><span class="hljs-deletion">-        ClientUseIPv6 1</span><span class="hljs-deletion">-        ClientPreferIPv6ORPort 1</span><span class="hljs-deletion">-      &#x27;&#x27;;</span><span class="hljs-addition">+    relay.onionServices = &#123;</span><span class="hljs-addition">+      myOnion = &#123;</span><span class="hljs-addition">+        version = 3;</span><span class="hljs-addition">+        map = [&#123;</span><span class="hljs-addition">+          port = 80;</span><span class="hljs-addition">+          target = &#123;</span><span class="hljs-addition">+            addr = &quot;[::1]&quot;;</span><span class="hljs-addition">+            port = 8080;</span><span class="hljs-addition">+          &#125;;</span><span class="hljs-addition">+        &#125;];</span><span class="hljs-addition">+      &#125;;</span><span class="hljs-addition">+    &#125;;</span><span class="hljs-addition">+    settings = &#123;</span><span class="hljs-addition">+      ClientUseIPv4 = false;</span><span class="hljs-addition">+      ClientUseIPv6 = true;</span><span class="hljs-addition">+      ClientPreferIPv6ORPort = true;</span><span class="hljs-addition">+    &#125;;</span>  &#125;;</code></pre>]]></content>
    
    
    <summary type="html">Changes that I made when upgrading from 20.09 to 21.05</summary>
    
    
    
    <category term="linux" scheme="https://mdleom.com/tags/linux/"/>
    
    <category term="server" scheme="https://mdleom.com/tags/server/"/>
    
    <category term="nixos" scheme="https://mdleom.com/tags/nixos/"/>
    
    <category term="tor" scheme="https://mdleom.com/tags/tor/"/>
    
  </entry>
  
</feed>
